<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>24-01 交易复盘</title>
    <link href="/2024/01/31/%E4%BA%A4%E6%98%93%E5%A4%8D%E7%9B%98/%E4%BA%8C%E5%9B%9B%E5%B9%B4%E4%B8%80%E6%9C%88%E4%BA%A4%E6%98%93%E5%A4%8D%E7%9B%98/"/>
    <url>/2024/01/31/%E4%BA%A4%E6%98%93%E5%A4%8D%E7%9B%98/%E4%BA%8C%E5%9B%9B%E5%B9%B4%E4%B8%80%E6%9C%88%E4%BA%A4%E6%98%93%E5%A4%8D%E7%9B%98/</url>
    
    <content type="html"><![CDATA[<h1 id="持仓股票"><a href="#持仓股票" class="headerlink" title="持仓股票"></a>持仓股票</h1><h2 id="PDD"><a href="#PDD" class="headerlink" title="PDD"></a>PDD</h2><p><img src="/../../images/24-01-%E4%BA%A4%E6%98%93%E5%A4%8D%E7%9B%98/image-20240203150616399.png" alt="PDD-日线"></p><h3 id="1、基本面分析"><a href="#1、基本面分析" class="headerlink" title="1、基本面分析"></a>1、基本面分析</h3><ul><li>1.16 Trump 共和党内初选大胜，中概股应声大跌</li><li>1.29 Trump 声称正在思考对中国提高60%关税的可行性，跟境外电商相关的中概大跌（名创优品，拼多多等）</li></ul><h3 id="2、技术分析"><a href="#2、技术分析" class="headerlink" title="2、技术分析"></a>2、技术分析</h3><ul><li><p>1.16前，PDD强势无比</p><ul><li>在调整过程中 上升的时候成交额都是大于下跌的时候</li><li>K线受到20ma的支撑，很强势</li><li>调整的时候没看到不利的K线，上涨秩序没有被打破</li><li><strong>美中不足的是 1.11 突破150块的十字星，略微放量。这不是一个特别好的突破，有可能是假突破，但是结合当时的信息考虑，这个十字星不足为据。如果突破是放量中阳线以上可能会更加好。</strong></li></ul></li><li><p>1.16下跌跌破ma20后，行情转弱</p><ul><li>无法站上1.16的跳空缺口，感觉有很大的压力</li><li>表现比其他大型中概股要弱，上涨比的时候比他们弱，下跌则更加凶猛</li><li>期间的阳线，即使是放量，但是仍旧没法创出新高</li></ul></li><li><p>1.29放量突破后</p><ul><li>1.29这跟K线没什么好说的，标准的strength of weak，未来一段时间基本上都是看空为主</li><li>1.29后的看线，也很弱，基本挑战了1.29收盘价130就马上回撤，上影线</li></ul></li><li><p>周线角度来看</p><ul><li>这周的K线踩到了ma20，但是下破了。</li><li>macd死叉，<strong>这个是最要命的，昨天量化跑了一下，回测历史数据，macd出现死叉，大概只有不到20%的机会能够在4周内恢复</strong></li></ul></li></ul><h3 id="3、交易计划"><a href="#3、交易计划" class="headerlink" title="3、交易计划"></a>3、交易计划</h3><p>​    我并不能预测行情，只能做好相应的计划</p><p>​    目前持有看空期权，以及现货，期权的delta大于现货</p><p>1、下跌第一目标位：120</p><ul><li><p>如果在这个位置附近，出现长阴后 + 微量短K，考虑择机把空单平掉</p></li><li><p>放量插针后，出现高1也会把空单平掉</p></li></ul><p><strong>如果后续的反弹比预期弱，则重新持有空单</strong></p><p>2、下跌第二目标位：100</p><ul><li>如果行情走到这里，就很凶险了，一般中概就没见过守住的，操作同上</li></ul><p>3、如果现在是洗盘行情</p><p>​    其他下周有一个很强的反转K线，但是当前看来比较难</p><p>​    先重点观察130这个位置，日线ema20</p><h2 id="NFLX"><a href="#NFLX" class="headerlink" title="NFLX"></a>NFLX</h2><p><img src="/../../images/24-01-%E4%BA%A4%E6%98%93%E5%A4%8D%E7%9B%98/image-20240203155209287.png" alt="NFLX-日线"></p><h3 id="1、技术分析"><a href="#1、技术分析" class="headerlink" title="1、技术分析"></a>1、技术分析</h3><p>​    我的买入点就在财报前一天</p><p>​    这里分析过很多次了，nk225，nvda都是这样</p><h3 id="2、交易计划"><a href="#2、交易计划" class="headerlink" title="2、交易计划"></a>2、交易计划</h3><ul><li>目前感觉超买了，等待回调到ema20再说</li></ul><h2 id="XBI"><a href="#XBI" class="headerlink" title="XBI"></a>XBI</h2><p><img src="/../../images/24-01-%E4%BA%A4%E6%98%93%E5%A4%8D%E7%9B%98/image-20240203215421007.png" alt="XBI-周线"></p><p><img src="/../../images/24-01-%E4%BA%A4%E6%98%93%E5%A4%8D%E7%9B%98/image-20240203215736221.png" alt="XBI-日线"></p><h3 id="1、基本面分析-1"><a href="#1、基本面分析-1" class="headerlink" title="1、基本面分析"></a>1、基本面分析</h3><ul><li>生物科技，有并购的预期</li><li>中小盘股，降息有很大的好处。但是现在鲍威尔粉碎了三月份降息的预期</li></ul><h3 id="2、技术分析-1"><a href="#2、技术分析-1" class="headerlink" title="2、技术分析"></a>2、技术分析</h3><ul><li>大级别来看，突破了大级别的底部形态。突破之后走出了高位横盘走势</li><li>虽然这几根K线上影线</li><li>K1放量K线插针，努力没有结果</li><li>K2缩量下跌</li><li>K3继续插针，努力没结果</li><li>目前看来卖压有点强，但是并没有破坏上涨秩序</li></ul><h3 id="3、交易计划-1"><a href="#3、交易计划-1" class="headerlink" title="3、交易计划"></a>3、交易计划</h3><p>​    <strong>预计持有100个delta的XBI，目前持有约200delta</strong></p><p>​    如果，继续横盘那是最好，等待突破之后继续加仓。</p><p>​    如果回调，看到83.5附近的支撑力度，如果不好平仓，如果回落很弱，继续持有。</p><h1 id="重点关注"><a href="#重点关注" class="headerlink" title="重点关注"></a>重点关注</h1><h2 id="Marathon"><a href="#Marathon" class="headerlink" title="Marathon"></a>Marathon</h2><p><img src="/../../images/24-01-%E4%BA%A4%E6%98%93%E5%A4%8D%E7%9B%98/image-20240203224331295.png" alt="Mara-日线"></p><h2 id="1、技术分析-1"><a href="#1、技术分析-1" class="headerlink" title="1、技术分析"></a>1、技术分析</h2><ul><li>因为周线在EMA20上，有短期的反弹</li><li>反弹力度有点失望，多次被日线级别的均线压制，上影线很长，经常跳水，并不是强势的表现</li><li>上涨的过程中，缩量，很弱的表现</li></ul><h3 id="2、交易计划-1"><a href="#2、交易计划-1" class="headerlink" title="2、交易计划"></a>2、交易计划</h3><ul><li>平掉所有多仓，如果下周无法站上ma20，找机会做空</li></ul><h2 id="Heng-Sheng-Index"><a href="#Heng-Sheng-Index" class="headerlink" title="Heng Sheng Index"></a>Heng Sheng Index</h2><p><img src="/../../images/24-01-%E4%BA%A4%E6%98%93%E5%A4%8D%E7%9B%98/image-20240203224907602.png" alt="image-20240203224907602"></p><h3 id="1、技术分析-2"><a href="#1、技术分析-2" class="headerlink" title="1、技术分析"></a>1、技术分析</h3><ul><li>上周的几根阳线很强，但是没有后续，持续时间很短</li><li>本来期望，回调的力度很弱，这样构成了抄底的机会。目前来看，并不符合预期。</li><li>谨慎，谨慎，再谨慎</li></ul>]]></content>
    
    
    <categories>
      
      <category>交易</category>
      
    </categories>
    
    
    <tags>
      
      <tag>交易复盘</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>2023交易复盘</title>
    <link href="/2023/12/31/%E4%BA%A4%E6%98%93%E5%A4%8D%E7%9B%98/23-12-31-2023%E4%BA%A4%E6%98%93%E5%A4%8D%E7%9B%98/"/>
    <url>/2023/12/31/%E4%BA%A4%E6%98%93%E5%A4%8D%E7%9B%98/23-12-31-2023%E4%BA%A4%E6%98%93%E5%A4%8D%E7%9B%98/</url>
    
    <content type="html"><![CDATA[<h2 id="年终总结"><a href="#年终总结" class="headerlink" title="年终总结"></a>年终总结</h2><p>​    <img src="/../../images/23-12-31-2023%E4%BA%A4%E6%98%93%E5%A4%8D%E7%9B%98/image-20231231012454761.png" alt="image-20231231012454761"></p><p>​    这个美股账号实际玩的时间四个月，这个收益还算满意啦。明年继续加油</p><p>​    </p><h3 id="1、收获"><a href="#1、收获" class="headerlink" title="1、收获"></a>1、收获</h3><p>​    今年的交易是真的好难做。但是却想明白了两个很重要的事情。</p><ul><li><p><strong>慢就是快，没必要想着一天暴富</strong>，没必要头脑发热。依靠复利，月收益6%左右，三年时间可以把一百万做到一千万。</p></li><li><p><strong>要赚easy money</strong>，不要抄底。寻找区间突破 或者 趋势回调的股票来做。不要逆势反弹，想都不要想 （包括且不限于，下跌趋势中的下行通道、交易区间）</p></li><li><p>要避免有zz风险的市场</p></li></ul><h3 id="2、今年最成功的三笔交易"><a href="#2、今年最成功的三笔交易" class="headerlink" title="2、今年最成功的三笔交易"></a>2、今年最成功的三笔交易</h3><ul><li>01-23 bitcoin 突破20000进场</li><li>11月初 PDD 突破头肩顶横盘，110的时候不断买入，重仓出击。均价145平仓</li><li>12月初Mara突破18，突破进场</li></ul><h3 id="3、今年最傻逼的三笔交易"><a href="#3、今年最傻逼的三笔交易" class="headerlink" title="3、今年最傻逼的三笔交易"></a>3、今年最傻逼的三笔交易</h3><ul><li>8月到10月做多恒指，老是被骗…领悟了千万不要在弱势的市场，而且在下跌趋势中做骚操作。而且真的感觉港股真的好难玩，技术分析基本失效（多头方向）</li><li>11月初做空纳斯达克指数，不想说有多蠢</li><li>错过10月 bitcoin 突破三万的机会</li></ul><h2 id="PDD"><a href="#PDD" class="headerlink" title="PDD"></a>PDD</h2><p><img src="/../../images/23-12-31-2023%E4%BA%A4%E6%98%93%E5%A4%8D%E7%9B%98/image-20231224215416571.png" alt="pdd-周线"></p><p><img src="/../../images/23-12-31-2023%E4%BA%A4%E6%98%93%E5%A4%8D%E7%9B%98/image-20231224215846059.png" alt="pdd-日线"></p><p>​    在上次的博客中，说了<strong>PDD的买入逻辑</strong>，在突破大级别底部之后出现了盘整的形态，带来了一个<strong>盈亏比非常高的买入机会。</strong></p><p>​    在这两周的时间内<strong>判断PDD接近了阶段性的顶部，于是分别在145和147的价格平仓。</strong></p><h3 id="1、技术分析"><a href="#1、技术分析" class="headerlink" title="1、技术分析"></a>1、技术分析</h3><ul><li>目前来看·，从周线来看，无论从何种角度形态、均线来看，都是很bullish的状态。从中长期（3～6个月）的角度来看PDD都是值得持有</li><li>但是从日线来看，各种真的很超买了，而且价格已经已经达到了<strong>第一目标位：150（第二目标位：170）</strong></li><li>从指标来看，RSI、MACD已经很超买了。历史上来看，出现这种情况，即使在多头趋势中，PDD也会有大概15%左右的回调</li><li>从形态来看，财报之后，买力还是很强<ul><li>回调的时候成交量很低</li><li>但是这段时间成交量很低，有出货的嫌疑？但是不是很大貌似，目前来看形态看不到顶部形态</li></ul></li></ul><h3 id="2、交易计划"><a href="#2、交易计划" class="headerlink" title="2、交易计划"></a>2、交易计划</h3><p>​    结论：至少在6个月内，坚定看多PDD，但是目前采取减仓的操作。预计一个月内吧，等待指标的修复，再看看形态有没有破坏</p><ul><li>目标价格分别是133、126再看看</li></ul><h2 id="Bitcoin"><a href="#Bitcoin" class="headerlink" title="Bitcoin"></a>Bitcoin</h2><p><img src="/../../images/23-12-31-2023%E4%BA%A4%E6%98%93%E5%A4%8D%E7%9B%98/image-20231226223533241.png" alt="btc-周线"></p><p><img src="/../../images/23-12-31-2023%E4%BA%A4%E6%98%93%E5%A4%8D%E7%9B%98/image-20231226223624300.png" alt="btc-日线"></p><p>​    从今年年初bitcoin 16000左右开始，就间间断断参与比特币交易。但是牛市前夜选择了退出了，现在想想有点拍断大腿。</p><h3 id="1、技术分析-1"><a href="#1、技术分析-1" class="headerlink" title="1、技术分析"></a>1、技术分析</h3><p>（1）16000 - 25000 底部反弹</p><p>​    这里我有一篇博客写过，为什么参与了这笔反弹交易。</p><ul><li>大阴线后，长期低量短K线，一定程度上说明卖压衰竭</li><li>1-09号的大阳线突破了下降趋势线，并且在小结构里面出现了很好的双底</li></ul><p>​    <strong>但是这时候即使价格涨到25000，还是觉得仅仅是一个反弹。主要表现在上涨很急促，但是后续力量不足。</strong></p><p>（2）19000 - 31000 银行危机</p><p><img src="/../../images/23-12-31-2023%E4%BA%A4%E6%98%93%E5%A4%8D%E7%9B%98/image-20231227221750422.png" alt="image-20231227221750422"></p><p>​    这段的背景是，价格下跌到了22000，当时处于一个比较重要的趋势线上。我从25000之后平仓很久，一直等待机会进行买入。后面出现了银行危机的黑天鹅，价格很快就跌破了19000。<strong>后面只能说，美国人真的厉害，又一次被危机给解决了。三天时间内比特币上涨超40%</strong></p><p>​    这里在btc历史最强周线收盘后（如右图），这里横盘了三根十字星周线。<strong>这里做了一次十字星突破的买入尝试</strong>，从事后结果来看，价格并没有延续强势的周线，而是选择了回调整理到25000。</p><ul><li>从技术的角度来看，这里十字星突破并没有什么问题。<strong>美中不足的可能是，这里突破后并没有延续强势，而是用一种很震荡的上涨，以后碰到这种情况可以酌情考虑减仓，很容易形成背离削弱趋势的力量</strong></li></ul><p>（3）25000 - 44000 牛市起开始</p><p><img src="/../../images/23-12-31-2023%E4%BA%A4%E6%98%93%E5%A4%8D%E7%9B%98/image-20231227225053756.png" alt="image-20231227225053756"></p><p>​    当时大概在七八月份，我在30000左右时候开了一笔空单，大概拿到27000。<strong>后面价格一直在25000左右，横盘，量很小，K线很短。</strong></p><p>​    从技术上来看：</p><ul><li>25000在当前走势是一个非常关键的位置，支撑阻力互换位置。是一个经过验证的支撑位</li><li><strong>在这种位置出现量能很小的K线，对空头不是很友好</strong></li></ul><p>​    后面反弹到30000之后，也一直认为是一个反弹，仅此而已。<strong>但是当价格突破30000之后的走势，让场内几乎所有聪明的交易者都意识到，牛市几乎已经要来了。</strong>两个理由</p><ul><li>10月底这跟K线突破了很关键的阻力位，并且这个位置很容易看出来就是支撑阻力互换，很显然要发生反转了</li><li>今年前几次比特币都是涨的很急促，之前的上涨都是在很短时间内完成的，并不能让人很好的介入，<strong>这次就不太相同，就是上涨持续了很久</strong></li></ul><p>​    <strong>当这些信号出现之后，后续的行情应该按照上涨趋势的思路进行交易。</strong></p><h2 id="Mara-和-Riot-等区块链概念"><a href="#Mara-和-Riot-等区块链概念" class="headerlink" title="Mara 和 Riot 等区块链概念"></a>Mara 和 Riot 等区块链概念</h2><p><img src="/../../images/23-12-31-2023%E4%BA%A4%E6%98%93%E5%A4%8D%E7%9B%98/image-20231231004904490.png" alt="mara-K线"></p><p><img src="/../../images/23-12-31-2023%E4%BA%A4%E6%98%93%E5%A4%8D%E7%9B%98/image-20231231005230777.png" alt="RIOT-K线"></p><p>​    这两个都是矿股，放到一起说了。</p><p>​    最近为什么关注到矿股，主要是基于下面这三个事实：（1）BTC-ETF通过 （2）BTC明年行情 （3）减半</p><h3 id="1、技术分析-2"><a href="#1、技术分析-2" class="headerlink" title="1、技术分析"></a>1、技术分析</h3><p><strong>（1）Mara</strong></p><ul><li>从大形态来看<ul><li>在2022.04 ～ 2023.10 走了差不多600多天的，头肩底形态</li><li>突破了头肩底颈线，并且是一个非常好的支撑阻力互换的位置，<strong>突破了关键的位置关键的阻力</strong></li></ul></li><li>从日线来看<ul><li>突破18块后，做多动能加剧，急速拉升到<strong>31块（第一目标位）</strong></li><li>继续看涨，但是指标过于夸张，有回调需求</li><li>量能来看，12.29的这跟K线，成交量太大了 很夸张…<strong>预计会有两到三周的回调，预计30%～50%</strong></li></ul></li></ul><p><strong>（2）RIOT</strong></p><p>​    走势类似，但是并没突破关键阻力位置。<strong>如果要介入交易，耐心等待。</strong></p><h3 id="2、后续交易计划"><a href="#2、后续交易计划" class="headerlink" title="2、后续交易计划"></a>2、后续交易计划</h3><ul><li>矿股以 Mara，RIOT龙头为主。小仓位可以看看IREN</li><li><strong>Coinbase趋势最为健康，可以考虑介入</strong></li><li>一到两周内 观察Mara 20 18 14 三个价位</li></ul><h2 id="Heng-Sheng-Index-和-Tencent"><a href="#Heng-Sheng-Index-和-Tencent" class="headerlink" title="Heng Sheng Index 和 Tencent"></a>Heng Sheng Index 和 Tencent</h2><p><img src="/../../images/23-12-31-2023%E4%BA%A4%E6%98%93%E5%A4%8D%E7%9B%98/image-20231231010545633.png" alt="HSI-K线"></p><p><img src="/../../images/23-12-31-2023%E4%BA%A4%E6%98%93%E5%A4%8D%E7%9B%98/image-20231231010912641.png"></p><p>​    好久没做港股了，帮忙大家看看</p><h3 id="1、基本面分析"><a href="#1、基本面分析" class="headerlink" title="1、基本面分析"></a>1、基本面分析</h3><p>​    做港股前有以下几个事实需要知道</p><ul><li>港股真的是低估了，META市盈率31.24，腾讯市盈率13.24。业务类似，腾讯股价在700左右才比较合理。</li><li>外资流动性真的低，真的很不喜欢买港股。</li><li>还有zz风险</li></ul><p>​    综上，目前认为会有反弹，牛市比较难</p><h3 id="2、技术分析"><a href="#2、技术分析" class="headerlink" title="2、技术分析"></a>2、技术分析</h3><ul><li><p>大形态来看，到了价格都到了通道底部，有回调需求</p></li><li><p>但是不尽如人意，HSI在指标倾向上涨的时候选择了盘整，emm</p></li><li><p>今年盘整了一年的筹码，需要时间消化</p></li></ul><h3 id="3、交易计划"><a href="#3、交易计划" class="headerlink" title="3、交易计划"></a>3、交易计划</h3><p><img src="/../../images/23-12-31-2023%E4%BA%A4%E6%98%93%E5%A4%8D%E7%9B%98/image-20231231012110763.png" alt="00700"></p><p>​    <strong>真的不建议交易港股</strong></p><p>​    <strong>除非腾讯价格能这样走，不然真的很难弄</strong></p>]]></content>
    
    
    <categories>
      
      <category>交易</category>
      
    </categories>
    
    
    <tags>
      
      <tag>交易复盘</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>23-11 PDD交易复盘</title>
    <link href="/2023/11/30/%E4%BA%A4%E6%98%93%E5%A4%8D%E7%9B%98/11-30-PDD%E4%BA%A4%E6%98%93%E5%A4%8D%E7%9B%98/"/>
    <url>/2023/11/30/%E4%BA%A4%E6%98%93%E5%A4%8D%E7%9B%98/11-30-PDD%E4%BA%A4%E6%98%93%E5%A4%8D%E7%9B%98/</url>
    
    <content type="html"><![CDATA[<p>  在十月底十一月初的时候，PDD在Q2财报的时候从80块涨到了110块左右，突破两年的高点。<br>  当时感觉这个股票过于强势，随之把它放进了观察列表中。<br>  后面价格强势站上了一个非常关键的位置，于是在11.07 ～ 11.15的时间内不断买入，最后成本控制在110左右，重仓持有PDD&#x2F;</p><p>  <strong>好久没写博客了，长话短说，将就看看吧，反正我看得懂就行。</strong></p><h2 id="PDD"><a href="#PDD" class="headerlink" title="PDD"></a>PDD</h2><h3 id="1、PDD-周K线"><a href="#1、PDD-周K线" class="headerlink" title="1、PDD-周K线"></a>1、PDD-周K线</h3><p><img src="/../../images/11-30-PDD%E4%BA%A4%E6%98%93%E5%A4%8D%E7%9B%98/image-20231202194836668.png" alt="PDD-周K线"></p><ul><li>从30块开始的上涨，形成了一个非常大级别的双重底。第二个底部回测了前方70块的高点（其实当时这里有持仓PDD，但是被打掉了止损）。属于一个不错的支撑。</li><li>PDD的Q1财报非常炸裂，完成了底部第二条腿的上涨，70～110的涨幅，强势，迅速，高支撑。</li><li>Q1财报后，价格一直在100附近停留，<strong>可能很多人害怕追高，但是这确实是一个非常非常高盈亏比的交易</strong><ul><li>止损非常好做</li><li>价格虽然横盘，但是一直在ema上方</li><li>成交量相对较小</li></ul></li></ul><h3 id="2、日线"><a href="#2、日线" class="headerlink" title="2、日线"></a>2、日线</h3><p><img src="/../../images/11-30-PDD%E4%BA%A4%E6%98%93%E5%A4%8D%E7%9B%98/image-20231202200838060.png" alt="PDD-日K线"></p><ul><li>不知道怎么评价，整理区间的日线其实已经强的不行</li><li>上涨成交相对大</li><li>回调不破上涨趋势线，基本在ema附近都能找到买点，反正一个就是强</li></ul><h3 id="3、后续交易计划"><a href="#3、后续交易计划" class="headerlink" title="3、后续交易计划"></a>3、后续交易计划</h3><p>​    坚定持有，除非出现明确的顶部信号，目前上方没啥套牢盘</p><h2 id="HengSheng-Index"><a href="#HengSheng-Index" class="headerlink" title="HengSheng Index"></a>HengSheng Index</h2><p>​    港股最近有点诡异看不懂，但是我会在底部买入一点。</p><h2 id="Nasdaq"><a href="#Nasdaq" class="headerlink" title="Nasdaq"></a>Nasdaq</h2><p>​    纳指也很诡异看不懂</p>]]></content>
    
    
    <categories>
      
      <category>交易</category>
      
    </categories>
    
    
    <tags>
      
      <tag>交易复盘</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>10-20 10月交易复盘 交易计划</title>
    <link href="/2023/10/20/%E4%BA%A4%E6%98%93%E5%A4%8D%E7%9B%98/23-10-20-%E7%BE%8E%E8%82%A1%E5%A4%8D%E7%9B%98/"/>
    <url>/2023/10/20/%E4%BA%A4%E6%98%93%E5%A4%8D%E7%9B%98/23-10-20-%E7%BE%8E%E8%82%A1%E5%A4%8D%E7%9B%98/</url>
    
    <content type="html"><![CDATA[<h2 id="前情回顾"><a href="#前情回顾" class="headerlink" title="前情回顾"></a>前情回顾</h2><p>回顾9.20写的博客。当时对于市场的判断大致是这样子的：</p><ul><li>九月中旬到九月底的下跌，看起来是恐慌下跌。</li><li>在中周期（三个月到六个月）的时间周期内是看涨美股的</li><li>恐慌指数来到了极度恐慌，不管是空头平仓还是多头买入，以及技术分析，纳指都是有上涨的动力的</li></ul><p>基于以上的判断，当时做了三笔交易：</p><ul><li>TQQQ（34.2-36.6）的区间内，进行4次的买入，最后TQQQ成本35</li><li>NVDA（410～425）的区间内，进行买入1.5倍做多NVDA（买入NVDL），成本大概在80</li><li>GOOG（130～140）的区间内，进行买入，忘了具体价格，成本大概在131左右</li></ul><p>当时在旅游，虽然价格在上涨，但是当时嗅到一点反常的味道，于是乎在上周四（10.12）纳指接近趋势线的时候，逐步把仓位全部平仓。获利颇丰，事后来看也是平在了最高的点位。</p><h2 id="NASDAQ"><a href="#NASDAQ" class="headerlink" title="NASDAQ"></a>NASDAQ</h2><h3 id="1、为什么我在TQQQ39块钱的位置平仓"><a href="#1、为什么我在TQQQ39块钱的位置平仓" class="headerlink" title="1、为什么我在TQQQ39块钱的位置平仓?"></a>1、为什么我在TQQQ39块钱的位置平仓?</h3><p><img src="/../../images/23-10-20-%E7%BE%8E%E8%82%A1%E5%A4%8D%E7%9B%98/image-20231021231348004.png" alt="纳指-上一周K线图"></p><p>​    在九月中旬，纳指快速且大幅度下跌到前方低点的时候，开始介入纳指的做多交易。</p><p>​    当时决定做这次交易的理由其实也很简单：</p><ul><li>在前方低点的位置出现下跌停止的行为</li><li>9.27 - 10.02的上涨中，成交量升高，且突破下跌趋势线，证明多头有力量在这个位置克服抛压</li><li>后续的长阴线没有创下新低，而且很快被克服</li><li>在九月底到十月中的底部，明显成交量开始放大，且价格局限在一个箱体内。一定程度说明抛压被克服了</li></ul><p>​    基于上述上述理由，可以认为TQQQ在34～36的价格是在做一个阶段性的底部。不管从<code>空头平仓</code>还是<code>多头在底部吸收筹码延续趋势</code>的</p><p>角度来看，会有一波不错的上涨。<strong>至于是哪种原因引起的上涨，我们需要评估上涨的质量</strong>（在9月week3的时候也提到过，是否平仓苹果也需要衡量它的上涨质量）</p><p>​    在<code>10.06 - 10.12</code>的上涨中，如果仅仅看价格轴出现连续的四高（更高的开盘，更高的低点，更高的收盘，更高的高点），强势无比。<strong>但是很遗憾，成交量却出现持续的走低，量价出现了严重的背离现象，我其实不介意成交量比造底的时候要低，但是成交量一直减少，让我怀疑这次上涨是否能上破这个大级别的下降趋势线。基于保守起见，以及还在旅游，先把仓位平了是比较好的做法</strong></p><p>​    事后来看竟然出在了几乎最好的位置，也是非常幸运</p><h3 id="2、怎么看待纳指接下来的走势"><a href="#2、怎么看待纳指接下来的走势" class="headerlink" title="2、怎么看待纳指接下来的走势"></a>2、怎么看待纳指接下来的走势</h3><p><img src="/../../images/23-10-20-%E7%BE%8E%E8%82%A1%E5%A4%8D%E7%9B%98/image-20231021234015450.png" alt="纳指-日线图"></p><p>​    <code>金融市场中，一个行为需要另外一个行为来确认</code>    </p><p>​    如果不看最新的图表，仅仅从九月底的图来看，如果突破下降趋势线或者前高，这次的上涨就得到了确认了，可以在任何的回调之中加仓，可惜市场并没有给我们这样一个机会。</p><p>​    从九月中旬开始，我希望的行情是怎么样的：</p><p>（1）</p><p>​    纳指从7.19-8.18开始回调，8.18-9.01恢复上涨。</p><p>​    这段回调幅度实在太大了，纳指在这段时间以下跌通道下降了8%，这种幅度是一个中期的调整了。</p><p>​    虽然我相信多头趋势仍在，但是很难直接上涨延续多头趋势，至少要测试这一次下跌的低点。<strong>如果第二次下跌的成交量比较低，说明抛压其实并不重，上涨趋势的秩序并没有改变。</strong></p><p>（2）</p><p>​    第二段下跌迅速完成，在九月week3中提到过，这段下跌更像是恐慌性的卖出。</p><p>​    在九月底到十月初的底部里面，我其实最希望看到的是，成交量的均值比下降时候要低，价格低点高于前方低点。</p><p>​    当时对于市场的判断还是倾向下跌是中期调整，趋势会延续，所以还是在造底吸筹的角度思考。在造底的过程中，通常大资金都不会主动竞价，除非当前价格已经买不到股票了，才会提高收购的价格。<strong>如果出现低成交量，higher low就大大加强吸筹的预期。</strong></p><p>​    可惜市场并没有给出这种最好的底部，<strong>而是另外一种停止形态，高成交量配合阳线较多。</strong>这里说明该位置卖压依然很重，但是多头力量占上风，依然可以做多，但是没有第一种那么确定。</p><p>（3）</p><p>​    造底完成后的上涨，希望是成交量逐渐增加的（可以比造底的时候少，但是希望是跟价格一样，慢慢走高）。成交量组建走高可以说明买入人气的上升，反之则是需求萎靡。</p><p>​    <strong>简单概括，从多头的角度来看，最好的走势就是，下跌缩量，上涨放量，突破趋势线，底部成交量减少。</strong></p><p>​    <strong>如果我们把视角放在空头，那么现在就是最好的走势：</strong></p><ul><li><p>从七月底以来的行情，其成交量明显之前上涨趋势成交量要大很多。</p><ul><li><strong>巨量不涨，也就意味着多方的努力没有结果，是一个上涨趋势停止的信号</strong></li><li>这里甚至隐隐约约有派发的嫌疑，如果派发完成，最强势的交易者就会把底部的支撑撤掉</li></ul></li><li><p>从七月底的调整开始，下跌总是放量的，上涨总是缩量的，从这个级别的周期来看，卖出的力量是远强于买入的力量</p></li><li><p>每次到了底部成交量总是很大，而且SPX500已经创下更低的低点且大幅突破。科技股比较强势，纳指还在支撑位置上</p></li><li><p>到了高点，附近成交量很低，而且高点越来越低。说明已经没有主力资金愿意继续推动价格走高了</p></li><li><p>宏观一坨屎，十年美债突破5%感觉近在咫尺了</p></li></ul><p>​    真是完美的空头背景，到此为止，感觉上涨的背景已经完全被打破。</p><h3 id="3、技术分析-以及-交易计划"><a href="#3、技术分析-以及-交易计划" class="headerlink" title="3、技术分析 以及 交易计划"></a>3、技术分析 以及 交易计划</h3><p><img src="/../../images/23-10-20-%E7%BE%8E%E8%82%A1%E5%A4%8D%E7%9B%98/image-20231022003509021.png" alt="纳指-周线图"></p><p>​    该分析的在上面其实已经说完了，从周线来看下周开始周线要处于ema20下方了，压力特别大。</p><p><strong>交易计划</strong></p><ul><li>目前有5%的三倍做空spx500的仓位，5%做空苹果的仓位</li><li>等待纳指日线回调到ema20附近，会找机会加入纳指做空，仓位大概10%左右</li><li>等待纳指突破支撑，找机会做空纳指，仓位大概7.5%</li><li>大幅度的加仓可能要等支撑位置的突破回调确认，科技股的做空估计要等英伟达的财报后</li><li>如果真要做多，不会抄底，要等到突破趋势线，回调确认再说</li></ul>]]></content>
    
    
    <categories>
      
      <category>交易</category>
      
    </categories>
    
    
    <tags>
      
      <tag>交易复盘</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>09-29 九月交易复盘</title>
    <link href="/2023/09/29/%E4%BA%A4%E6%98%93%E5%A4%8D%E7%9B%98/09-29-%E4%BA%A4%E6%98%93%E5%A4%8D%E7%9B%98/"/>
    <url>/2023/09/29/%E4%BA%A4%E6%98%93%E5%A4%8D%E7%9B%98/09-29-%E4%BA%A4%E6%98%93%E5%A4%8D%E7%9B%98/</url>
    
    <content type="html"><![CDATA[<p>​    week3交易没怎么做，在9.20开始做空纳斯达克指数之后，指数就开始单边下跌。</p><p>​    在week3纳指接近低点的时候，做了一些多仓的部署。</p><h2 id="NASDAQ"><a href="#NASDAQ" class="headerlink" title="NASDAQ"></a>NASDAQ</h2><p><img src="/../../images/09-29-%E4%BA%A4%E6%98%93%E5%A4%8D%E7%9B%98/image-20230929222406859.png" alt="NASDAQ-日线和1小时K线"></p><p>​    按照9月week2的交易部署，在K1前的两根小阳线接近高点的位置开始做空。</p><p>​    然后K2回调到EMA的时候再次加仓。</p><p>​    <strong>这笔空单的逻辑在于，虽然目前仍然看多美股（3个月～6个月），但是七月底的回调如此之大，要延续多头趋势，很大可能需要造底。</strong></p><h3 id="1、技术分析"><a href="#1、技术分析" class="headerlink" title="1、技术分析"></a>1、技术分析</h3><p>（1）从日线级别来看</p><p>​    K1～K4的下跌很强，同时成交量也很大，<strong>在一些技术分析的角度来看，放量下跌似乎是一种空头的趋势</strong></p><p>​    但是在week2的分析中，从中长期的角度来看，仍然是看多美股的，因此在这个位置不太适合去加仓做空，反而选择做多是<strong>数学期望更高</strong>的做法。</p><p>​    虽然K1～K4的下跌速度以及幅度都十分超预期，虽然利空但同时也是问题所在</p><ul><li><p>分析K1～K4下跌中的成交量</p><ul><li><p>成交量虽然在K1～K4中逐渐加大，但是算一下平均值，是不如七月底开始的第一腿下跌。<strong>这里似乎说明了，空头没有看起来那么厉害。</strong></p></li><li><p>从大一点的周期来看，第二次下跌相比第一次是缩小的，也就是意味着低量测试，支撑位置</p></li></ul></li><li><p>分析K1～K4下跌过程中的幅度</p><ul><li><p>下跌幅度太大了，这次下跌似乎是消息驱动的结果，从量价关系来看，<strong>这里更像是恐慌性的卖出</strong>。有人把不准备卖出的货都卖出了，<strong>也就意味着接下来一段时间，市场内的浮动做空力量就会减弱</strong></p></li><li><p>而且刻舟求剑来看，在交易区间内这种区间内的急速下跌，似乎都不是跌破区间的信号，更像是一种吸筹的手段</p></li></ul></li><li><p>从恐慌指数来看，在K4的那一天，恐慌指数已经来到了极度恐慌的程度，也就是说市场来到极度恐慌的时候，这时候可以关注一下是否有入场机会</p></li></ul><p>（2）从小时级别来看</p><ul><li>在红色区域内，急速下跌</li><li>但是急速下跌之后接了一个下行通道<ul><li>一般急速加通道是动能减弱的信号（虽然不是绝对，即使减弱了也应该等待信号才做多）</li><li>在通道中虽然看起来上涨很困难，下跌很轻易。<strong>可是观察每次新低的跌幅，可以看出力量的减弱</strong></li></ul></li></ul><h3 id="2、交易复盘"><a href="#2、交易复盘" class="headerlink" title="2、交易复盘"></a>2、交易复盘</h3><p><strong>记录</strong></p><p>（1）9.22开仓做多</p><p>​    这里是因为，下跌到了第一个支撑位，结合之前的分析，这里做了一次左侧入场的操作。仓位大小在5%左右。</p><p>（2）9.23第一次加仓</p><p>​    这里是因为连续两天阳线，并且两天收盘都在支撑位14678上方。因此加仓，tqqq仓位大小10%</p><p>（3）9.27第二次加仓</p><p>​    这里是因为，K4是一根非常好的信号K线，低点马上收回。加仓，tqqq仓位15%</p><p><strong>复盘</strong></p><p>​    这次左侧抄底从逻辑上来看是ok，但是操作上有两个可以改进的地方。</p><ul><li>在同一个位置交易过多，前两次其实点位很接近，但是仓位到了10%。<ul><li>当时tqqq的成本大概在35.8左右，后面价格一直到了33.9左右，说实话持仓体验并不好</li><li>让后续操作十分受限，仓位过大，在后续更低的点位操作受到限制。</li><li><strong>以后应该吸取这个经验，在特别左的时候，不要在重复位置多次交易</strong></li></ul></li><li>过于激进，这次下跌过程实在太迅速<ul><li>虽然在第一个支撑位，但是恐慌指数也仅仅到了恐慌，没有极度恐慌，这时候可能还会有一定的卖出力量。<strong>因此价格接近最低点的时候，感觉有点被动</strong></li><li>不过做好交易计划应该没啥问题，解决第一个重复下单的问题，持仓体验应该会好很多</li></ul></li></ul><h3 id="3、交易部署"><a href="#3、交易部署" class="headerlink" title="3、交易部署"></a>3、交易部署</h3><ul><li>目前判断买入力量回归<ul><li>价格突破下跌供应线，说明这个位置开始有需求介入，需求增加供应减弱，空头背景开始被削弱</li><li>连续三根K线的三高（更高的低点，更高的高点，更高的收盘），说明买入需求旺盛</li><li>周线EMA20有支撑</li></ul></li><li>买入计划，<strong>不会追高买入，只会在回调中买入</strong><ul><li>毕竟下跌幅度很快，可能需要再一次测试，希望是低量的下跌</li></ul></li></ul><h2 id="NVDA"><a href="#NVDA" class="headerlink" title="NVDA"></a>NVDA</h2><h3 id="1、交易部署"><a href="#1、交易部署" class="headerlink" title="1、交易部署"></a>1、交易部署</h3><ul><li>继续持有多单</li></ul><h2 id="AAPl"><a href="#AAPl" class="headerlink" title="AAPl"></a>AAPl</h2><h3 id="1、交易计划"><a href="#1、交易计划" class="headerlink" title="1、交易计划"></a>1、交易计划</h3><ul><li>等价格回调174左右的时候观望，如果上升很弱，平仓转仓NVDA、TQQQ、META或者GOOG</li></ul>]]></content>
    
    
    <categories>
      
      <category>交易</category>
      
    </categories>
    
    
    <tags>
      
      <tag>交易复盘</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>23-09 09-week2 交易计划</title>
    <link href="/2023/09/10/%E4%BA%A4%E6%98%93%E5%A4%8D%E7%9B%98/09-10-%E4%B9%9D%E6%9C%88%E4%BB%BDweek2%E4%BA%A4%E6%98%93%E8%AE%A1%E5%88%92/"/>
    <url>/2023/09/10/%E4%BA%A4%E6%98%93%E5%A4%8D%E7%9B%98/09-10-%E4%B9%9D%E6%9C%88%E4%BB%BDweek2%E4%BA%A4%E6%98%93%E8%AE%A1%E5%88%92/</url>
    
    <content type="html"><![CDATA[<p>​    </p><h2 id="NADSAQ"><a href="#NADSAQ" class="headerlink" title="NADSAQ"></a>NADSAQ</h2><p><img src="/../../images/09-10-%E4%B9%9D%E6%9C%88%E4%BB%BDweek2%E4%BA%A4%E6%98%93%E8%AE%A1%E5%88%92/image-20230910142140712.png" alt="NASDAQ-周线日线图"></p><h3 id="1、技术分析"><a href="#1、技术分析" class="headerlink" title="1、技术分析"></a>1、技术分析</h3><p><strong>（1）周线角度</strong></p><ul><li><p>从周线级别的角度来看，纳指毫无疑问是多头趋势，多头的结构保留还是很完整。从历史经验来看，经过前面的强力拉升，调整过后应该也还会有等比例的拉升。<strong>也就是说，从中长线的角度（3个月）来看，纳指我是偏向继续涨的。</strong></p></li><li><p>但是目前有个比较大的风险，我倾向指数目前会有第二条腿的下跌</p><ul><li><p>NASDAQ在八月初的回调，可以看到<strong>下跌的幅度是比较大，并且伴随成交量的增加，这里很明显是主力资金平仓&#x2F;空头的卖单在高点挂着</strong>。</p></li><li><p>从0801的回调来看，虽然看上去很强，突破了50%左右的位置，但是总的来看还是不够强势。<strong>因为回调的成交量很明显缩量，而且比出货的成交量低一些。</strong>这里来看的话，主力资金的抄底意愿似乎不是那么足。</p></li><li><p>从0801的回调来看，幅度还是比较大的，一般来说这种情况很少v型反转。目前以周线的角度来看，没做好足够的整理形态。发起新的趋势，似乎还没做好准备。<strong>需要看到第二条腿的下跌。</strong></p></li></ul></li></ul><figure class="highlight"><table><tr><td class="gutter"><div class="code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><pre><code class="hljs">总结：从周线的角度来看，week2倾向看跌，至少是维持震荡<br></code></pre></td></tr></table></figure><p><strong>（2）日线角度</strong></p><ul><li>从0831开始，行情从拉升开始进入了震荡，而且是铁丝网的形态，收了很多根十字星K线。<strong>从形态上来看，这里上升趋势的力量已经不是那么充足了，至少让人怀疑从0825的上涨是否已经停顿。</strong></li><li>震荡调整的位置，处于七月底M头的底部位置，也就是八月下跌的开始。<ul><li>这里几根十字星成交量都缩小，这里买方和卖方的力量都很小。<strong>也就是说，这个位置并没有很多卖压阻拦上涨，但是买方的需求同样也是很少的。</strong></li><li>从0906放量下跌来看，是继续下跌的确认，但是后续的K线都是有比较长的下影线且成交量还是比较大。<strong>这里说明还是有一定的买家在进行抵抗，所以说下跌也不是那么顺利。</strong></li><li>但是从week1-周五收盘的K线来看，买家的力量似乎也没有那么强。</li></ul></li></ul><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs">总结：维持下跌的判断，日线来看确实有一定的多方抵抗，具体怎么走有待商榷<br></code></pre></td></tr></table></figure><h3 id="2、NASDAQ-week2-交易计划"><a href="#2、NASDAQ-week2-交易计划" class="headerlink" title="2、NASDAQ week2-交易计划"></a>2、NASDAQ week2-交易计划</h3><p>​    目前判断下周是下跌，但是有两种可能：（1）价格快速下跌 （2）震荡下跌</p><p><strong>（1）快速下跌</strong></p><ul><li>会现在ema20附近找机会，如果在1小时级别一直收到压制，找机会下破盘整区域加空</li><li>日线希望看到<strong>放量且有效的下跌</strong></li><li>日线希望看到延续性，<strong>两天连续的下跌</strong></li><li>如果周一周二 或者 周二周三能按照这个剧本走，拿好空单，否则找机会平仓</li></ul><p><strong>（2）震荡下跌</strong></p><ul><li>日线毕竟有一定的买压抵抗，而且上方有铁丝网（一般来说都会回测铁丝网测试一下）</li><li>如果下周，日线在<strong>周一周二</strong>回测铁丝网，希望看到以下两种情况之一<ul><li>上涨希望是<strong>缩量的、最好伴随有上影线</strong>。 这种情况可以左侧入场，或者右侧等待放量下跌（一小时级别就行）</li><li>如果上涨放量，那么如果有<strong>长上影线、后续没有力量继续跟进、持续缩量。</strong>这些情况可以考虑和第一种情况一样的入场方式</li></ul></li><li>如果没有上面的剧本，不考虑进场</li></ul><h2 id="TESLA"><a href="#TESLA" class="headerlink" title="TESLA"></a>TESLA</h2><p><img src="/../../images/09-10-%E4%B9%9D%E6%9C%88%E4%BB%BDweek2%E4%BA%A4%E6%98%93%E8%AE%A1%E5%88%92/image-20230910153755347.png" alt="Tesla-周线日线图"></p><h3 id="1、技术分析-1"><a href="#1、技术分析-1" class="headerlink" title="1、技术分析"></a>1、技术分析</h3><p><strong>（1）周线角度</strong></p><ul><li>在之前关于tesla的分析中已经讲过，八月下旬的反弹逻辑，这里就不再讲述了。<strong>到了260的目标位置之后明显上涨停顿了</strong></li><li>目前判断在这个位置tesla有一定的风险积累，<strong>但是仅从这一周的表现来看，tesla是比其他科技股要强的。</strong><ul><li>从299到210的<strong>回调当中，回调是放量的</strong>，但是总体来看这里成交量是略低于最近的均值的。<strong>也就是说，虽然卖压在增加，但是还在一个可以接受的范围内。</strong></li><li>从210开始上涨的三根周线，成交量我算他<strong>略微放量</strong>吧。但这里有一个特别不好的地方，虽然放量，但是后两根K线上影线太长了。<strong>也就是说，上涨过程中买家需求增多，但是成效不太好，卖压并没有消失。</strong><ul><li><strong>（因为这周是短交易周，这周的成交量不好判断）</strong></li></ul></li></ul></li></ul><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs">结论：<br>1、从周线给出的信号来看，空方更胜一筹，多方比较顽强<br>2、从历史的角度来看，这种深幅度的调整，会有第二腿下跌。<br></code></pre></td></tr></table></figure><p><strong>（2）日线角度</strong></p><ul><li>从0829的放量长阳线之后，后面成交量开始减少，涨幅也明显降低。<strong>这里有可能是超买的表现，到了阻力位置没有买压需求跟进，价格停顿。</strong></li><li>0901放量长阴，但是很快被同等力度收回。<strong>从这里开始到周五，多空双方似乎都有点势均力敌的感觉。但是价格高点不断的下降。</strong></li></ul><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs">结论：<br>1、日线目前给到的信息，是双方比较均衡，不好判断<br>2、行情似乎进入了交易区间<br></code></pre></td></tr></table></figure><h3 id="2、TESLA-week2-交易计划"><a href="#2、TESLA-week2-交易计划" class="headerlink" title="2、TESLA week2-交易计划"></a>2、TESLA week2-交易计划</h3><p>​    大方向还是看空的，但是目前这个位置很纠结可上可下，没方向</p><ul><li>目前空单先拿好，在没有明确信号之前仍旧在区间内交易</li><li>做空希望看到上涨乏力的信号，缩量上涨，上影线这种，或者区间内阴线变多</li></ul><h2 id="APPLE"><a href="#APPLE" class="headerlink" title="APPLE"></a>APPLE</h2><h3 id="APPLE-week2-交易计划"><a href="#APPLE-week2-交易计划" class="headerlink" title="APPLE week2-交易计划"></a>APPLE week2-交易计划</h3><ul><li>似乎到了底部，如果看到缩量下跌的话，慢慢抄底买点便宜call</li></ul><h2 id="GOOG"><a href="#GOOG" class="headerlink" title="GOOG"></a>GOOG</h2><h3 id="GOOG-week2-交易计划"><a href="#GOOG-week2-交易计划" class="headerlink" title="GOOG week2-交易计划"></a>GOOG week2-交易计划</h3><ul><li>价格很强势，继续突破前高追call</li></ul><h2 id="HSIndex"><a href="#HSIndex" class="headerlink" title="HSIndex"></a>HSIndex</h2><h3 id="HSIndex-week2-交易计划"><a href="#HSIndex-week2-交易计划" class="headerlink" title="HSIndex week2-交易计划"></a>HSIndex week2-交易计划</h3><p><img src="/../../images/09-10-%E4%B9%9D%E6%9C%88%E4%BB%BDweek2%E4%BA%A4%E6%98%93%E8%AE%A1%E5%88%92/image-20230910155230119.png" alt="恒生指数-日线图"></p><p>​    恒指看法偏空，但是目前不会马上追进去</p><ul><li><p>如果缩量回调到18200附近，考虑空单进场</p></li><li><p>如果追空的话，位置在17800附近，如果能下破这个位置就进场</p></li><li><p>其他时候都是观望</p></li></ul>]]></content>
    
    
    <categories>
      
      <category>交易</category>
      
    </categories>
    
    
    <tags>
      
      <tag>交易复盘</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>23-08 八月份week4交易复盘</title>
    <link href="/2023/09/02/%E4%BA%A4%E6%98%93%E5%A4%8D%E7%9B%98/09-02-%E5%85%AB%E6%9C%88%E4%BB%BDweek4%E4%BA%A4%E6%98%93%E5%A4%8D%E7%9B%98/"/>
    <url>/2023/09/02/%E4%BA%A4%E6%98%93%E5%A4%8D%E7%9B%98/09-02-%E5%85%AB%E6%9C%88%E4%BB%BDweek4%E4%BA%A4%E6%98%93%E5%A4%8D%E7%9B%98/</url>
    
    <content type="html"><![CDATA[<p>​    这周做了很多次交易，一开始大幅盈利。但是后面夜盘时分，恒生指数跳水导致手上的中概也受了不小影响，后面这些仓位出在一个中下的位置。</p><p>​    下面复盘几笔，感觉操作有待改进的交易。</p><h3 id="COIN-77-29-买入"><a href="#COIN-77-29-买入" class="headerlink" title="COIN 77.29 买入"></a>COIN 77.29 买入</h3><p><img src="/../../images/09-02-%E5%85%AB%E6%9C%88%E4%BB%BDweek4%E4%BA%A4%E6%98%93%E5%A4%8D%E7%9B%98/image-20230902163109031.png" alt="coin-08-22 K线"></p><p>​    这笔交易 77.29夜盘开仓，开盘后大幅度跳水，止损位置74.42离场。后续btc的etf方案通过，急速拉升15%。</p><p><strong>买入逻辑</strong></p><ul><li>从周线日线上看<ul><li>前方急速拉升突破盘整了很久的区间，然后进行一个回调</li><li>这次回调处在一个窄幅下行通道，并且一直收到EMA10的压制，空头动能较强</li><li>回调幅度有35%，空头能量还是比较强</li><li>但是到了一个支撑位（区间上沿），<strong>复盘发现回调深度还没到前方w底部</strong></li><li>指标有到了底部且拐头的迹象</li></ul></li><li>从小时级别来看<ul><li>1小时级别来看就，ema即将拐头</li><li>而且突破了左侧的底部，虽然突破幅度不多，<strong>但是K线站上了ema20</strong></li><li><strong>盘前K线大幅度高开，价格来到77</strong></li></ul></li></ul><table><thead><tr><th>有利</th><th>不利</th></tr></thead><tbody><tr><td>回调幅度0.63，且到了区间上方，即将验证支阻互换</td><td>日线下跌窄幅通道，回调深度比较大，说明动能比较强</td></tr><tr><td>日线指标即将拐头</td><td>日线一直受ema10压制，<strong>日线并没有走强的信号</strong>（当前并没有看到ema10和ema20金叉的迹象）</td></tr><tr><td>1小时K线突破左侧w底</td><td>1小时上破后，动能减弱（没有连续走强），有可能会测底部</td></tr><tr><td>1小时K线站上ema20，期望在这里横盘一小段时间，然后突破</td><td></td></tr><tr><td>夜盘大幅度高开</td><td></td></tr></tbody></table><p><strong>交易评价</strong></p><p>1、这里买入逻辑，基本没什么问题。<strong>当时其实也意识到，这里不太可能马上反转，但是到了位置应该会有一个反弹。</strong>跟做纳斯达克的反弹逻辑一样，并没有期望能拿多少</p><p>2、后面这里大幅度跳水，打到止损。这里从价格行为来看，<strong>1小时级别来看更像是突破回踩阻力位置，最后结果来看确实也是这样。</strong></p><p>3、这里在74这个位置果断止损，是因为自己入场价格太高了。<strong>跳水后不清楚日线是否无法突破ema，还是收到压制。对后续行情无法判断。</strong></p><p><strong>思考</strong></p><p>1、<strong>盘前夜盘价格，要小心一点。</strong>比如NVDA当初财报，夜盘价格一度到510，但是后来当天跌幅不小。</p><p>2、控制仓位大小，<strong>可以考虑小仓位介入突破，等突破回调后再加仓进入</strong></p>]]></content>
    
    
    <categories>
      
      <category>交易</category>
      
    </categories>
    
    
    <tags>
      
      <tag>交易复盘</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>08-25 八月中旬交易复盘 week4交易部署</title>
    <link href="/2023/08/25/%E4%BA%A4%E6%98%93%E5%A4%8D%E7%9B%98/08-25-%E5%85%AB%E6%9C%88%E4%BB%BD%E4%BA%A4%E6%98%93%E5%A4%8D%E7%9B%98%E4%BB%A5%E5%8F%8Aweek4%E9%83%A8%E7%BD%B2/"/>
    <url>/2023/08/25/%E4%BA%A4%E6%98%93%E5%A4%8D%E7%9B%98/08-25-%E5%85%AB%E6%9C%88%E4%BB%BD%E4%BA%A4%E6%98%93%E5%A4%8D%E7%9B%98%E4%BB%A5%E5%8F%8Aweek4%E9%83%A8%E7%BD%B2/</url>
    
    <content type="html"><![CDATA[<p>​    这周分析一下几笔交易，其中TQQQ 和 TESLA都达到目标离场。</p><p>​    coin、goog、amzon几笔本来想锦上添花，但是都止损掉了，现在回头来看走的还是挺明智的</p><h2 id="交易一-TQQQ-37-08做多买入"><a href="#交易一-TQQQ-37-08做多买入" class="headerlink" title="交易一: TQQQ 37.08做多买入"></a>交易一: TQQQ 37.08做多买入</h2><p><img src="/../../images/08-25-%E5%85%AB%E6%9C%88%E4%BB%BD%E4%BA%A4%E6%98%93%E5%A4%8D%E7%9B%98%E4%BB%A5%E5%8F%8Aweek4%E9%83%A8%E7%BD%B2/image-20230822200029379.png" alt="08-21 TQQQK线图"></p><p><img src="/../../images/08-25-%E5%85%AB%E6%9C%88%E4%BB%BD%E4%BA%A4%E6%98%93%E5%A4%8D%E7%9B%98%E4%BB%A5%E5%8F%8Aweek4%E9%83%A8%E7%BD%B2/image-20230822200854992.png" alt="08-21 纳指K线图"></p><p><strong>1、技术分析</strong></p><ul><li>从周线级别形态来看，是支持做多的<ul><li>周线来看多头结构没有被破坏，虽然从0801开始，周线开始下跌，并且下破上升趋势线。但是并没有那种很急迫的感觉</li><li>周线回踩该段大行情的0.618位置，预期是有一个反弹</li><li>周线回踩EMA20，也是有做多的预期</li></ul></li><li>从日线来看<ul><li>从纳指期货的日线来看，在0.618位置原来也有低点，在8.18的时候纳指插了一根针，有一点做多预期</li><li>这里其实看指标可以看到，日线的动能有走强的迹象</li></ul></li><li>从小时级别来看<ul><li>纳指期货动能持续走强，指标走强</li><li>最关键的是，<strong>价格站上EMA20，并且没有马上被拉回，形成了一个窄幅交易区间</strong></li><li>红色箭头前的K线，再次拉升确认了一小级别可能会有趋势发生</li></ul></li></ul><p><strong>2、止盈止损分析</strong></p><p>止损分析：</p><p>​    TQQQ这次做多其实在中途平仓一次。8.22的时候股价高开低走，<strong>刚好这个位置是一个阻力位置。而且我的风险偏好是特别不喜欢高开低走的，当日可以下跌，但是大幅度高开低走让我特别没有安全感，因此决定先保存利润。</strong></p><p>​    第二天在39的位置强势突破这个箱体，重新介入波段。</p><p>止盈分析：</p><p>​    这笔订单止盈其实挺难受的，周四价格已经接近最开始的目标位置40.00（红色区域上边缘）。但是当晚英伟达财报，市场当时预期远超预期，怕错错过后续的行情。</p><p>​    但是观测到纳指，<strong>周四收盘的位置已经接近日线EMA20，因此还是决定平仓，在40左右take profit离场。</strong>如果后续能企稳在红色箱体上方在继续介入。</p><p>​    后面行情走势证明我这次的决策是完全正确的，<strong>果然在交易中不要贪心，知道自己是在做反弹还是在做趋势，做出相应的决策</strong>。</p><p><img src="/../../images/08-25-%E5%85%AB%E6%9C%88%E4%BB%BD%E4%BA%A4%E6%98%93%E5%A4%8D%E7%9B%98%E4%BB%A5%E5%8F%8Aweek4%E9%83%A8%E7%BD%B2/image-20230825224406572.png" alt="8-22 平仓位置"></p><p><strong>3、该次交易评价</strong></p><ul><li>开仓逻辑理性，有比较合理的分析。<strong>预期到这个位置会有反弹，但是并没有马上进行抄底，等待有合理的逻辑再进行买入</strong></li><li>平仓优秀，有比较好的风险规避。因为NASDAQ下跌幅度还是比较深的，因此很难会有v反直接上去，及时take profit离场。</li></ul><h2 id="交易二：TQQQ-230901-38-5-buy-put"><a href="#交易二：TQQQ-230901-38-5-buy-put" class="headerlink" title="交易二：TQQQ 230901 38.5 buy put"></a>交易二：TQQQ 230901 38.5 buy put</h2><p>​    这单没啥好说的，周四晚上纳指大跌，无法突破红色box上边缘，直接做空。</p><h2 id="交易三：Coin-77-29做多"><a href="#交易三：Coin-77-29做多" class="headerlink" title="交易三：Coin 77.29做多"></a>交易三：Coin 77.29做多</h2><p><img src="/../../images/08-25-%E5%85%AB%E6%9C%88%E4%BB%BD%E4%BA%A4%E6%98%93%E5%A4%8D%E7%9B%98%E4%BB%A5%E5%8F%8Aweek4%E9%83%A8%E7%BD%B2/image-20230825232253929.png" alt="coin-8-22K线"></p><p>​    这笔交易本来想锦上添花的，但是好在仓位不是很大。</p><p><strong>1、技术分析</strong></p><ul><li>从日线来看<ul><li>前方突破一个整理结构，行情大幅度拉升，回调到了合适的位置</li><li>后面行情走一个下跌回调，虽然阴线很多，但是重叠程度很大，证明下跌很犹豫。</li><li>在前方突破的位置上盘整了两天，且出现了两根阳线</li><li>盘前跳空大涨（价格接近78），阴线前的一根K线，收盘价格是75.28</li></ul></li><li>从1小时级别来看<ul><li>K线下跌动能明显减弱</li><li>盘整慢慢开始处于EMA20上方</li></ul></li><li>从均线指标来看<ul><li>日线被EMA20压制，但是不影响做反弹</li><li>1小时处于EMA20上方，有一定的做多理由。<strong>（但是事后复盘，这里仍然不够强烈，因为再往下级别的ema来看，K线并没有很强烈的上升动能，仍旧是根EMA横盘纠缠）</strong></li><li>日线RSI，MACD都极度超卖，可能会有一定修复动能</li><li>小时级别来看RSI，MACD倒是不错的买入</li></ul></li></ul><p><strong>2、止盈止损分析</strong></p><p>​    当天行情基本高开低走，和TQQQ那天平仓的原因一样。因为跌幅过大，靠近1小时EMA20左右的时候就选择了平仓。</p><p>​    幸好本来的仓位不大，<strong>但是这笔交易没有设置止损，需要手动平仓，有点不好。</strong></p><p><strong>3、评价</strong></p><p>做多条件</p><ul><li>突破后的回调，且下跌不是那么强烈，虽然走了很久</li><li>在突破的位置有支撑</li><li>盘前跳空</li></ul><p>不利条件</p><ul><li>日线指标不行，反弹可能不会很远，需要严格观察</li><li>1小时结构来看EMA效果其实不够强烈</li></ul><p>​    总的来看，这次交易还是比较理性，受大盘影响，及时止损认错认错就行。</p><h2 id="交易四：-GOOG-和-AMZN"><a href="#交易四：-GOOG-和-AMZN" class="headerlink" title="交易四： GOOG 和 AMZN"></a>交易四： GOOG 和 AMZN</h2><p>​    这笔交易其实和COIN止损的订单很像。</p><p>​    除了建仓形态不同，<strong>这里当时因为nv公布了财报，当时纳指走的很强，不想追高nv。于是找了两个大科技中，该轮回调程度较低的两个进行买入。</strong></p><p>​    后面被高开打止损了确实没啥办法，不过这里确实有点担心了，<strong>应该要等待确认nv是否是真突破，等待nasdaq是否真的企稳，才进行后续布局可能比较好。</strong></p><h2 id="八月份week4部署"><a href="#八月份week4部署" class="headerlink" title="八月份week4部署"></a>八月份week4部署</h2><p><strong>总的来说，八月中旬交易还是做的不错的，重仓的都获利，轻仓很多都及时止损。以后可能要更加注意，在反弹中要及时取走利润</strong></p><p><strong>1、nasdaq</strong></p><p><img src="/../../images/08-25-%E5%85%AB%E6%9C%88%E4%BB%BD%E4%BA%A4%E6%98%93%E5%A4%8D%E7%9B%98%E4%BB%A5%E5%8F%8Aweek4%E9%83%A8%E7%BD%B2/image-20230826000734514.png" alt="08-25 纳斯达克K线"></p><p>​    鲍威尔刚在jackson hole发言，纳斯达克上下震荡找不到方向。</p><p>​    在week3的时候，因为种种原因，预测本周开始可能会有反弹。事实上行情也确实如此，<strong>但是周四这跟这么强的阴线，让行情困在了（14700～15300），这里重叠程度较高，估计很有可能会形成箱体震荡。</strong></p><p>​    因此八月份week4的纳指行情看法：</p><p>（1）不会有大级别的拉升，这里的大阴线需要时间消化</p><p>（2）如果下周三前站稳在14700上，</p><ul><li><p>平仓空单</p></li><li><p>布局做多，但不是重仓，目标位在15000点</p></li></ul><p>（3）如果下周三前下破14700，继续持有put</p><ul><li>继续持有空单，看到14200</li></ul><p>（4）目前暂时篇中性，震荡行情，<strong>暂时不会在区间底部追沽</strong></p><p><strong>2、Tesla</strong></p><p><img src="/../../images/08-25-%E5%85%AB%E6%9C%88%E4%BB%BD%E4%BA%A4%E6%98%93%E5%A4%8D%E7%9B%98%E4%BB%A5%E5%8F%8Aweek4%E9%83%A8%E7%BD%B2/image-20230826001657578.png" alt="08-25-TeslaK线图"></p><p>​    本周反弹特斯拉表现太弱，反弹高度不超高0.5，重叠程度太高。week4对特斯拉的看法</p><p>（1）反弹很弱，不适合追高</p><p>（2）收到均线压制，下跌幅度很大，感觉需要时间筑底消化，需要回到21x这个价格附近再看</p><p><strong>3、恒生指数</strong></p><p><img src="/../../images/08-25-%E5%85%AB%E6%9C%88%E4%BB%BD%E4%BA%A4%E6%98%93%E5%A4%8D%E7%9B%98%E4%BB%A5%E5%8F%8Aweek4%E9%83%A8%E7%BD%B2/image-20230826002141571.png" alt="08-25 恒指期货K线图"></p><p>​    反弹无力，貌似形成支阻互换，需要再来1根日线确认。当前价格偏沽，但是担心下方空间有限，考虑周1的价格后再考虑。week4看法</p><p>（1）看阻力17950是否得到确认，确认尝试轻仓做空，目标位置17400左右</p><p>（2）目前看两个重要价位，18200是否确认阻力，确认开空。18500是否确认阻力，确认开空</p><p>（3）站上18500，考虑开多。</p><p><strong>4、FNGU 和 ARKK</strong></p><p>（1）FNGU看法和nasdaq类似，寻找机会介入</p><p>（2）ARKK则和Tesla，但是可以观察一下</p><p><strong>5、其他</strong></p><ul><li>看coin是否在72以上</li><li>AMZN看是否能重新站上EMA20再说</li><li>GOOG看是否跌破EMA20，没有的话找找是否在箱体下有买入形态</li></ul>]]></content>
    
    
    <categories>
      
      <category>交易</category>
      
    </categories>
    
    
    <tags>
      
      <tag>交易复盘</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>23-08 Tesla八月份交易复盘 week3 week4部署</title>
    <link href="/2023/08/18/%E4%BA%A4%E6%98%93%E5%A4%8D%E7%9B%98/23-08%20Tesla%E4%BA%A4%E6%98%93%E5%A4%8D%E7%9B%98%E4%BB%A5%E5%8F%8Aweek3%20week4%E9%83%A8%E7%BD%B2/"/>
    <url>/2023/08/18/%E4%BA%A4%E6%98%93%E5%A4%8D%E7%9B%98/23-08%20Tesla%E4%BA%A4%E6%98%93%E5%A4%8D%E7%9B%98%E4%BB%A5%E5%8F%8Aweek3%20week4%E9%83%A8%E7%BD%B2/</url>
    
    <content type="html"><![CDATA[<h2 id="08-14-Tesla240点-做多"><a href="#08-14-Tesla240点-做多" class="headerlink" title="08-14 Tesla240点 做多"></a>08-14 Tesla240点 做多</h2><p><img src="/../../images/23-08-Tesla%E4%BA%A4%E6%98%93%E5%A4%8D%E7%9B%98%E4%BB%A5%E5%8F%8Aweek3-week4%E9%83%A8%E7%BD%B2/image-20230820161200667.png" alt="Tesla240点K线图"></p><figure class="highlight mathematica"><table><tr><td class="gutter"><div class="code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><pre><code class="hljs mathematica">这次交易发生在<span class="hljs-number">8.14</span>号，<span class="hljs-variable">K1</span>是入场<span class="hljs-built_in">K</span>线，位置大概在<span class="hljs-number">238</span>左右，后面盈亏平衡离场。<br></code></pre></td></tr></table></figure><p><strong>技术分析</strong></p><ul><li><p>从日线来看</p><ul><li><p>自从7.19创下阶段性高点299后，Tesla双顶背离基本已经确立，后面很快进入调整。</p></li><li><p><strong>价格很长一段时间都受到均线压制，在EMA20下方形成箱体。</strong></p></li><li><p>8.7号价格再次下破箱体，但是在<strong>前低240的位置受到比较强的支撑</strong></p></li><li><p>并且回调达到了0.618的位置（240），有一定的反弹需求</p></li></ul></li><li><p>从1小时级别来看</p><ul><li>这段时间，EMA20的压制效果很强，<strong>在入场前图中K线已经四次尝试上破K线</strong>。</li><li>K1区域，最后收盘前仍旧是收到EMA压制，<strong>理性考虑这里应该take profit离场，但是考虑到夜盘没时间操作也比较合理。</strong></li></ul></li><li><p>从均线指标来看</p><ul><li>1小时级别，日线级别EMA都受到压制</li><li>RSI下跌动能还是较强</li><li>MACD快线处于0轴下方，但是有见底的预期</li><li><strong>从这里来看，短期应该不是合适的买入</strong></li></ul></li></ul><p><strong>止损分析</strong></p><ul><li>第二天盈亏平衡就离场，<strong>本来预期能够挑战一下245左右的位置</strong></li></ul><p><strong>这次交易的评价</strong></p><ul><li><p>理性程度中等，从形态来看有一定的买入逻辑，但是不利于做多的逻辑也有，总体来看胜利不会太高，略低于50%。但是止盈止损做得还行，数学期望高于1</p></li><li><p>可能忽视了指标的作用，特别是EMA20。可能大的形态上是没有问题，<strong>但是短期指标不够强。这种情况等等指标是否会更好</strong></p></li></ul><table><thead><tr><th align="center">有利做多的逻辑</th><th align="center">不利做空的逻辑</th></tr></thead><tbody><tr><td align="center">在240低点盘整比较久</td><td align="center">虽然240上盘整，但是价格也是处上方箱体下方</td></tr><tr><td align="center">五月份突破以来的0.618，回调幅度还算可以</td><td align="center">日线EMA压制，价格在线下不利于做多</td></tr><tr><td align="center">补充了前方的一个比较大的缺口</td><td align="center">1小时级别EMA强力压制</td></tr><tr><td align="center"></td><td align="center">RSI指标，MACD都不利于做多</td></tr></tbody></table><h2 id="8m-w3-w4-Tesla交易策略"><a href="#8m-w3-w4-Tesla交易策略" class="headerlink" title="8m-w3-w4 Tesla交易策略"></a>8m-w3-w4 Tesla交易策略</h2><p>先说结论：<strong>（1）下周Tesla大概率有反弹，但是不能过早参与做多，时间大概在周三～周四参与比较稳妥。（2）如果能做多，大概在217～220参与，止损在208，止盈区间大概在240～250左右（3）短期前方下跌空间有限</strong></p><p><img src="/../../images/23-08-Tesla%E4%BA%A4%E6%98%93%E5%A4%8D%E7%9B%98%E4%BB%A5%E5%8F%8Aweek3-week4%E9%83%A8%E7%BD%B2/image-20230820164533156.png" alt="08-18 Tesla收盘周线日线图"></p><p><img src="/../../images/23-08-Tesla%E4%BA%A4%E6%98%93%E5%A4%8D%E7%9B%98%E4%BB%A5%E5%8F%8Aweek3-week4%E9%83%A8%E7%BD%B2/image-20230820164626555.png" alt="08-18 Tesla收盘1小时图"></p><p><strong>分析</strong></p><ul><li><p>从周线来看</p><ul><li>目前形态来到可以支持做多的地方，<strong>前方调整的突破位置（208），该区域积累了大量筹码</strong></li><li><strong>价格回踩到周级别的EMA20</strong>，一下子下破有点不现实，有一定的支撑</li><li><strong>但是MACD形成死叉，RSI回落到50以下。</strong>但是这个不太能影响1～2周的行情</li></ul></li><li><p>从日线来看</p><ul><li>极度超卖，价格远离EMA20太多，有一定的靠近EMA20的需求。<strong>（这个比较中性，短期利多，长期来看利空）</strong></li><li>但是从成交量来看，08-18周五收盘时，<strong>有明显放量。有一点底部止跌反弹的迹象</strong></li></ul></li><li><p>从1小时来看，严重被EMA20压制</p></li></ul><p><strong>我会什么时候参与做多</strong></p><ul><li>周一周二大概率不是马上参与的好机会，日线和1小时的压制效果太强。<ul><li><strong>等待走出如蓝色箭头所示的方向在参与，</strong>等待1小时EMA20靠近，看是否成功企稳，能企稳考虑参与做多</li><li><strong>日线看是否能在白色区间顶部企稳（215）</strong>，企稳2天 或者 突破回踩不进入区间也可以参与</li></ul></li><li>持仓时间大概两根周线，<strong>回到顶部突破的位置（245～260）差不多就要走了</strong>，上方压力很大</li></ul><table><thead><tr><th>有利条件</th><th>不利条件</th></tr></thead><tbody><tr><td>周线级别的均线</td><td>周线指标不好看</td></tr><tr><td>周线级别的支撑</td><td>日线很超卖，动能很强，需要注意回调的高度</td></tr><tr><td>日线有回调到ema的需求，空头应该要take profit</td><td>1小时ema一直被压制</td></tr><tr><td>208～215位置有放量，观察能否站稳</td><td></td></tr><tr><td></td><td></td></tr></tbody></table>]]></content>
    
    
    <categories>
      
      <category>交易</category>
      
    </categories>
    
    
    <tags>
      
      <tag>交易复盘</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>23-08 恒生指数八月份交易复盘</title>
    <link href="/2023/08/18/%E4%BA%A4%E6%98%93%E5%A4%8D%E7%9B%98/23-08-%E6%81%92%E7%94%9F%E6%8C%87%E6%95%B0%E4%BA%A4%E6%98%93%E5%A4%8D%E7%9B%98/"/>
    <url>/2023/08/18/%E4%BA%A4%E6%98%93%E5%A4%8D%E7%9B%98/23-08-%E6%81%92%E7%94%9F%E6%8C%87%E6%95%B0%E4%BA%A4%E6%98%93%E5%A4%8D%E7%9B%98/</url>
    
    <content type="html"><![CDATA[<p>经历七月份的大赚之后，八月份交易很不顺，记录一下这个月的几次交易复盘一下亏损发生的原因</p><h2 id="07-31-恒生指数20300点-突破做多"><a href="#07-31-恒生指数20300点-突破做多" class="headerlink" title="07-31 恒生指数20300点 突破做多"></a>07-31 恒生指数20300点 突破做多</h2><p><img src="/../../images/23-03-%E4%BA%A4%E6%98%93%E5%A4%8D%E7%9B%98/image-20230819181750882.png" alt="08-01的恒指期货图形"></p><p><strong>从图像来分析</strong></p><ul><li>从去年年底的强反弹后，<code>恒生指数</code>一直在走一个回调。回调的结构也相当健康，在走一个楔形收敛三角形的回调，属于bullish flag，倾向看涨</li><li>从日线级别的结构来看<ul><li>几个低点都构成了<code>higher low</code>，高点也构成了<code>higher high</code>，是一个不错的看涨形态</li><li>28号的超大阳线突破了大级别的下降通道线 和 突破了6月23日以来的箱体</li><li><strong>29号市场跳空高开，也是在开盘的时候直接进场</strong></li></ul></li></ul><p><img src="/../../images/23-03-%E4%BA%A4%E6%98%93%E5%A4%8D%E7%9B%98/image-20230819183644246.png" alt="盘中图形"></p><ul><li>从均线以及指标来看<ul><li><code>EMA20</code> 和<code> MA20</code>，在日线级别，1小时级别来说都是支持做多的，价格都是在线上</li><li><code>RSI</code> 和 <code>MACD</code>来说，日线级别的高点和低点都没有出现背离的现象，并且指标所在的区间也是支持做多的。</li></ul></li><li>消息面来分析，<strong>当时国内各种政策吹风，有活跃资本市场的预期</strong></li></ul><p><strong>止损分析</strong></p><p><img src="/../../images/23-03-%E4%BA%A4%E6%98%93%E5%A4%8D%E7%9B%98/image-20230819184750358.png" alt="07-31后续的恒指走势"></p><ul><li>入场K线是K线1前面一根K线(该K线高开低走)，K线1也是走的一个高开低走，但两根K线重叠程度较高<ul><li>但是从盘中的分析，当时对<strong>K1盘中合理的推测</strong>是：小时级别回踩EMA20，再继续一个多头趋势，至少也会测试前高</li></ul></li><li>第二天K2，进行了一个跳空低开<ul><li>在K3的时候，仍有保留市场在EMA20附近横盘的看法</li><li>K4大阴线后，平仓离场</li></ul></li><li>从日线级别的指标来看<ul><li><code>RSI</code>指标从高点回落，<code>MACD</code>也出现拐头</li><li>当时盘内的推演是：（1）多头趋势仍没有被破坏 （2）指标拐头，价格可能要测试几个地方，箱体突破的位置，日线EMA20，日线大级别的下跌通道线</li></ul></li></ul><p><strong>这次交易的评价</strong></p><p>（1）这次交易还是比较理性，有入场逻辑的分析，有严格的止损</p><p>（2）从现在（八月底）来看，这次的消息面刺激是失败的，但是回到八月一号的盘中交易时，是否有过度相信消息面的嫌疑，这里有待商榷</p><p>（3）K1收盘低于昨日低点时，<strong>考虑离场是否会更好，这里也值得思考一下</strong></p><p>（4）在突破追高的时候，可以看到其实有压力位，应该考虑当时的动能是否足够支持一次突破成功。<strong>该次动能，从低点直接拉到高点，做多力量做了一个长途奔袭，即使突破了重要位置，但是要考虑一下是否会在这些地方会有盘整调整。</strong></p><h2 id="08-03-恒生指数19300点-回踩均线做多-part1"><a href="#08-03-恒生指数19300点-回踩均线做多-part1" class="headerlink" title="08-03 恒生指数19300点 回踩均线做多 part1"></a>08-03 恒生指数19300点 回踩均线做多 part1</h2><p><img src="/../../images/23-03-%E4%BA%A4%E6%98%93%E5%A4%8D%E7%9B%98/image-20230819194002010.png" alt="08-03 走势图"></p><p><img src="/../../images/23-03-%E4%BA%A4%E6%98%93%E5%A4%8D%E7%9B%98/image-20230819194127149.png" alt="08-03 恒生指数日线图"></p><p>在这跟日线内做了几次交易，买入，平仓，做T，再买入。但是买入逻辑基本一样，可以当成一次在这个位置不断买入</p><p><strong>图像分析</strong></p><ul><li><p>从期货日线级别的图形来分析，突破前方的箱体后进行了一次价格的回调。</p><ul><li><p>回调回到了三个地方，前方箱体(box1)的上方，下降通道线，日线。<strong>在此时此刻，仍旧偏向前方的下跌是回调，而且在这里买入是很合理的</strong></p></li><li><p>K1回踩到了预期的地方，K2又进行了一个回调但仍旧在该位置进行一个止跌，K3收了小十字星，可以看到价格在这里是有一定的支撑的，<strong>这里形成了一个小型的箱体(box2)。</strong></p></li></ul></li><li><p>从恒生指数来看，虽然逻辑很有力，但是box2内的持仓却不是那么的好受</p><ul><li><p><strong>K1</strong>对应的区域，在收盘前的一段时间多头还是走的比较舒服的，但是碰到了EMA20后，价格遇阻快速下跌。<strong>当天收盘是一个倒锤头阳线。</strong></p></li><li><p><strong>K2</strong>当天跳空高开（在1小时EMA20上），我也马上进场进行了买入。从1小时级别来看，这里试图延续多头力量，但是很快失败，价格持续走低，<strong>收盘回到K1的低点，这里box2其实已经成立。</strong></p></li><li><p><strong>K3</strong>十字星，表示价格在这里是有一定的支撑</p></li></ul></li><li><p>从形态分析</p><ul><li>形态上来看，是有不错的买入逻辑。突破通道线回调，箱体突破回踩支撑都是支撑买入的。</li><li><strong>比较右侧的交易，K2高1买入，也是合理的，但是市场没走出来</strong></li></ul></li><li><p>从均线、指标来分析</p><ul><li>日线EMA20，价格仍然是长时间处于上方，买入是有逻辑的</li><li>1小时EMA20，K1区域第一次挑战均线被打回，K2区域跳空上涨被打回，K3在均线下横盘。<strong>这里的证据并不足以改变回调的看法，但是确实应该要引起一定的注意。</strong></li><li>RSI 和 MACD 都表明了价格进行了一个回调，但MACD形成了一个死叉，但似乎不够强烈</li></ul></li></ul><p><strong>止损分析</strong></p><p>​    这部分先不说，放到下一part</p><ul><li>该箱体的止损放在part2的K1开盘</li></ul><p><strong>这次交易的评价</strong></p><p>​    同上</p><h2 id="08-08-恒生指数19000点-回踩下降通道线做多-part2"><a href="#08-08-恒生指数19000点-回踩下降通道线做多-part2" class="headerlink" title="08-08 恒生指数19000点 回踩下降通道线做多 part2"></a>08-08 恒生指数19000点 回踩下降通道线做多 part2</h2><p><img src="/../../images/23-03-%E4%BA%A4%E6%98%93%E5%A4%8D%E7%9B%98/image-20230819205023014.png" alt="08-08 恒生指数日线"></p><p><img src="/../../images/23-03-%E4%BA%A4%E6%98%93%E5%A4%8D%E7%9B%98/image-20230819205958664.png" alt="08-08 恒指1小时级别"></p><p><strong>从图像分析</strong></p><ul><li><p>从日线级别来看</p><ul><li><strong>K1</strong>，<code>恒生指数</code>9点开盘就跳空下跌，离开了上方小型箱体的区间，<strong>同时对箱体进行了一次止损。</strong>K1收盘后，到达了下降通道线，是一个买入的逻辑</li><li><strong>K2</strong>，从<code>恒指期货</code>的日线来看K1的下破真的很强<ul><li><strong>（因为恒指期货在恒指收盘后还会交易一段时间，但当时并不知道有恒指期货，事后来看在K1的时候并不适合买入）</strong></li><li>K2是K1的inside bar，如果在恒指期货上面来看的话，不适合在K2买入，<strong>如果当时看恒指到期货应该会在K2第二天开盘时候平仓</strong></li><li>K2在恒生指数上面来看倒是走的还不错，是回踩下降通道的一次验证</li></ul></li><li><strong>K3</strong>，十字星。但是价格回到了大型箱体box1内，处于在part1形成的小型箱体box1下方两天。</li><li><strong>K4</strong><ul><li><code>恒生指数</code>收盘时，也是处于下降通道线附近，从这里来看仍有一定的做多条件</li><li>在<code>恒生指数</code>收盘后，<code>恒指期货</code>加速下跌，从这个结构来看，无疑是空头的确立，即使不做空。也不能继续看作简单回调了。可惜当时信息缺失</li></ul></li></ul></li><li><p>从1小时级别来看</p><ul><li><p><strong>K1，K2，K3</strong>，都位于box2下方，且受到均线压制，但是处于通道线上方。</p><ul><li><strong>K1～K3，随着时间推移，这里看多的概率其实是越低的</strong></li><li><strong>因为逐渐形成一个箱体box3处于box2下方，而且受到小时级别均线压制，日线级别也是微微处于均线下方</strong></li><li><strong>看多的条件越来越少了，即使要做可能要放弃一点利润，等价格回到box2再进行操作才比较合理</strong></li></ul></li><li><p><strong>K4</strong></p><ul><li>开盘后试图挑战上方区域，上破均线后无力继续往上，而且很快拉回均线。<code>恒生指数</code>收盘，box3正式确立</li><li><code>恒生指数</code>收盘后，<code>恒指期货</code>加速下跌，很快离开box3</li><li><strong>在K4突破箱体下方后，跌破了预期的一些位置。即使不做空，也不应该做多了，简单调整的看法也应该改变。</strong></li></ul></li></ul></li><li><p>从形态来看</p><ul><li>这里<strong>K1,K2,K3，处于box2下方，受到了压制。</strong></li><li><strong>均线，以及也收回到下方通道线中</strong></li><li>从<code>恒指期货</code>的图形来看，这里属于一个向下突破，然后回踩再突破，比较空头。</li><li>但是好的方面来看，确实是一个突破向下的通道线然后回踩，当前价格也处于一个低点相连的上升趋势线上，有一定的理由做多。</li></ul></li></ul><p><strong>止损分析</strong></p><ul><li>这里K4后面的K线跳空低开，就已经马上进行平仓了，预想中的形态已经完全走坏了</li></ul><p><strong>这次交易的评价</strong></p><p>prat1</p><p>（1）对于这次交易，还是偏理性的，交易还是有逻辑的。价格回踩到均线，在box2（19300～19600）区间中，看多仍然是合理的</p><p>（2）<strong>但是这里操作上有点问题</strong></p><ul><li><code>恒生指数</code>里box2中的K1K2，走的都不太好高开低走，收了两个锤头，而且重叠程度很高。<strong>这里应该就要预期到可能形成一个箱体</strong></li><li>虽然K3后面在底部进行一个抄底，在该位置上看逻辑没啥问题。<strong>但是比较保守的做法是放弃一些利润，至少小时级别上等价格在箱体上方稍微站稳，采取做多（毕竟K1K2收了两个锤头，抄底风险还是偏高，虽然在这个位置看起来没有问题）</strong></li></ul><hr><p>part2</p><p>（1）box3回踩下降通道线，这里的交易理性程度中等，逻辑中等<strong>（有些信息没有考虑到）</strong></p><ul><li>因为从一开始就是倾向看多（higher low，以及一些形态），所以价格到了<strong>box3的时候我仍然偏向看多，但是可能带有偏见，没看到做多逻辑已经越来越弱了。</strong></li><li>价格被box2的箱体压制</li><li>价格被EMA压制了（1小时级别，日级别）</li><li>单靠一个下降通道线突破回踩，不足以支持在box3底部做多，<strong>可能这种情况等待站上均线，突破box3，回到box2在考虑会比较好</strong></li></ul><p>（2）做单考虑的因素不够</p><ul><li><p>忽略了期货，<strong>如果看到恒指期货中，box3中的k1强势下破上方箱体，在该位置做多我会谨慎很多，但是当时缺少这个信息</strong></p></li><li><p>忽视了EMA的作用</p><ul><li><p>box3中日线基本都受到了压制。<strong>只要价格在下方，站不上去，就很难V反，更多时候都是盘整</strong></p></li><li><p>在1小时级别中，价格更是被EMA20压制严重，多次进行挑战，都是很快被收回</p></li></ul></li><li><p>过于放大了趋势线通道线的作用。 <strong>多次严重的支撑阻力位，效果一般最好，其次EMA，趋势线通道线次之</strong></p></li></ul><h2 id="08-14-恒生指数18500点和18000点-测试前方低点做多"><a href="#08-14-恒生指数18500点和18000点-测试前方低点做多" class="headerlink" title="08-14 恒生指数18500点和18000点 测试前方低点做多"></a>08-14 恒生指数18500点和18000点 测试前方低点做多</h2><p>​    这里两笔交易的逻辑都差不多，合并在一起说</p><p><img src="/../../images/23-03-%E4%BA%A4%E6%98%93%E5%A4%8D%E7%9B%98/image-20230820020452500.png" alt="0814～0818 恒生指数"></p><p><img src="/../../images/23-03-%E4%BA%A4%E6%98%93%E5%A4%8D%E7%9B%98/image-20230820020603424.png" alt="0817 恒指期货1小时级别"></p><p><strong>从图像分析</strong></p><ul><li><p>从形态上看，这里其实已经没有什么很强的形态了，没有足够的形态支持价格快速回到20000点</p><ul><li>低点也没有多次验证，形成很好的支撑位置，<strong>只是希望在低点能看到一个小反弹</strong>，仅凭这个就做多了</li><li>在14号低点时，仍旧处于higher low</li></ul></li><li><p>从日线级别来看，也没什么好分析的，<strong>值得一提的是，此刻恒指期货日线级别在看起来很空头，但是当时不知道</strong></p></li><li><p>从1小时级别来看，不管是恒指期货还是恒生指数，K线都是被EMA20压制，一点做多机会都没有</p></li></ul><p><strong>止损分析</strong></p><ul><li>这里的几次止损，都是低点抄底，然后打回盈亏平衡出离场</li><li>但是17号的抄底中，其实是有很大的回撤的，这里其实特别难受</li></ul><p><strong>这次交易的评价</strong></p><ul><li>在前面几次比较有逻辑的交易里面，都没有按照预期进行。<strong>后面就理性程度很低了，企图在一些不太强的支撑位置里面进行一个反弹，以后交易需要克制这种情况</strong></li><li>过于相信消息面了，以后中国市场的消息，除非很大的利好，否则都当拉高出货处理</li></ul><h2 id="从恒指的几笔交易中学到什么"><a href="#从恒指的几笔交易中学到什么" class="headerlink" title="从恒指的几笔交易中学到什么"></a>从恒指的几笔交易中学到什么</h2><ul><li>多注意重叠程度比较高的价格 ，这里很可能会形成箱体，<strong>如果当时行情确实比较犹豫，学会放弃利润，等价格离开箱体后2～3根K线再入场</strong></li><li>多关注各个级别的EMA20，尤其日线和1小时级别<ul><li>顺势中交易，每当回测就是交易机会。如0814的交易中其实日线很难找到做空机会，但是如果看1小时K线，当价格来到均线下方测试，顺势做空就很好</li><li>当价格穿过EMA20，看是否能企稳，才确定方向的选择</li><li>可以在大级别行情中，可以在小级别中找找机会，配合EMA等看看是否有机会交易</li></ul></li><li>斜向的趋势线通道线的效果比较弱，因为这些都是很主观的。支撑阻力以及均线是比较客观的反映</li><li>不要在没有多次验证的低点中寻找支撑，太过危险</li><li>不要逆势回补</li></ul><h2 id="后续交易策略"><a href="#后续交易策略" class="headerlink" title="后续交易策略"></a>后续交易策略</h2><p><img src="/../../images/23-03-%E4%BA%A4%E6%98%93%E5%A4%8D%E7%9B%98/image-20230820023849253.png" alt="当前恒指期货日线图"></p><ul><li><p>暂时不看多，日线下跌有点加速，下方无支撑</p></li><li><p>如果想看反弹，考虑下面这些情况</p><ul><li>日线级别回调是否高于18200点</li><li>日线是否在某个价格区域形成箱体，然后站上箱体</li><li>小时级别的K线不再受到EMA20的压制</li><li>加速减缓，形成双底</li></ul></li><li><p>目前潜在需要关注的区域17600，17200，16900</p></li></ul>]]></content>
    
    
    <categories>
      
      <category>交易</category>
      
    </categories>
    
    
    <tags>
      
      <tag>交易复盘</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>02-17 cpi前后btc交易机会复盘</title>
    <link href="/2023/02/17/%E4%BA%A4%E6%98%93%E5%A4%8D%E7%9B%98/02-17-BTC-%E5%85%AC%E5%B8%83CPI%E5%90%8E%E5%87%A0%E6%AC%A1%E4%BA%A4%E6%98%93%E6%9C%BA%E4%BC%9A%E5%A4%8D%E7%9B%98/"/>
    <url>/2023/02/17/%E4%BA%A4%E6%98%93%E5%A4%8D%E7%9B%98/02-17-BTC-%E5%85%AC%E5%B8%83CPI%E5%90%8E%E5%87%A0%E6%AC%A1%E4%BA%A4%E6%98%93%E6%9C%BA%E4%BC%9A%E5%A4%8D%E7%9B%98/</url>
    
    <content type="html"><![CDATA[<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>当时BTC大涨到21000的时候，并没有走出一个牛旗 或者 ABC调整，而是走出了一个上行的楔形通道，这是一个不太好的现象</p><ul><li>几乎所有上行通道都会测试通道的底部</li><li>如果在牛市中，<strong>跌破通道的上升趋势线后，马上掉头就走向上突破</strong>，这种在牛市中很常见，但是现在不算牛市，只是一个反弹</li><li>因为，走的这个上升结构不是很好，因此看回调，回调的位置在上次多头发力的地方。该位置也是上一个波段高点 20400~21500左右</li><li>市场创出新高失败，然后2月9日下跌测试到21500附近。然后市场在该位置盘整了三天（周末、等待14号CPI）</li></ul><p><img src="/../../images/02-17-eth-%E4%BA%A4%E6%98%93%E5%A4%8D%E7%9B%98/image-20230217222553286.png" alt="当时的市场大背景"></p><h2 id="机会1-趋势回调"><a href="#机会1-趋势回调" class="headerlink" title="机会1 趋势回调"></a>机会1 趋势回调</h2><h3 id="逻辑分析"><a href="#逻辑分析" class="headerlink" title="逻辑分析"></a>逻辑分析</h3><p><img src="/../../images/02-17-eth-%E4%BA%A4%E6%98%93%E5%A4%8D%E7%9B%98/image-20230218154118791.png" alt="CPI公布前后的btc4小时级别K线"></p><ul><li>当时本来已经打算在21500附近进场，但是公布CPI之后，不及预期于是在想第三次创出低点的时候才进场</li><li>CPI公布后，在1小时图表上，马上走出来了一根外包阴线，但是马上被反转，在高级别的图表上来看形成了一根外包阳线</li></ul><h3 id="反思"><a href="#反思" class="headerlink" title="反思"></a>反思</h3><ul><li>做交易，量价行为比宏观基本面的分析更重要。当时看了tw上的一些KOL的分析，影响了自己本来的判断。以后要自动忽略这些。除非价格行为也给出相应的分析</li><li>到了合理的位置，不一定非要高杠杆合约。适当可以用现货，1～3倍杠杆做左侧交易。</li></ul><h2 id="机会2-短线刮头皮"><a href="#机会2-短线刮头皮" class="headerlink" title="机会2 短线刮头皮"></a>机会2 短线刮头皮</h2><p><img src="/../../images/02-17-eth-%E4%BA%A4%E6%98%93%E5%A4%8D%E7%9B%98/image-20230218155538597.png" alt="btc大涨后又一根大阳线创出新高"></p><h3 id="逻辑分析-1"><a href="#逻辑分析-1" class="headerlink" title="逻辑分析"></a>逻辑分析</h3><ul><li><p>BTC强势拉升到24500左右，然后盘整不够充分，以一根大阳线突破了25000（20022.08以来的最高点）。</p></li><li><p>当时分析，这跟阳线不一定代表多头力量强势。</p><ul><li>因为回调时间不够充分，而且从RSI指标已经看出来这次创新高有背离的迹象</li><li>也很有可能时，空头在淡出交易，然后获得一个更好的价格开空</li><li>该次拉升中场内参与做多的交易者，需要一根创新高的大阳线卖空</li><li>在25000被套很久的多头，需要这个位置解套</li></ul></li><li><p>上面这些理由，给了一个短线上的挂头皮机会</p><ul><li><p>然后在下一根K线是阴线，在他的收盘价附近入场。（该K线不是很长，如果很长的话，我可能会考虑是否挂头皮入场）</p></li><li><p>当时在24800开的空单，止损位置放在高点，止盈位置放在了23400（前方的一个波段点）。本来想拿更远的，这么强的上涨趋势，不太合适</p></li><li><p>后面该单完美拿到止盈。</p></li></ul></li></ul><h3 id="反思-1"><a href="#反思-1" class="headerlink" title="反思"></a>反思</h3><ul><li>这次是一个很棒的刮头皮卖空交易，如果发现某些位置有多头解套的机会，可以大胆去逆势挂头皮。</li><li>但是需要注意的是，不要一创新高就马上逆势交易，要等待该次上升的力量停止了，然后看信号K线是否合适入场</li></ul>]]></content>
    
    
    <categories>
      
      <category>交易</category>
      
    </categories>
    
    
    <tags>
      
      <tag>交易复盘</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>01-13 以太坊1410多单复盘</title>
    <link href="/2023/02/07/%E4%BA%A4%E6%98%93%E5%A4%8D%E7%9B%98/01-13-eth-%E4%BA%A4%E6%98%93%E5%A4%8D%E7%9B%98/"/>
    <url>/2023/02/07/%E4%BA%A4%E6%98%93%E5%A4%8D%E7%9B%98/01-13-eth-%E4%BA%A4%E6%98%93%E5%A4%8D%E7%9B%98/</url>
    
    <content type="html"><![CDATA[<h3 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h3><p>1、当时市场大背景很好，美国当时CPI见顶，利好风险资产<br>2、当时eth走了一段很强的趋势，上涨力量明显，日线如下图所示。<strong>这里显示上涨的力量很强，说明多头暂时掌控了市场</strong></p><p><img src="/../../images/01-13-eth-%E4%BA%A4%E6%98%93%E5%A4%8D%E7%9B%98/image-20230208202425920.png" alt="image-20230208202425920"></p><h3 id="开单逻辑"><a href="#开单逻辑" class="headerlink" title="开单逻辑"></a>开单逻辑</h3><p>​    <strong>开单前无非就是思考几个问题，1、市场大背景 2、波段点 3、寻找形态 4、信号K线</strong></p><p>1、市场背景在上面已经分析了毫无疑问的多头趋势，在日线上有大量连续的多头K线，重合程度很小</p><p>2、从日线来看，市场越过1350这个波段点后，继续上涨，并没有回调，明显市场有一种急迫感</p><p>3、这时候，市场在1小时图上，走了一个几乎很完美的双重底</p><ul><li>第一腿下跌的时候，买盘很强劲</li><li>有一根很强的阳线，大幅度突破第一腿下跌，显示了多头的力量</li><li>第二次下跌，在MA30均线处停止了获得了支撑，形成了一个更高低点</li><li>这时候就已经集齐双重底最完美的三个要素，强趋势，强阳线突破，更高低点。很完美的双重顶</li></ul><p><img src="/../../images/01-13-eth-%E4%BA%A4%E6%98%93%E5%A4%8D%E7%9B%98/image-20230208203723957.png" alt="image-20230208203723957"></p><p>4、在1410寻找高2开单，杠杆倍数20（其实直接入场问题也不大）</p><ul><li>入场之后，市场盘整了一段时间，但是没有跌破1400位置</li><li>然后调整完成后，两段急速拉升到1640左右</li><li>后面在回测的过程中分批进行平仓，<strong>总体收益超过200%</strong></li></ul><p><img src="/../../images/01-13-eth-%E4%BA%A4%E6%98%93%E5%A4%8D%E7%9B%98/image-20230208204117539.png" alt="image-20230208204117539"></p><h3 id="反思"><a href="#反思" class="headerlink" title="反思"></a>反思</h3><ul><li>这是一次很完美的双重底，各种分析验证得也是相当正确的</li><li>唯一美中不足可能是当时突破1450的时候可以考虑挂突破单加仓</li></ul>]]></content>
    
    
    <categories>
      
      <category>交易</category>
      
    </categories>
    
    
    <tags>
      
      <tag>交易复盘</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>02-02 以太坊两次交易区间内的交易复盘</title>
    <link href="/2023/02/02/%E4%BA%A4%E6%98%93%E5%A4%8D%E7%9B%98/02-02-eth-%E4%BA%A4%E6%98%93%E5%A4%8D%E7%9B%98/"/>
    <url>/2023/02/02/%E4%BA%A4%E6%98%93%E5%A4%8D%E7%9B%98/02-02-eth-%E4%BA%A4%E6%98%93%E5%A4%8D%E7%9B%98/</url>
    
    <content type="html"><![CDATA[<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p><img src="/../../images/02-02-eth-%E4%BA%A4%E6%98%93%E5%A4%8D%E7%9B%98/image-20230218162930610.png" alt="02-02 eth-日线图"></p><ul><li>当时市场经理一轮上涨，然后到了1500～1650附近，开始进行一个整理，从当时的视角(2月2日)来看，市场显然更有可能是走一个上升的楔形或者交易区间。</li><li>anyway，不管哪种形态，现在可以确定的是，<strong>市场目前在整理，而且处于一个区间的底部位置。</strong></li><li>在这两天做了两笔区间的交易，但是结果不尽人意</li></ul><h2 id="交易一：上升趋势线底部入场"><a href="#交易一：上升趋势线底部入场" class="headerlink" title="交易一：上升趋势线底部入场"></a>交易一：上升趋势线底部入场</h2><h3 id="当时的开单逻辑"><a href="#当时的开单逻辑" class="headerlink" title="当时的开单逻辑"></a>当时的开单逻辑</h3><p><img src="/../../images/02-02-eth-%E4%BA%A4%E6%98%93%E5%A4%8D%E7%9B%98/image-20230218164136725.png" alt="等待二次测试低点，1560入场"></p><ul><li>因为市场处于调整，上涨楔形，或者交易区间。从日线级别来看，当时区间内才走两次上升，有比较大概率还会有一次上涨。</li><li>但是价格到了趋势线附近并没有马上入场，而是等待6:00~18:00这段下行通道，第二次测试下行通道时候进场。</li><li>当通道测试了趋势线后，出现了阳线之后，在这个地方挂了一个高1入场。<ul><li>大概在1560左右开的单，止损在最低点，1540左右。</li></ul></li><li>入场之后，4根K线出现了一根外包阳线</li></ul><p>​    上面就是开单的分析逻辑。开单之后市场顺着我的方向运行，然后出现了外包阳线，当时觉得这是一个很好的信号，加大我对这笔交易的信心。然后当时准备睡觉，就移动止损，把止损挂到了外包阳线底部。</p><p>​    后面行情就如图发展了，直接打掉我的止损，但是没有打掉我最初的止损。</p><h3 id="反思"><a href="#反思" class="headerlink" title="反思"></a>反思</h3><p>​    本来这次开单就已经很保守了，该价位测试了几次之后才进场，但是还是犯了两个错误。</p><ul><li><p>没有坚守交易系统，移动止损应该是行情运行到一定程度后，才移动止损抱住利润。这里刚开始我获利都没多少，维持原来的止损也不会有多少亏损，因为市场有可能再一次下探测试低点。</p></li><li><p><strong>在交易区间的顶部和底部，信号K线的作用降低，特别是高2低2这种，很容易失败。</strong>可能在交易区间中，进行稍微左侧的交易合适一点，因为顶部底部其实多次被测试验证了。</p><ul><li><p>在这里以外包阳线作为信号K线移动止损，事后感觉真的很没必要。</p></li><li><p>就像zyf说的一样，不要关注蝇头小利，多关注波段的收益</p></li><li><p>如果维持原来的判断，获利可能颇丰</p></li></ul></li></ul><h2 id="交易二：区间顶部卖空"><a href="#交易二：区间顶部卖空" class="headerlink" title="交易二：区间顶部卖空"></a>交易二：区间顶部卖空</h2><p><img src="/../../images/02-02-eth-%E4%BA%A4%E6%98%93%E5%A4%8D%E7%9B%98/image-20230218170753109.png" alt="区间顶部卖空"></p><h3 id="开单逻辑"><a href="#开单逻辑" class="headerlink" title="开单逻辑"></a>开单逻辑</h3><p>​    <strong>这应该是我最近一次最破防的交易。</strong></p><ul><li>当时1700是ETH前方的一个波段位置，而且这里刚好是上涨通道的阻力位置，完全有理由做空。</li><li>但是前面的上涨趋势如此强势，因此以太坊到了1700的时候并没有马上卖空，希望等待一个二次确认。</li><li>箭头所指的K线后面，那根外包阴线，一开始是一个很强势的上涨K线<ul><li>但是当该K线逐渐下降的时候，我意识到这里很可能成为一个高点的二次测试</li><li>于是我在箭头K线低点，挂单卖空，希望出现一根外包阴线</li></ul></li><li>这跟外包K线迅速扩大，但是收盘之后马上出现了一根反转阳线。因为当时想睡觉，就把止损挂到1700，最高点附近。<ul><li>因为反转K线后面接着是一根阴线，想着可能继续向下运行，就没管</li></ul></li></ul><p>​    后面行情发展，就很简单了，打到我的止损后马上反转下跌，气死我了…</p><h3 id="反思-1"><a href="#反思-1" class="headerlink" title="反思"></a>反思</h3><ul><li>其实这次交易一开始的开单逻辑也没什么问题，止损也没什么问题。</li><li>事后复盘，<strong>还是感觉在交易区间中信号K线不可靠，</strong>虽然下跌阳线很大，但是后面出现了一样强度的反转，这时候比较明智的做法应该立场观望一下，马后炮来说，出现如此强的反转，说明空头在淡出，可能期待更好的卖空位置。</li></ul>]]></content>
    
    
    <categories>
      
      <category>交易</category>
      
    </categories>
    
    
    <tags>
      
      <tag>交易复盘</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>读论文《In Search of an Understandable Consensus Algorithm》 --- raft (2)</title>
    <link href="/2022/01/10/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%9B%B8%E5%85%B3/detail-of-raft-part-2/"/>
    <url>/2022/01/10/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%9B%B8%E5%85%B3/detail-of-raft-part-2/</url>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>&amp;#8195;&amp;#8195;在上一篇文章里面，介绍了<code>raft</code>定义的一些接口，<code>leader</code>和<code>follower</code>这些身份的一些特性。在下面的文章中，将继续讨论一下<strong>leader的选举的一些细节问题。</strong></p><p>&amp;#8195;</p><!--more--><h2 id="Leader-election"><a href="#Leader-election" class="headerlink" title="Leader election"></a>Leader election</h2><h3 id="什么时候需要选举？"><a href="#什么时候需要选举？" class="headerlink" title="什么时候需要选举？"></a>什么时候需要选举？</h3><p>&amp;#8195;&amp;#8195;<code>raft</code>使用了心跳机制来判断<strong>是否发起一次leader election</strong>。下面来看一下，当集群启动的时候是如何发起第一次选举的。</p><p>&amp;#8195;&amp;#8195;当<code>server</code>启动的时候，他是先处于<code>follower</code>状态的。如果<code>server</code>一直能收到来自<code>master</code>的心跳信号，那么就会一直保持在<code>follower</code>状态。</p><p>&amp;#8195;&amp;#8195;<code>leader</code>会定期发送心跳信号，去跟集群中的其他<code>server</code>进行沟通，通过这样的机制能够有效地保持他们的身份（<code>follower</code>只要收到来自<code>leader</code>的心跳，就一直维持这种状态）。如果<code>follower</code>长时间没有收到这个心跳，那么<code>follower</code>就会认为，<code>leader</code>出现了事故。因此，集群需要选举出一个新的<code>leader</code>维持集群的正常运转。</p><p>&amp;#8195;</p><h3 id="选举的过程"><a href="#选举的过程" class="headerlink" title="选举的过程"></a>选举的过程</h3><p>&amp;#8195;&amp;#8195;某个节点想要发起一次<code>leader election</code>，那么有以下事情需要他去完成。选举的过程如下：</p><p>（1）先给自己投票，并且把自身的<code>currentTerm</code> + 1</p><p>（2）并且把自身的状态设置为<code>candidate</code></p><p>（2）然后<strong>并行地</strong>调用<code>RequestVote RPC</code>，向集群的节点请求投票，并且对回复进行一个统计</p><p>&amp;#8195;</p><p>&amp;#8195;&amp;#8195;以上，就是一次<code>follower</code>发起选举之后需要做的事情，上述这些事情做完之后，就开始等待下面事情发生（其中之一即可）：</p><p>（a）<code>RequestVote RPC</code>统计后，获得过半选票后，赢得了选举</p><p>（b）收到别的<code>follower</code>发来的信息，<strong>声称它已经赢得了选举</strong></p><p>（c）在规定时间内，该次选举（一般来说，以currentTerm来表示第几次选举）并没有成功选出一个<code>leader</code>，就再次发起一次新的选举</p><p>&amp;#8195;</p><p>&amp;#8195;&amp;#8195;情况a，当一个<code>candidate</code>获得过半的选票之后，它就会赢得该次选举，并且向集群中的所有其他机器发送自己赢得选举的信息。在介绍<code>RequestVote RPC</code>接口的时候简单介绍过，<strong>该接口会根据，来者优先的策略，去决定把票投给谁。并且在每次的选举中，每个节点只能投票给其中一人。</strong>（这种投票的策略保障了不会发生重复投票的情况，但是会带来一些其他的问题，放在后面讲）</p><hr><p>&amp;#8195;&amp;#8195;情况b，节点输掉选举。当某个<code>candidate a</code> 在等待选举结果的时候，收到来自别的<code>candidate b</code>发出的<code>heartbeat</code>信号，声称<code>candidate b</code>已经赢得了选举。<strong>如果该心跳信号的<code>currentTerm</code>大于等于<code>candidate a</code>的，那么就认为自己(candidate a)已经输掉了选举，转化为<code>follower</code>状态。</strong></p><hr><p>&amp;#8195;&amp;#8195;情况c，就是在该<code>currentTerm</code>的选举过程中并没有任何一个<code>candidate</code>成功获得过半的选票，赢得选举。<strong>如果在同一时间内，太多follower失去跟leader的连接，成为candidate的话这种情况是有可能发生的。并且会带来大量的无用选举</strong>。因此，我们必须想办法减少这个问题发生的概率。</p><h3 id="选举图示"><a href="#选举图示" class="headerlink" title="选举图示"></a>选举图示</h3><p><a href="https://www.hellodemos.com/algo-animation/raft/index.html">raft -算法流程图解</a></p><h3 id="选举算法其他的一些细节"><a href="#选举算法其他的一些细节" class="headerlink" title="选举算法其他的一些细节"></a>选举算法其他的一些细节</h3><p>&amp;#8195;&amp;#8195;上面对<code>raft</code>的描述，已经大致讲清楚了，<strong>leade是怎么样选举出来的</strong>。但是实际上，该算法仍旧存在一些小问题。下面将讨论一下，会出现哪些事情，并且通过怎样的技巧去解决它们。</p><h4 id="保证日志的持久性"><a href="#保证日志的持久性" class="headerlink" title="保证日志的持久性"></a>保证日志的持久性</h4><p>&amp;#8195;&amp;#8195;我们显然是希望，如果一条日志被<code>leader</code>提交了，即使是以后切换了新的<code>leader</code>，该条日志仍旧会存在于新的<code>leader</code>的日志集中。这显然是理所当然的事情，<strong>但是在上面的算法里，并不能做到这种保证，而是需要添加一些限制条件。</strong></p><p>&amp;#8195;</p><p><strong>我们先来讨论一下，为什么上面讨论的算法，无法做到持久性的保证。如下图所示：</strong></p><p>(1) 一个集群里面，所有节点的日志复制进度都不尽相同</p><p>(2) 此时一个比较落后的节点，率先超时，转变成<code>candidate</code>，并开始向集群其他节点申请票数</p><p>(3) 成功选举成为了<code>leader</code>，并开始新一轮的同步</p><p>(4) 因为，根据复制日志的规则，强制其他所有<code>follower</code>接收<code>leader</code>的日志，因此<code>follower</code>的日志被重写。造成了日志(3,4)的现象</p><p><img src="/../../images/detail-of-raft-part-2/image-20220124220417731.png" alt="日志丢失"></p><p>&amp;#8195;&amp;#8195;因此，为了解决这个问题，在原有的基础上面，还要再多加一个<code>up - to - date</code>规则。什么是<code>up - to - date</code>规则呢？其实很简单，在<code>candidate</code>调用<code>getVotes RPC</code>想要获取票数，<strong>需要额外多传递一些参数，就是<code>candidate</code>最新那条日志的Term和Index。</strong></p><p>&amp;#8195;&amp;#8195;有了这两个参数，<code>follower</code>就能判断，向“我”请求票数的<code>candidate</code>目前，它与原来的<code>leader</code>的进度 和 我跟<code>leader</code>之间的进度，到底谁比较快。如果<code>candidate</code>更快，就选择把票投给它，如果“我”更快，则拒绝投票。这就是<code>up - to - date</code>机制。</p><p>&amp;#8195;&amp;#8195;为什么说这个机制能够保证日志的持久性呢？这我就不详细解释了，提示一下。<strong>在上一篇文章说过，如果一条日志被leader提交，那么绝大多数的节点必然已经提交该日志，再结合刚提到的<code>up - to - date</code>规则，答案就显而易见。</strong></p><p>&amp;#8195;</p><h4 id="确信规则"><a href="#确信规则" class="headerlink" title="确信规则"></a>确信规则</h4><p>&amp;#8195;&amp;#8195;什么是确信规则呢？其实很直白，就是当<code>follower</code>确信自己没有与<code>leader</code>断开连接，或者说<code>leader</code>没有任何问题，仍旧存活。在种情况下，即使有<code>candidate</code>向其进行请求投票，<code>follower</code>都会拒绝该次投票。</p><p>&amp;#8195;&amp;#8195;在我看来，这个规则相当重要，能够避免很多奇奇怪怪的事情发生。加上了这个限制规则之后，有两个好处，下面来说一下。</p><p><strong>(1)避免没有意义的选举</strong><br>&amp;#8195;&amp;#8195;避免整个集群中，只有一个<code>follower</code>与<code>leader</code>断开连接。如果该<code>follower</code>发起一次选举，并且取得选举的胜利，成为了新的<code>leader</code>。这显然是非常不合理的，因为其他的<code>follower</code>与<code>leader</code>的连接都还好好的。这次选举，强行破坏了原有的关系，显然是没有任何实际意义的。</p><p><strong>(2)避免奇怪的事情发生</strong><br>&amp;#8195;&amp;#8195;如下图所示，在(1)的时候，<code>candidate</code>确实是符合<code>up - to - date</code>。但是<code>follower</code>与<code>leader</code>的连接仍旧存活，仍旧能接收到<code>leader</code>发来的日志，那么在(2)的时候，<code>candidate</code>就不是<code>up - to -date</code>了，如果此时它成为了<code>leader</code>那么就不能保证数据的持久性。</p><p>&amp;#8195;&amp;#8195;如果，采用了确信规则，再加上<code>majority rule</code>。那么就能够确保，当这个集群，真的发生了大部分节点都无法取得与<code>leader</code>的联系时，才能成功选举出一个新的<code>leader</code>。并且这种选举，必然不会发现这样的数据丢失情况</p><p><img src="/../../images/detail-of-raft-part-2/image-20220126024631065.png" alt="奇怪的事情"></p><p>&amp;#8195;</p><h4 id="避免分散票数的选举"><a href="#避免分散票数的选举" class="headerlink" title="避免分散票数的选举"></a>避免分散票数的选举</h4><p>&amp;#8195;&amp;#8195;这个其实就很简单了。如果一段时间间隔内，<code>follower</code>节点没有收到来自<code>leader</code>的心跳信号，那么<code>follower</code>会转变为<code>candidate</code>。<strong>问题是，如果该时间间隔都是相同，那么就会出现，同一时间会有大量的<code>candidate</code>出现。造成选票被瓜分，无法出现一个节点赢得绝大部分选票。</strong></p><p>&amp;#8195;&amp;#8195;因此，为了解决这个问题，就是把该时间间隔在合理范围内，设置成随机值。这样就能大大避免，在某一个时刻出现大量的<code>candidate</code>。</p><p>&amp;#8195;</p><h4 id="避免脑裂发生"><a href="#避免脑裂发生" class="headerlink" title="避免脑裂发生"></a>避免脑裂发生</h4><p>&amp;#8195;&amp;#8195;脑裂是什么，相信有对分布式共识算法有一定了解都知道这个问题。那么<code>raft</code>是如何解决这个问题的？简单提示一下，具体我就不描述了<strong>。<code>raft</code>是通过赢得选举的<code>Majority Rule</code>，还有<code>Term</code>，以及<code>Log Matching Property</code>来避免脑裂。</strong></p><p>&amp;#8195;</p><h2 id="Log-replication"><a href="#Log-replication" class="headerlink" title="Log replication"></a>Log replication</h2><h3 id="日志复制的流程"><a href="#日志复制的流程" class="headerlink" title="日志复制的流程"></a>日志复制的流程</h3><p>&amp;#8195;&amp;#8195;<strong>一旦一个节点被选举成为<code>leader</code>，那么该节点就成为了集群的代表，去处理客户端的请求。</strong>我们知道，为了提高可用性，就需要备份master的数据到其他节点上面，<code>raft</code>中用到日志复制这个机制去达成备份数据的目的。下面，我们来讨论一下日志复制这个机制是怎么运作的，以及会遇到什么小问题。</p><p>&amp;#8195;&amp;#8195;<code>leader</code>收到客户端请求后，<strong>会把请求命令，节点当前的term，还有日志的索引</strong>封装成了一个<code>log entry</code>，然后并行调用<code>AppendEntries RPC</code>，向集群中的其他节点追加这条<code>log entry</code>。<strong>当<code>leader</code>确认日志已经成功复制到其他节点上面后（这点很重要，后面细说）</strong>，<code>leader</code>就会把日志提交(committed)，然后把它日志的命令添加到自己的状态机里面，然后再把客户端请求的结果回复给到客户端。</p><p><img src="/../../images/detail-of-raft-part-2/image-20220122133230950.png" alt="image-20220122133230950"></p><p>&amp;#8195;&amp;#8195;<code>logs entry</code>如上图一样在集群中排列，在上面的描述中已经说过了，<code>log entry</code>中包括了 客户端请求的命令，term(该日志是哪个时期的<code>leade</code>发出的)，还有索引（用来定位该log entry在日志中的位置）。</p><p>&amp;#8195;&amp;#8195;日志里面的<code>term number</code>是用来校验<code>follower</code>和<code>leader</code>之间的日志不一致的问题，并且还用来实现之前在part-1文章中说过的几个<code>raft</code>提供的保证，下面来回顾一下：</p><ul><li>Log Matching Property：如果集群中的两条日志具有相同的<code>index 和 term</code>，那么这两条日志就是相同的。</li><li>Leader Completeness Property：如果日志被<code>leader</code>提交了，那么这条日志一定会出现在以后<code>leader</code>中的日志里面。</li></ul><h3 id="leader-commit-机制"><a href="#leader-commit-机制" class="headerlink" title="leader commit 机制"></a>leader commit 机制</h3><p>&amp;#8195;&amp;#8195;<code>leader</code>收到一次客户端请求之后，<code>leader</code>就会调用追加日志的接口把日志追加到其他节点上面。<strong>但是这时候，<code>leader</code>只是把日志缓存起来。但是其他<code>follower</code>节点会直接把日志进行提交。</strong>等到一个<strong>合适且安全</strong>的时候，才会把该日志进行提交(commit)。</p><p>&amp;#8195;&amp;#8195;<code>leader</code>想要追加一个<code>log entry</code>到集群的其他节点，会调用追加日志的接口，当过半的<code>follower</code>成功地把该<code>log entry</code>提交到自己的日志集后。<code>leader</code>就会认为该<code>log entry</code>可以被安全地提交。</p><p>&amp;#8195;&amp;#8195;这个机制，保证了集群节点之间日志的高一致性。而且通过该机制实现了<code>raft</code>保证的<code>Log Matching Property</code>。这个保证主要是两个内容，下面来讨论一下这个：</p><p><strong>1.集群中的两条日志记录，如果具有相同的Index和Term，那么就是该日志记录就存储着同一条命令</strong></p><p>&amp;#8195;&amp;#8195;来分析一下。每一次选举的发生，都会有一个属于该次选举的<code>Term</code>，当选出<code>leader</code>之后，<code>leader</code>就会使用该<code>Term</code>。<strong>也就是说，一个<code>Term</code>只有一个<code>leader</code>。</strong></p><p>&amp;#8195;&amp;#8195;所以，不同<code>Term</code>的<code>Log Entry</code>是不同由不同的<code>Leader</code>发出的，所以必然是不同的日志记录。那么相同<code>Term</code>的日志记录，必然是同一个<code>leader</code>发出的。</p><p>&amp;#8195;&amp;#8195;日志索引(Index)，表示该记录在日志集的位置。那么两条日志，具有相同的<code>Term 和 Index</code>，就是说明该日志记录的本源是在同一个<code>leader</code>日志集里面的，同一个位置。<strong>因此，就是具有同样的命令。</strong></p><p><strong>2.如果不同节点中的两条日志，具有相同的Index和Term。那么这两个节点的日志集里，在该日志记录前的所有记录，都是一致的</strong></p><p>&amp;#8195;&amp;#8195;这个保证是如何实现的？还要结合上面的保证来分析。</p><p>&amp;#8195;&amp;#8195;上面说到相同<code>Term 和 Index</code>的日志记录，实际上是同一条记录。根据<code>AppendEntries RPC</code>它的请求参数包括，<code>leader</code>即将要追加到<code>follower</code>节点的记录(Current Log Entry)的前一条记录(Pre Log Entry)。</p><p>&amp;#8195;&amp;#8195;如果<code>Pre Log Entry</code>在<code>follower</code>节点中存在 &#x2F; 匹配，那么才会在<code>Pre Log Entry</code>后面追加<code>Current Log Entry</code>。否则，就会尝试去先把<code>Pre Log Entry</code>追加到<code>follower</code>上面。如果还不匹配，就继续尝试追加上一条日志记录，直到找到该<code>follower</code>和<code>leader</code>日志集中，<code>Index</code>最大的那条匹配记录。</p><p>&amp;#8195;&amp;#8195;结果就是，当一条日志成功追加到<code>follower</code>上，那么<code>leader</code>就会知道，该日志前的所有记录，跟<code>leader</code>都是一致的。</p><h3 id="leader-crash-机制"><a href="#leader-crash-机制" class="headerlink" title="leader crash 机制"></a>leader crash 机制</h3><h4 id="数据不一致"><a href="#数据不一致" class="headerlink" title="数据不一致"></a>数据不一致</h4><p><img src="/../../images/detail-of-raft-part-2/image-20220122160417302.png" alt="image-20220122160417302"></p><p>&amp;#8195;&amp;#8195;正常情况下，上述操作能够保证<code>leader</code>和<code>follower</code>之间的一致。</p><p>&amp;#8195;&amp;#8195;但是，如果发生了宕机，重新开启了一次选举，那么就很可能会发生数据不一致 &#x2F; 脏数据的情况。下面，就简单什么时候会发生这些，以及<code>raft</code>是通过怎么样的机制去避免这些。</p><p>&amp;#8195;&amp;#8195;比如说，当选举发生了，选举出了新<code>leader</code>。根据赢得选举的规则，我们知道该<code>new leader</code>必然赢得过半的选票。但是在极端情况下，小部分的节点仍旧会与<code>old leader</code>进行连接，此时集群中会存在有两个<code>leader</code>（实际上这不是脑裂，<code>old leader</code>节点的日志必然不会提交，因为无法获得过半的提交成功）。<strong>但是小部分的<code>follower</code>仍旧会接收<code>old leader</code>发出的日志记录，这就会造成数据不一致。</strong></p><p>&amp;#8195;&amp;#8195;就像是上面图中的(e)~(f)都是因为收到<code>old leader</code>发出的日志记录，产生的数据不一致的情况。详细情况我就不细说了，可以自己分析一下便知道。</p><p>​    </p><h4 id="修复不一致"><a href="#修复不一致" class="headerlink" title="修复不一致"></a>修复不一致</h4><p>&amp;#8195;&amp;#8195;如何修复这些日志记录不一致的情况，<code>leader</code>强迫所有<code>follower</code>去接收它的日志，以<code>leader</code>的为准。这就意味着<code>follower</code>接收的<strong>脏记录将要被重写。</strong></p><p>&amp;#8195;&amp;#8195;其实这个机制的实现在上面就已经说过了，通过两个机制<code>up - to -date </code>和<code>Log Matching Property</code>就可以保证。</p><ul><li><code>up - to - date</code>：保证了，已经被<code>leader</code>提交的记录，不会丢。</li><li><code>Log Matching Property</code>：这个机制负责找到<code>Index</code>最大的匹配记录，脏记录 &#x2F; 不一致的记录</li></ul><h2 id="结尾"><a href="#结尾" class="headerlink" title="结尾"></a>结尾</h2><p>&amp;#8195;&amp;#8195;好了，<code>leader</code>选举和日志复制的内容和细节都梳理得差不多。相信都能对<code>raft</code>有更进一步的理解。下一篇文章(如果有的话)，会谈一下<code>raft</code>是如何更新配置的</p>]]></content>
    
    
    <categories>
      
      <category>数据库</category>
      
    </categories>
    
    
    <tags>
      
      <tag>分布式</tag>
      
      <tag>论文</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>读论文《In Search of an Understandable Consensus Algorithm》 --- raft (1)</title>
    <link href="/2022/01/01/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%9B%B8%E5%85%B3/detail-of-raft-part-1/"/>
    <url>/2022/01/01/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%9B%B8%E5%85%B3/detail-of-raft-part-1/</url>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>&amp;#8195;&amp;#8195;最近读了<code>raft</code>共识算法的论文，对其有更深且进一步的理解。<code>raft</code>是一种用来管理复制日志的一致性共识算法。它的作用跟<code>Paxos</code>相同，并且效率差距也不大。但是，<code>raft</code>最大的特点就是容易理解。这才得以让<code>raft</code>在工程实践里面，大规模应用。</p><p>&amp;#8195;&amp;#8195;按照我个人的理解，让一个集群里面的服务器保持一致性或者说达成某种共识，<strong>实质上就是让<code>log/command</code>在所有服务器上都按照同一种顺序被执行。</strong><code>raft</code>为了简化这个设计，参考了<code>gfs</code>选出了一个<code>master</code>，让其他所有服务器都服从<code>master</code>的执行顺序。</p><p>&amp;#8195;&amp;#8195;为了减少复杂性，<code>raft</code>把一致性共识的关键<code>leader选举</code>,<code>日志复制</code>,<code>安全性</code>,<code>集群配置更新</code>，这几部分分割开来。下面的篇幅我们来讨论一下算法的种种细节</p><!--more--><h2 id="一致性共识算法"><a href="#一致性共识算法" class="headerlink" title="一致性共识算法"></a>一致性共识算法</h2><h3 id="规则"><a href="#规则" class="headerlink" title="规则"></a>规则</h3><p>&amp;#8195;&amp;#8195;<code>raft</code>是如何实现一致性共识的？它是通过选举出一个<code>leader</code>，然后让其负责协调集群的日志复制工作。当其他的<code>follower</code>收到日志之后，便可以在合适的时机，把<code>log里面的command</code>作用到自己的状态机里面。</p><p>&amp;#8195;&amp;#8195;上面已经提到过了，跟<code>gfs</code>一样，让一个<code>master</code>协调日志的顺序，这样做会简化很多设计（不然的话要加很多复杂的措施）。<strong>显然，在分布式的系统当中不得不考虑系统的容错性还有网络等问题，这些因素都会造成该集群中<code>leader</code>不可通信的情况。</strong>为了集群的高可用性，这时候就必须选举出一个新的<code>leader</code>。</p><p>&amp;#8195;&amp;#8195;为了达成共识，需要遵守一些规则进行的。</p><h4 id="state"><a href="#state" class="headerlink" title="state"></a>state</h4><p><img src="/../../images/detail-of-raft/image-20220103150743291.png" alt="image-20220103150743291"></p><p>这里的状态是所有在集群里面的<code>server</code>都要有的</p><ul><li><strong>currentTerm</strong>：这里是server存储，目前它已知的最新的term</li><li><strong>voteFor</strong>：当选举发生时，<code>candidate</code>向所有人请求投票，这个标记着投票给哪个<code>candidate</code></li><li>**log[ ]**：就是log-entry，里面的内容包括该条日志包含的command和term(标记该log在哪个term里main生成)还有logIndex(一般情况，这是一个单调递增的)</li></ul><p><img src="/../../images/detail-of-raft/image-20220103151942895.png" alt="image-20220103151942895"></p><p>这里的标识是用来协调日志的:</p><ul><li><strong>commitIndex</strong>：服务器缓存日志的记录，标记该server已经缓存到了哪条日志，<strong>有了该标识方便master发送下一条log</strong></li><li><strong>lastApplied</strong>：标记着最新一条应用到状态机的index</li></ul><p><img src="/../../images/detail-of-raft/image-20220108130032476.png" alt="image-20220108130032476"></p><p><strong>用来维护该发送哪条日志的</strong></p><ul><li><p>nextIndex[ ]：<code>nextIndex[i]</code>表示，要发送给<code>follower(i)</code>的下一条日志，<strong>初始化的值是leader最新的日志+1</strong></p></li><li><p>matchIndex[ ]：<code>matchIndex[i]</code>表示，已经复制到<code>follower(i)</code>的日志，<strong>初始值是0，单调递增</strong></p></li></ul><h4 id="AppendEntried-RPC"><a href="#AppendEntried-RPC" class="headerlink" title="AppendEntried RPC"></a>AppendEntried RPC</h4><p>&amp;#8195;&amp;#8195;这是一个RPC接口，被<code>master</code>调用，用来向<code>follower</code>进行日志的复制，还有进行<code>heart beat</code>。</p><p><img src="/../../images/detail-of-raft/image-20220103154050554.png" alt="image-20220103154050554"></p><p>这里是该函数的入参</p><ul><li><strong>term</strong>：调用RPC接口时，会把leader目前的term传过去</li><li><strong>leaderId</strong>：我也不知道干啥的…后面论文中好像也没看到具体的应用</li><li><strong>prevLogIndex</strong>,<strong>prevLogTerm</strong>：leader追加的该条日志的上一条日志**(下面统一叫prevLog)<strong>他的lndex还有term。</strong>这里是为了实现<code>Log Complete Property</code>**</li><li>**entries[ ]**：跟上面的logEntries[ ]一样</li><li><strong>leaderCommit</strong>：目前leader最新的commit-index</li></ul><p>函数的返回值：</p><ul><li><strong>term</strong>：每次Leader和follower进行交互的时候，都会比较他们的term，这样就能方便互相都能及时进行更新</li><li><strong>success</strong>：表示追加是否成功，这里不想解释了看上面的英文吧</li></ul><p><img src="/../../images/detail-of-raft/image-20220103155638087.png" alt="image-20220103155638087"></p><p>该接口的一些细节：</p><p>（1）如果 <strong>当前<code>server</code>的term大于<code>leader</code>的term(该leader可能是以前的leader)，</strong>那么显然就该拒绝这次追加请求</p><p>（2）如果 <strong>当前<code>server</code>的日志里面没有包含<code>leader</code>的prevLog</strong>，那么就拒接这次追求请求，<strong>并让leader把logIndex-1再进行重试。这样是为了在日志的序列里面找到，<code>follower</code>是从哪条日志开始与<code>leader</code>不一致的。</strong>这个机制保证了，<code>Log Complete Property</code></p><p>（3）如果 追加日志时发生了冲突了，通常情况是同一个Index但是Term不一样，代表其中必然有一个是<code>old leader</code>产生的。因此，要删除<code>old leader</code>产生的还有该日志后面的日志</p><p>（4）<code>follower</code>追加没有缓存的记录，只有prevLog有包含</p><p>（5）这里没想明白为啥要做这个 leader和follower commitIndex的判断，到时候再看看</p><h4 id="RequestVote-RPC"><a href="#RequestVote-RPC" class="headerlink" title="RequestVote RPC"></a>RequestVote RPC</h4><p>&amp;#8195;&amp;#8195;这是一个<code>Candidate</code>调用的接口，用来收集选票来达成leader的选举</p><p><img src="/../../images/detail-of-raft/image-20220103162625445.png" alt="image-20220103162625445"></p><p>接口函数的入参：</p><ul><li><strong>term</strong>：candidate的term，用来辨别是否要响应该投票</li><li><strong>candidateId</strong>：记录投票给谁，对用<code>voteFor</code></li><li><strong>lastLogIndex,lastLogTerm</strong>：candidate最新的log，这个是作用<code>update - to - date</code>机制的，是决定是否投票的限制</li></ul><p>接口的返回值：</p><ul><li><strong>term</strong>：在RPC交互之后，用来更新<code>term</code>的</li><li><strong>voteGranted</strong>：表示调用的<code>candidate</code>是否得到选票</li></ul><p><img src="/../../images/detail-of-raft/image-20220103164055533.png" alt="image-20220103164055533"></p><p>接口得到一些细节：</p><p>（1）跟上面的差不多，这里是为了比较是否是<code>old term</code>,如果是就要拒绝该请求</p><p>（2）如果该<code>follower</code>还没有投票，并且<code>candidate</code>的最新日志比该<code>follower</code>的要大，就证明<code>candidate</code>比<code>follower</code>更加<code>up - to -date</code>，这样把票投给它</p><p><strong>（3）其实不仅如此，还有一个限制。有时候只有一个<code>follower</code>断开了和<code>leader</code>的连接，这时候该<code>follower</code>会成为<code>candidate</code>并发起一次选举。但是别的<code>follower</code>都没有问题。所以，只要别的<code>follower</code>确认<code>leader</code>还在存活，就拒绝该次投票请求。</strong></p><h4 id="Rule-for-server"><a href="#Rule-for-server" class="headerlink" title="Rule for  server"></a>Rule for  server</h4><p><img src="/../../images/detail-of-raft/image-20220108121000192.png" alt="image-20220108121000192"></p><p>（1）是把缓存的<code>log / command</code>添加到状态机的规则，<code>lastApplied</code>表示最新添加到状态机的日志索引，只要缓存索引 &gt; 已经添加的索引，就表示可以继续该过程(add log to state machine)</p><p>（2）如果，收到一个<code>RPC request</code>，该请求中所携带的<code>term</code>比自身服务器记录的<code>term</code>还要大，则证明该服务器可能错过了某些时候的选举过程，因此需要重新设置<code>term</code>还有回到<code>follower</code>状态(如果服务器先前是<code>leader</code>)</p><p><img src="/../../images/detail-of-raft/image-20220108121905228.png" alt="image-20220108121905228"></p><p>（1）<code>follower</code>只会回复来自他们两个的<code>rpc</code>请求，并且<code>follower</code>不会主动调用请求。</p><p>（2）如果某个<code>follower</code>长时间没有收到来自<code>leader的heartbeat</code>，那么<code>follower</code>就会转变成<code>candidate</code>发起一次选举，等待成为<code>leader</code></p><p><img src="/../../images/detail-of-raft/image-20220108122938660.png" alt="image-20220108122938660"></p><p>（1）leader由选举产生，当选出一个leader之后，要发出一个<code>heartbeat</code>来向集群传递，新的<code>leader</code>已经出来了。</p><p>（2）客户端的命令会先转发给<code>leader</code>，然后<code>leader</code>缓存该客户端请求到自己的<code>local log</code>，等到该请求应用到了<code>state machine</code>里面时，便会回复给到客户端。 <strong>(这里这个过程其实还有一点限制，下民的篇幅在展开细说)</strong></p><p>（3）在向<code>follower</code>同步日志的过程里面，如果最新的日志索引 &gt; 要给<code>follower</code>发送的下个日志的索引，那么就发送日志。**如果向<code>follower</code>追加日志失败，证明<code>prvLog</code>并不匹配，因此<code>master</code>会把<code>nextIdx -1 </code>然后重试追加日志的过程。</p><p>（4）如果存在一条日志索引N，N大于leader的commitIndex，且该日志索引N已经存储在大部分服务器上面。那么leader把其commitIndex设置为N。 <strong>(如果加了某个限制条件之后，该情况久不会发生，下面有讲解)</strong></p><h4 id="Five-basic-properties"><a href="#Five-basic-properties" class="headerlink" title="Five basic properties"></a>Five basic properties</h4><p><img src="/../../images/detail-of-raft/image-20220108131654159.png" alt="image-20220108131654159"></p><p>（1）<strong>选举安全性质</strong>：每在一个<code>term</code>中，只有一个<code>leader</code>能够被选出来</p><p>（2）<strong>只有leader能追加日志</strong>：不解释了</p><p>（3）<strong>日志比较规则</strong>：如果两条日志它们的<code>term和index</code>都是一样的话，那么它们就是同一条日志</p><p>（4）<strong>日志完整性</strong>：如果<code>leader</code>中的某条日志已经提交到了某个<code>follower</code>上，那么该条日志前面的所有日志都已经被提交到了<code>follower</code>上，不会出现日志空洞，缺失日志的情况（除非是磁盘问题）</p><p>（5）<strong>状态机的安全</strong>：先不解释，后面会细说</p><h3 id="Raft-Basic"><a href="#Raft-Basic" class="headerlink" title="Raft Basic"></a>Raft Basic</h3><h4 id="奇数节点"><a href="#奇数节点" class="headerlink" title="奇数节点"></a>奇数节点</h4><p>&amp;#8195;&amp;#8195;在一个<code>raft集群</code>中，有一个很重要的原则就是，<strong>集群里面的节点个数必须是基数的，通常情况采用的是3 &#x2F; 5。</strong> 因为只有奇数才能达成<code>majority</code>，偶数就没有这种效果，因为可能出现五五开的场景。</p><p>&amp;#8195;&amp;#8195;在通常情况下，当一个决策（日志的提交，选举leader），只要该决策被大部分的节点承认，那么就可以把结果返回给外界。采用了这种<code>majority</code>的机制，有以下的好处：</p><ul><li>首先，从性能的角度来看，这种<code>majority</code>显然要不等待所有节点同步要高</li><li>其次，因为有<code>majority</code>，这样能够保证在相邻的两次决策，必然存在一个节点都<code>commit</code>了两次决策。</li></ul><p><img src="/../../images/detail-of-raft/image-20220108151256533.png" alt="决策继承"></p><h4 id="节点的三种状态"><a href="#节点的三种状态" class="headerlink" title="节点的三种状态"></a>节点的三种状态</h4><p>&amp;#8195;&amp;#8195;集群的所有节点只处于以下三种状态之一：<code>Follower</code>,<code>Candidate</code>,<code>Leader</code>。并且正常的情况下，只会有一个<code>Leader</code>，并且其他剩余的节点是<code>Follower</code>。</p><p>&amp;#8195;&amp;#8195;在这之中，<code>Leader</code>负责处理所有的客户端请求；<code>Follower</code>只会被动地执行<code>Leader 或 Candidate</code>的rpc请求，并不会自己主动地去做一些其他的事情；<code>Candidate</code>，当某个<code>Follower</code>觉得集群可能出现问题的时候，就会转变进入该状态，发起一次选举，保证系统的正常运转。</p><p>​    下面是，集群的状态机转换，有几个特别的点我们需要注意：</p><p><img src="/../../images/detail-of-raft/image-20220108151102526.png" alt="状态转换"></p><ul><li><code>Follower</code>只会在超时的情况下转变状态，进入<code>Candidate</code>。</li><li><code>Candidate</code>在一次选举中，获得大部分选票，就会成为新的<code>Leader</code>。</li><li><code>Candidate</code>在发现一个大于自己的<code>Term</code>或者是一条声明(某个节点赢得了选举，成为了<code>Leader</code>)，则进入<code>Follower</code>状态。</li><li><code>Leader</code>只有在收到一个更大的<code>Term</code>才会转变状态，变为<code>Follower</code>。</li></ul><h4 id="Term"><a href="#Term" class="headerlink" title="Term"></a>Term</h4><p>&amp;#8195;&amp;#8195;<code>term</code>是一个<strong>逻辑上单调递增的序列</strong>，并且该序列是与<code>Leader election</code>捆绑在一起的，是用来标记着该<code>Leader</code>是由第几次选举产生的。</p><p>&amp;#8195;&amp;#8195;每一次<code>Leader election</code>都会产生一个<code>term</code>，在一次选举中可能会有一个或多个候选人，若是一次选举中某个节点成为了<code>Leader</code>，那么就会用该次选举的<code>term</code>作为<code>ConcurrentTerm</code>，去发送<code>heartbeat</code>让剩余的节点重新成为<code>Follower</code>。</p><p>&amp;#8195;&amp;#8195;但是，一次选举中可能会出现多个候选人，很可能会出现票数被多个候选者平均掉了，因此会出现<strong>没有任何一个节点能够获得大部分的票数。</strong>那么这种情况，要怎么进行处理呢？继续用该<code>Term</code>发起一次选举吗？</p><p>&amp;#8195;&amp;#8195;在<code>Raft</code>中，<strong>允许某次选举中没有选出<code>Leader</code>。</strong>当一次选举因为票数分散导致选举不出一个<code>Leader</code>，它会把<code>term + 1</code>然后重新发起一次选举。在论文中，作者并没有说明为什么要这样做，但是我猜测<code>Raft</code>的设计者是这样考虑的，如果一次再发起一次选举，仍就是使用上一次选举的<code>term</code>的话，那么就无法再次收获票数了。因为<code>Follower</code>已经记录了在该<code>Term</code>的选举中投过票了。</p><p><img src="/../../images/detail-of-raft/image-20220108155012682.png" alt="term divdied"></p><p>&amp;#8195;&amp;#8195;由于篇幅问题，这篇文章就先介绍这些内容。关于<code>Leader election</code>和<code>log replicate</code>的内容放在下一篇文章</p>]]></content>
    
    
    <categories>
      
      <category>数据库</category>
      
    </categories>
    
    
    <tags>
      
      <tag>分布式</tag>
      
      <tag>论文</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>如何保证缓存和数据库双写一致</title>
    <link href="/2021/12/19/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%9B%B8%E5%85%B3/consistency-model-of-db-and-cache/"/>
    <url>/2021/12/19/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%9B%B8%E5%85%B3/consistency-model-of-db-and-cache/</url>
    
    <content type="html"><![CDATA[<p>&amp;#8195;&amp;#8195;最近工作上用到了缓存。用缓存的时候leader让我注意一致性的问题。在调研一下公司常见的双写一致方案，发现大部分方案都不是完美了<strong>（虽然我个人觉得不少方案，其实还是有优化的空间的）</strong>，需要结合实际的使用场景来选择，还是应了那句话<strong>不要抛开场景去谈技术选型</strong>。</p><p>&amp;#8195;&amp;#8195;先说结论：<strong>因为写入数据看和写入缓存，是两个原子性操作(合在一起就不是了)。因此，所有方法只能尽量避免数据的不一致，总会在极端的情况下有数据不一的情况发生，要想完全避免这事，那只能依靠事务了。</strong></p><!--more--><h2 id="常用的解决数据不一致的方案"><a href="#常用的解决数据不一致的方案" class="headerlink" title="常用的解决数据不一致的方案"></a>常用的解决数据不一致的方案</h2><p>​        先来简单了解一下，三种比较常见解决“缓存-数据库一致性”的方案。</p><h3 id="缓存旁路模式"><a href="#缓存旁路模式" class="headerlink" title="缓存旁路模式"></a>缓存旁路模式</h3><p>&amp;#8195;&amp;#8195;缓存旁路模式，<strong>是最常用的保证双写一致的模式</strong>，对于数据的读取和更新有两种不同的流程。</p><p><strong>对于读取数据：</strong></p><figure class="highlight scss"><table><tr><td class="gutter"><div class="code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></div></td><td class="code"><pre><code class="hljs scss">(<span class="hljs-number">1</span>)先从缓存中查询，判断缓存是否命中 <br>(<span class="hljs-number">2</span>)如果缓存命中的情况下，直接返回数据给到client <br>(<span class="hljs-number">3</span>)如果缓存没有命中，就从db里面读取数据，顺带把该key设置到缓存里面。<br></code></pre></td></tr></table></figure><p><img src="/../../images/consistency-model-of-db-and-cache/image-20211219151501236.png" alt="Cache-Aside-Pattern"></p><p><strong>对于写数据（插入&#x2F;更新）:</strong></p><p>&amp;#8195;&amp;#8195;写流程就简单一些了，只需要插入的时候，<strong>先操作数据库，然后再删除缓存就好了</strong>。</p><p><img src="/../../images/consistency-model-of-db-and-cache/image-20211219152053846.png" alt="image-20211219152053846"></p><h3 id="读写穿透"><a href="#读写穿透" class="headerlink" title="读写穿透"></a>读写穿透</h3><p><img src="/../../images/consistency-model-of-db-and-cache/image-20211219153932201.png" alt="image-20211219153932201"></p><p>&amp;#8195;&amp;#8195;这里他只是<strong>把缓存作为主要的存储单位，抽象了一个chache provider服务，该服务负责缓存的存储，以及后续与数据库的交互交给缓存去进行处理，这对客户端来说是不感知的，看起来只是简单地调用了一下缓存。</strong></p><p><strong>读流程</strong></p><ul><li>从缓存中读取</li><li>如果缓存命中，返回结果给调用者</li><li>如果缓存不命中，则缓存发送请求，到数据库中请求数据，然后缓存再返回给调用者</li></ul><p><strong>写流程</strong></p><ul><li>缓存命中，则更新缓存，然后缓存同步去更新数据库</li><li>缓存没有命中，则直接更新数据库</li></ul><p><strong>这个解决方案，很多地方都跟CAP一致，但是最大的不同点在于读写传统在更新的最后没有对缓存中的记录进行删除。这个我个人觉得有一些问题，后面的篇幅再细说。</strong></p><h3 id="异步缓存写入"><a href="#异步缓存写入" class="headerlink" title="异步缓存写入"></a>异步缓存写入</h3><p>&amp;#8195;&amp;#8195;这个方案，跟读写穿透很像，两者都是通过抽象的cache provider服务，对db进行交互。</p><p>&amp;#8195;&amp;#8195;但是又有很大的不同，读写穿透或者是缓存旁路，都是<strong>同步地对数据库进行更新，而该方案则不直接更新数据库，而是批量去更新数据库。</strong></p><p>&amp;#8195;&amp;#8195;这跟kafka一样，带来的吞吐率的提升，但是带来的一些一致性问题。</p><h2 id="要考虑的问题"><a href="#要考虑的问题" class="headerlink" title="要考虑的问题"></a>要考虑的问题</h2><h3 id="Q-删除缓存，还是更新缓存"><a href="#Q-删除缓存，还是更新缓存" class="headerlink" title="Q:删除缓存，还是更新缓存"></a>Q:删除缓存，还是更新缓存</h3><p>&amp;#8195;&amp;#8195;目前为止，大家都比较不喜欢更新缓存的方案，因为在高并发的场景之下，很容易出现数据不一致的问题的问题。我们假设是在“先更新db，再更新缓存”的方式下进行双写看看会发生什么样的问题。</p><p>&amp;#8195;&amp;#8195;假设，现在有两个请求要对同一个记录进行更新。我们希望db和cache这两个收到<strong>记录更新的顺序是一致的（比如说，都是先收到请求1再收到请求2，或者先收到请求2再收到请求1）</strong>，但是因为网络等其他原因，最后的顺序很可能跟我们理想情况不太一样，如下图：</p><p><img src="/../../images/consistency-model-of-db-and-cache/image-20211226174711210.png" alt="image-20211226174711210"></p><p>&amp;#8195;&amp;#8195;从图片中我们可以看到，因为db和cache他们收到请求的顺序不一样，因此造成了最后<strong>db中的数据是1，cache中的数据是2。</strong></p><p>&amp;#8195;&amp;#8195;更新缓存的方案，有概率比较大的概率导致数据不一致的情况发生。因此，比较多人喜欢用删除缓存来代替更新缓存。（毕竟删除肯定不会带来数据不一致的问题，因为删了就没有了嘛）</p><p>&amp;#8195;&amp;#8195;虽然如此，我个人觉得这个数据不一致的本质上是<strong>一种写冲突</strong>，因此实际上还是有不少方案来解决这个数据不一致的问题，我想了一下，大致有以下解决方案：</p><ul><li>last writer win</li><li>lamport时间戳</li><li>版本向量</li><li>仿照读写穿透跟rocketMQ，来保证请求的顺序</li></ul><p>​        至于为什么会选择删除缓存这种方案，我想这可能是最简单有效的吧。解决写倾斜，在这个场景中似乎没有带来性能的提升</p><h3 id="Q-先操作数据库，还是先操作缓存"><a href="#Q-先操作数据库，还是先操作缓存" class="headerlink" title="Q:先操作数据库，还是先操作缓存"></a>Q:先操作数据库，还是先操作缓存</h3><p>&amp;#8195;&amp;#8195;在<code>Cache-Aside-Pattern</code>中，是先操作数据库。但是在<code>读写穿透</code>的方案中，选择了先操作缓存，再同步修改db。下面，我们讨论一下这两种选择，会有什么样的问题。</p><p><strong>(1)先操作数据库，再操作缓存</strong></p><p>&amp;#8195;&amp;#8195;这种操作其实并没有特别大的问题，只是在某些情况下会发生一些小小的数据不一致问题。</p><p><img src="/../../images/consistency-model-of-db-and-cache/image-20211226191330592.png" alt="image-20211226191330592"></p><p>&amp;#8195;&amp;#8195;两个请求，请求1进行数据库的更新，如果缓存还没更新的情况下。请求2，发出了一个读请求，并且快速返回数据给调用者，那么就返回的是一个旧数据。</p><p>&amp;#8195;&amp;#8195;其实这个问题并没有什么大不了的，<strong>因为网络问题，导致数据更新不及时而已，数据总是会收敛到一致的，甚至连client也不知道自己拿到的数据是旧数据</strong>。</p><p>&amp;#8195;&amp;#8195;但是，如果请求1和请求2是同一个client发出的，那么client就会十分困惑了。</p><p><strong>(2)先操作缓存，再操作数据库</strong></p><p>&amp;#8195;&amp;#8195;这种方式我感觉，会带来比较严重的数据不一致问。我们还是假设有两个请求，如下图所示：</p><p><img src="/../../images/consistency-model-of-db-and-cache/image-20211226195010407.png" alt="image-20211226195010407"></p><p>&amp;#8195;&amp;#8195;一个写请求进行对记录进行更新，它删除缓存之后，马上来了一个读请求，此时cache中并没有数据，因此这个读请求需要到db里面请求数据。从db中拿到数据之后，需要把数据设置到缓存里面。<strong>那么此时，就出现了缓存是旧值，数据库是新的值。这种数据不一致还是比较严重的。我想这种操作，需要在缓存设置存在时间。</strong></p><p>​    我认为，<strong>如果采用删除缓存方案的话，应该要把操作缓存的步骤放到最后。</strong>不然就会出现上面的情况了。</p><p>​    那么为什么<code>读写穿透</code>没有这种问题，其实我觉得有以下原因：</p><ul><li>因为这时更新缓存，不是删除缓存。这样如果有读请求过来的话，它会访问到缓存，并直接返回数据。并不会走到db</li><li>因为请求都是统一由<code>cache provider</code>进行管理。因此，完全有能力去管理这个请求的先后顺序。</li></ul><p><strong>(3)双删</strong></p><p>&amp;#8195;&amp;#8195;这种，其实是为了针对情况(1)的不足而设计的。在该情况下，因为更改了数据库之后，还没更新数据库。<strong>这时读请求过来了，但是这个请求就会被，存储了旧数据给打发走了。</strong></p><p>&amp;#8195;&amp;#8195;因此，双删这种策略，<strong>就是在修改db之前，先进行一个缓存删除的操作</strong>。如果是用<code>Cache - Aside - Pattern</code>模式，先进行db的操作然后再对缓存中的数据进行删除。那么此时会出现一个小小的数据不一致的问题，<strong>比如说更新数据库成功后，缓存还没来得及删除，此时一个读操作就会被旧的缓存打回去，会读到旧的值，与db不太一致。</strong></p><p>&amp;#8195;&amp;#8195;因此，多了双删这种策略。但是，其实在非常极端的情况下依旧会出现数据不一致的情况发生。</p><p>​    </p><h2 id="思考"><a href="#思考" class="headerlink" title="思考"></a>思考</h2><p>&amp;#8195;&amp;#8195;上面说的三种缓存使用模式，实际上都会有或多或少的<code>缓存 - 数据库 不一致</code>的问题。<strong>归根结底还是那个问题，因为操作数据库和操作缓存合起来不是一个原子性的操作，因此总会有一个时间点让数据不是自洽的，会发生不一致问题。</strong></p><p>&amp;#8195;&amp;#8195;可能是因为分布式系统，很难实现类似<code>MVCC</code>的机制因此数据很难在一次“事务中”是自洽的。又或者说，实现分布式事务的性能开销实在是太大了。</p><p>&amp;#8195;&amp;#8195;总之呢，这三种方案还是要结合场景来使用的。不过我个人用的比较多的还是<code>Cache - Aside - Pattern</code>模式。其实，在我们大多数的使用场景中，缓存都是读多写少更新少。因此，大多是情况下放入缓存的数据都是更新频率很低的数据，导致极端的数据不一致的情况发生。还有，我们应该要防止<strong>”数据库是新值，缓存是旧值“</strong>的情况发生，因为这样该记录的缓存很长时间内都不会发生修改，会一直返回给调用方错误的值。<strong>因此，我觉得大多数读为主的场景，可以考虑该方案。</strong></p>]]></content>
    
    
    <categories>
      
      <category>数据库</category>
      
    </categories>
    
    
    <tags>
      
      <tag>分布式</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>《the MapReduce》 --- lab1</title>
    <link href="/2021/12/05/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%9B%B8%E5%85%B3/mit6-824-lab1-the-mapReduce/"/>
    <url>/2021/12/05/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%9B%B8%E5%85%B3/mit6-824-lab1-the-mapReduce/</url>
    
    <content type="html"><![CDATA[<p>&amp;#8195;&amp;#8195;最近稍微有空，就把割了很久的lab1给做了。在做的过程中磕磕碰碰，碰到了不少坑但是也总结了不少经验。感觉对日常的工作还是有不少帮助的，下面就来介绍本次的lab1。</p><!--more--><h2 id="MapReduce"><a href="#MapReduce" class="headerlink" title="MapReduce"></a>MapReduce</h2><p>&amp;#8195;&amp;#8195;简单来说MapReduce就是把一个大任务，拆成若干个小的任务。然后把这些任务分发到不同的worker(服务器)上面去运行，然后再把他们执行的结果聚拢到一起，回复给外界。</p><p>&amp;#8195;&amp;#8195;至于原理是什么我就不多说了，有兴趣的可以看看Jeff Dean的论文。 <a href="http://nil.csail.mit.edu/6.824/2020/papers/mapreduce.pdf">【the MapReduce】</a></p><p>&amp;#8195;&amp;#8195;下面来介绍，如何实现一个简单的MapReduce，这里只介绍master是如何设计，该lab我做下来，感觉最大的难点是在于如何维护metadata。至于worker的设计倒没有什么特别的地方。</p><h2 id="Master-Task相关的数据结构"><a href="#Master-Task相关的数据结构" class="headerlink" title="Master,Task相关的数据结构"></a>Master,Task相关的数据结构</h2><p>​    关于task（map和reduce），其实不难，仅需要把关于task的信息都抽象出来即可。如下</p><figure class="highlight golang"><table><tr><td class="gutter"><div class="code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></div></td><td class="code"><pre><code class="hljs golang"><span class="hljs-keyword">type</span> MapTaskInfo <span class="hljs-keyword">struct</span> &#123;<br>MapTaskSeq                <span class="hljs-keyword">int</span><br>MapTaskState              <span class="hljs-keyword">int</span><br>MapTaskStartTimeStamp     <span class="hljs-keyword">uint64</span><br>MapTaskAssignedWorkerId   <span class="hljs-keyword">uint64</span><br>InputFilePathLocation     <span class="hljs-keyword">string</span><br>IntermediateFileLocation  []<span class="hljs-keyword">string</span><br>&#125;<br><br><span class="hljs-keyword">type</span> ReduceTaskInfo <span class="hljs-keyword">struct</span> &#123;<br>ReduceTaskSeq                 <span class="hljs-keyword">int</span><br>ReduceTaskState               <span class="hljs-keyword">int</span><br>ReduceTaskStartTimeStamp      <span class="hljs-keyword">uint64</span><br>ReduceTaskAssignedWorkerId    <span class="hljs-keyword">uint64</span><br>InterMediatePathLocationList  []<span class="hljs-keyword">string</span><br>OutputFilePathLocation        <span class="hljs-keyword">string</span><br>&#125;<br><br><span class="hljs-comment">// 枚举量</span><br><span class="hljs-keyword">const</span>  (<br>MAP_TASK_STATE_INIT    = <span class="hljs-number">0</span><br>MAP_TASK_STATE_RUN     = <span class="hljs-number">1</span><br>MAP_TASK_STATE_FINISH  = <span class="hljs-number">2</span><br>)<br><br><span class="hljs-keyword">const</span>  (<br>REDUCE_TASK_STATE_BLOCK    = <span class="hljs-number">-1</span><br>REDUCE_TASK_STATE_INIT     = <span class="hljs-number">0</span><br>REDUCE_TASK_STATE_RUN      = <span class="hljs-number">1</span><br>REDUCE_TASK_STATE_FINISH   = <span class="hljs-number">2</span><br>)<br></code></pre></td></tr></table></figure><ul><li><strong>TaskSeq</strong>:task的序列号，用来区分不同的task</li><li><strong>TaskState</strong>:用来描述每个task的状态</li><li><strong>TaskStartTimeStamp</strong>：master每次分发一个task之后，都会记录该task的分发时间，用于后续的超时判断</li><li><strong>TaskAssignedWorkerId</strong>：记录该task被分发到哪个worker上，这个字段和时间戳有助于提高系统的容错</li><li><strong>InputPath和OutputPath</strong>：用来记录文件读取，和文件输出的路径</li></ul><p>&amp;#8195;&amp;#8195;这里解释一下，<strong>为什么reduce的状态枚举量比map多了一个BLOCK状态。</strong>因为，reduce的输入文件，是map的输出。因此，只有某个reduce的输入数据都准备好之后，它才能够运行。因此，在此之前它都是阻塞状态。</p><p>&amp;#8195;&amp;#8195;下面就是master的数据结构，在我实现的lab中，所设计的Master的数据结构参考了GFS里面的master。<strong>master存储着整个集群的控制信息，以及提供任务分发的接口。</strong></p><p>&amp;#8195;&amp;#8195;这是我一开始设计的Master结构体。</p><figure class="highlight golang"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs golang"><span class="hljs-comment">// 1.最初设计的Master</span><br><span class="hljs-keyword">type</span> Master <span class="hljs-keyword">struct</span> &#123;<br><span class="hljs-comment">// Your definitions here.</span><br>initMapTaskTable          List.list<br>  processMapTaskTable       List.list<br>  doneMapTaskTable          List.list<br>  <br>  initReduceTaskTable.      List.list<br>  processReduceTaskTable    List.list<br>  doneReduceTaskTable       List.list<br>&#125;<br><br><span class="hljs-comment">// 2.后面设计的Master</span><br><span class="hljs-keyword">type</span> Master <span class="hljs-keyword">struct</span> &#123;<br><span class="hljs-comment">// Your definitions here.</span><br>tableMapTask      <span class="hljs-keyword">map</span>[<span class="hljs-keyword">int</span>]*MapTaskInfo<br>mapNum            <span class="hljs-keyword">int</span><br>tableReduceTask   <span class="hljs-keyword">map</span>[<span class="hljs-keyword">int</span>]*ReduceTaskInfo<br>reduceNum         <span class="hljs-keyword">int</span><br>&#125;<br></code></pre></td></tr></table></figure><p>先说一下这两种设计各有什么优劣之处。</p><p><strong>(1)从任务分发的角度来看</strong></p><p>&amp;#8195;&amp;#8195;第一种设计，采用了三个队列来存储不同状态的task，<strong>这样就导致分发task的效率会很高，如果想要把一个空的task分发出去，直接从INIT状态的队列中直接取出来，效率很高，复杂度在O(1)。</strong></p><p>&amp;#8195;&amp;#8195;但是，做出同样的操作第二种设计却需要O(n)的时间复杂度。</p><p><strong>(2)从数据的完整性来看</strong></p><p>&amp;#8195;&amp;#8195;在这个角度来看，第一种设计的数据持久型做的不够好，我觉得它其实跟“分布式”有一点点像，<strong>在极端的情况下会数据丢失的。</strong></p><p>&amp;#8195;&amp;#8195;第二种结构，所有状态的task都用一个表来进行管理，这种又有点像”单机“，它的原子性和持久性能达到比较好的保障。</p><p>&amp;#8195;&amp;#8195;这个的具体原因，在下面的<strong>任务分发接口</strong>中会提及。</p><h2 id="Master的接口"><a href="#Master的接口" class="headerlink" title="Master的接口"></a>Master的接口</h2><p>&amp;#8195;&amp;#8195;一开始做这个lab的时候，其实我是有一点懵的。因为MIT给出的实验文件，仅仅只有master提供rpc接口，worker却没有rpc接口。也就是说，master并不能主动向worker分发任务。</p><p>&amp;#8195;&amp;#8195;后来通过查阅文档之后发现，该lab的设计是通过，worker在一个loop中不断的向master请求任务，解决任务，然后恢复master。不断执行这个loop。</p><p>&amp;#8195;&amp;#8195;这种设计方案，有一个好处，就是能够充分利用worker的性能，尽量减少worker闲置的情况发生。</p><h3 id="任务分发"><a href="#任务分发" class="headerlink" title="任务分发"></a>任务分发</h3><figure class="highlight golang"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><code class="hljs golang"><span class="hljs-keyword">type</span> AssignTaskReq <span class="hljs-keyword">struct</span> &#123;<br>workerId <span class="hljs-keyword">uint64</span><br>&#125;<br><br><span class="hljs-keyword">type</span> AssignTaskReply <span class="hljs-keyword">struct</span> &#123;<br>replyTaskType<span class="hljs-keyword">int</span><br>mapTaskInfo *MapTaskInfo<br>ReduceTaskInfo*ReduceTaskInfo<br>&#125;<br><br><span class="hljs-comment">// 分发任务的接口</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(m *Master)</span> <span class="hljs-title">assignTask2Worker</span><span class="hljs-params">(req *AssignTaskReq, rsp *AssignTaskReply)</span> <span class="hljs-title">error</span></span> &#123;<br><br>mutexLock.Lock()<br><span class="hljs-keyword">defer</span> mutexLock.Unlock()<br><br><span class="hljs-comment">// 1.check if propre map task for work</span><br>mapTask,assignMapSuccess := m.getInitMapTaskForAssign()<br><span class="hljs-keyword">if</span> assignMapSuccess &#123;<br><span class="hljs-comment">// 1. change the info of map task</span><br>mapTask.MapTaskState = MAP_TASK_STATE_RUN<br>mapTask.MapTaskStartTimeStamp = <span class="hljs-keyword">uint64</span>(time.Now().Unix())<br>mapTask.MapTaskAssignedWorkerId = req.workerId<br><br><span class="hljs-comment">// 2. set reply</span><br>rsp.mapTaskInfo = mapTask<br>rsp.replyTaskType = TASK_TYPE_MAP<br><br><span class="hljs-keyword">return</span> <span class="hljs-literal">nil</span><br>&#125;<br><br><span class="hljs-comment">// 2.try to assign reduce task</span><br>reduceTask,assignReduceSuccess := m.getInitReduceTaskForAssign()<br><span class="hljs-keyword">if</span> assignReduceSuccess &#123;<br><span class="hljs-comment">// register reduce task</span><br>reduceTask.ReduceTaskState = REDUCE_TASK_STATE_RUN<br>reduceTask.ReduceTaskStartTimeStamp = <span class="hljs-keyword">uint64</span>(time.Now().Unix())<br>reduceTask.ReduceTaskAssignedWorkerId = req.workerId<br><br><span class="hljs-comment">// set reply</span><br>rsp.replyTaskType = TASK_TYPE_REDUCE<br>rsp.ReduceTaskInfo = reduceTask<br><br><span class="hljs-keyword">return</span> <span class="hljs-literal">nil</span><br>&#125;<br><br><span class="hljs-keyword">return</span> <span class="hljs-literal">nil</span><br>&#125;<br></code></pre></td></tr></table></figure><p>&amp;#8195;&amp;#8195;先简单说一下分发任务的逻辑。因为，map任务是产生中间数据集，而reduce任务的输入就是map产生的中间数据集。因此，在任务分发的时候，<strong>显然map任务有更高的优先级，尽量让map任务先做完。</strong></p><p>&amp;#8195;&amp;#8195;以map的分发为例，<strong>需要分发的是INIT状态的任务，已经在计算和运行结束的任务不必再次分发。</strong>这里通过调用<code>m.getInitMapTaskForAssign()</code>获得一个**能够分发的任务(INIT)**。(如果找不到，说明map已经全部分发完毕，可以把reduce进行分发这个逻辑跟分发map类似）</p><p>&amp;#8195;&amp;#8195;后面就是对该任务进行注册（修改状态，添加分发时间，以及分给哪个worker）。</p><p>​    </p><p>以上就是分发任务接口的实现逻辑，十分简单。下面想讨论，在做这个lab遇到的问题以及细节：</p><p><strong>(1)数据的完整性以及分发的原子性</strong></p><p>&amp;#8195;&amp;#8195;刚开始做这个lab的时候，我设计的master是用三个队列来存储taskInfo的。<strong>这种设计，可以马上在INIT状态的队列里面拿出一个任务进行处理。而如果用table的话，需要遍历整个表。</strong></p><p>&amp;#8195;&amp;#8195;但是，这样三队列这种设计，其实它原子性是不高的。这种设计之下，它的分发其实是三个动作：(1)从INIT队列中拿出一个task (2)修改该task的信息 (3)把这个task插入到PROCESSING队列中</p><p>&amp;#8195;&amp;#8195;这三个都是独立的操作，即使定期给Master做一个快照，但还是会有数据丢失的情况发生。比如说以下这种场景：</p><ul><li>从INIT队列中取出一个task</li><li>系统进行快照备份</li><li>备份完之后发生了crash</li></ul><p>&amp;#8195;&amp;#8195;那么，在这种场景下，从INIT拿出来的这个task就会消失了。<strong>因为，发生持久化的时候，该task并不在这三个队列中，持久化的时候并不能把该task写入到硬盘中去。</strong>如果没有发生crash则没关系，若是在这个时候发生crash了，这个task是仅仅存在于内存里面的，因此会导致数据丢失。（除非持久化的时候，不仅存储那三个队列，还把内存中的数据一并持久化。但是真要这要做，开销是十分巨大的）</p><p>&amp;#8195;&amp;#8195;正是因为这个原因，我选择了把所有task存储在一个table里面，这样就避免了这种弱原子性的问题。<strong>并且考虑到，在table里面拿到一个可以分发的task的平均复杂度不会太高，因此这种方案还是能够接受的。</strong></p><p><strong>(2)处理逻辑和发送回复的顺序问题</strong></p><figure class="highlight golang"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs golang"><span class="hljs-comment">// 1. change the info of map task</span><br>mapTask.MapTaskState = MAP_TASK_STATE_RUN<br>mapTask.MapTaskStartTimeStamp = <span class="hljs-keyword">uint64</span>(time.Now().Unix())<br>mapTask.MapTaskAssignedWorkerId = req.workerId<br><br><span class="hljs-comment">// 2. set reply</span><br>rsp.mapTaskInfo = mapTask<br>rsp.replyTaskType = TASK_TYPE_MAP<br><br></code></pre></td></tr></table></figure><p>&amp;#8195;&amp;#8195;简单来说其实就是<strong>先处理注册逻辑还是先发送回复的问题</strong>。在这个lab中其实不会遇到这个问题，因为太久没用过rpc了，当时以为只要设置了rsp就会把回复发送给调用者。实际上，会等到这个接口调用结束之后，rpc框架才会对rsp进行序列化并通过网络进行传输。</p><p>&amp;#8195;&amp;#8195;虽然，这个问题在该lab中没有体现，但是还是有不少参考意义（比如在MQ中这应该会经常碰到）。</p><p>&amp;#8195;&amp;#8195;对于这个问题，有两种方案，下面来分析一下它们的优劣势：</p><p><strong>1.先发送rsp，再处理metadata（又或者是业务逻辑）</strong></p><p>&amp;#8195;&amp;#8195;当时做这个的时候，主要考虑的问题是。<strong>当我发送完这个回复请求之后，还没到业务逻辑的处理，这时系统发生宕机了</strong>，我该怎么进行处理？</p><p>&amp;#8195;&amp;#8195;如果发送rsp之后发生宕机了，假设网络没有任何问题，worker就会收到该请求，然后开始处理这个计算任务，从这个角度来看worker认为master已经把任务分发给他了。</p><p>&amp;#8195;&amp;#8195;但是从master的角度来说，<strong>它虽然已经发送了请求，但是metadata还没来得及修改，然而master作出的决策也基本是依靠metadata。因此从这个角度master不认为已经把任务分发了</strong>，在master的metadata中，该任务仍就是处于INIT状态。</p><p>&amp;#8195;&amp;#8195;正是因为上述原因，需要额外的机制来处理这种错误。此时，metadata没有修改，但是worker已经收到分发的任务了，并开始处理。<strong>处理完成后，会调用<code>task_finish</code>接口让master处理</strong>。但这时候，master就会很困惑了，<strong>因为该任务是INIT又被分发到别的worker上</strong>。</p><p>&amp;#8195;&amp;#8195;其实，这个处理也不难，<strong>只要回复的workerId 与 master记录的把该task分发到哪个workerId上，这两个对不上，master就不进行处理就好了。</strong>不要弄太复杂的逻辑。</p><p><strong>2.先处理metadata，再发送请求</strong></p><p>&amp;#8195;&amp;#8195;跟上面的问题类似，在这种场景下，从master的角度来看，确实是把任务分发了，因为metadata已经被修改了。但是从worker的角度来看，它没有收到分发的任务。</p><p>&amp;#8195;&amp;#8195;这种的处理策略也很简单，我们只需要等超时处理，自动把该任务回收就好了。</p><p>&amp;#8195;&amp;#8195;<strong>经过综合考虑之后，我决定选择第二种策略去做该lab。</strong></p><h3 id="任务结束"><a href="#任务结束" class="headerlink" title="任务结束"></a>任务结束</h3><figure class="highlight golang"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><code class="hljs golang"><span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">(m *Master)</span> <span class="hljs-title">finishTaskHandler</span><span class="hljs-params">(req *DoneTaskReq,rsp *DoneTaskRsp)</span> <span class="hljs-title">error</span></span> &#123;<br><br>mutexLock.Lock()<br><span class="hljs-keyword">defer</span> mutexLock.Unlock()<br><br><span class="hljs-comment">// get the task</span><br><span class="hljs-keyword">if</span> req.taskType == TASK_TYPE_MAP &#123;<br>m.finishMapTask(req)<br>&#125;<span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> req.taskType == TASK_TYPE_REDUCE &#123;<br>m.finishReduceTask(req)<br>&#125;<br><br><span class="hljs-keyword">return</span> <span class="hljs-literal">nil</span><br>&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">(m *Master)</span> <span class="hljs-title">finishMapTask</span><span class="hljs-params">(req *DoneTaskReq)</span></span>&#123;<br><br><span class="hljs-comment">// get the task</span><br>taskInfo := m.tableMapTask[req.taskSeq]<br><br><span class="hljs-keyword">if</span> checkMapTaskCanSetFinish(req.workerId, <span class="hljs-keyword">uint64</span>(time.Now().Unix()),taskInfo)&#123;<br><span class="hljs-comment">// set the task finish</span><br>m.intermediateHandler(req.outputFilePath)<br>taskInfo.MapTaskState = MAP_TASK_STATE_FINISH<br>&#125;<span class="hljs-keyword">else</span>&#123;<br><span class="hljs-comment">// if the worker id or the task timeout,don&#x27;t do anything just let the timeout handler to solve the problem</span><br><span class="hljs-comment">// it can simplfy the design</span><br>&#125;<br><br><span class="hljs-keyword">return</span><br>&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">(m *Master)</span> <span class="hljs-title">finishReduceTask</span><span class="hljs-params">(req *DoneTaskReq)</span></span> &#123;<br><br><span class="hljs-comment">// get the task</span><br>reduceTaskInfo := m.tableReduceTask[req.taskSeq]<br><br><span class="hljs-keyword">if</span> checkReduceTaskCanSetFinish(req.workerId,<span class="hljs-keyword">uint64</span>(time.Now().Unix()),reduceTaskInfo) &#123;<br>reduceTaskInfo.OutputFilePathLocation = req.outputFilePath[<span class="hljs-number">0</span>]<br>reduceTaskInfo.ReduceTaskState = REDUCE_TASK_STATE_FINISH<br>&#125;<br><br><span class="hljs-comment">// let the timeout handler the solute this situation</span><br><br><span class="hljs-keyword">return</span><br>&#125;<br></code></pre></td></tr></table></figure><p>&amp;#8195;&amp;#8195;当worker处理完任务之后，就会回调该函数，然后让master进行metadata的处理。因为worker能处理map_task和reduce_task，因此在回调的之后，需要指明当前worker是处理的哪个task。</p><p>&amp;#8195;&amp;#8195;同时，需要知道的是，有超时机制的存在，导致master有可能把任务再次分发给到了另一个worker。因此，master在处理任务结束的回调，最主要的是处理metadata的信息是否准确。<strong>当时有想过，在校验worker信息的时候，同时也检测超时。但是，后来还是觉得应该遵从单一原则，不应该把事情弄得过于复杂。并且，如果在处理结束任务时，实际上该任务已经超时了，但是超时任务还没来得及启动处理。我想，最终是否是超时应该交给超时机制去处理。</strong></p><h3 id="任务监控-timeout"><a href="#任务监控-timeout" class="headerlink" title="任务监控(timeout)"></a>任务监控(timeout)</h3><figure class="highlight golang"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><code class="hljs golang"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(m *Master)</span> <span class="hljs-title">MapCheckingHandler</span><span class="hljs-params">()</span></span>&#123;<br><br><span class="hljs-keyword">for</span>&#123;<br>mutexLock.Lock()<br><span class="hljs-keyword">defer</span> mutexLock.Unlock()<br>nowTimeStamp := <span class="hljs-keyword">uint64</span>(time.Now().Unix())<br><span class="hljs-keyword">for</span> _,mapTaskInfo := <span class="hljs-keyword">range</span> m.tableMapTask &#123;<br><span class="hljs-keyword">if</span> mapTaskInfo.MapTaskState == MAP_TASK_STATE_RUN &amp;&amp;<br>checkTaskTimeout(nowTimeStamp,mapTaskInfo.MapTaskStartTimeStamp) &#123;<br><br><span class="hljs-comment">// eraser map-register info</span><br>mapTaskInfo.MapTaskState = MAP_TASK_STATE_INIT<br>mapTaskInfo.MapTaskAssignedWorkerId = NO_WORKER_ID<br>mapTaskInfo.MapTaskStartTimeStamp = <span class="hljs-number">0</span><br>&#125;<br>&#125;<br>mutexLock.Unlock()<br><span class="hljs-comment">// sleep 15 sec</span><br>time.Sleep(<span class="hljs-number">100</span>*time.Millisecond*<span class="hljs-number">2</span>)<br>&#125;<br>  <br>&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(m *Master)</span> <span class="hljs-title">ReduceCheckingHandler</span><span class="hljs-params">()</span></span>&#123;<br><br><span class="hljs-keyword">for</span>&#123;<br>mutexLock.Lock()<br><span class="hljs-keyword">defer</span> mutexLock.Unlock()<br>nowTimestamp := <span class="hljs-keyword">uint64</span>(time.Now().Unix())<br><span class="hljs-keyword">for</span> _,reduceTask := <span class="hljs-keyword">range</span> m.tableReduceTask&#123;<br><span class="hljs-keyword">if</span> reduceTask.ReduceTaskState == REDUCE_TASK_STATE_RUN &amp;&amp;<br>checkTaskTimeout(nowTimestamp,reduceTask.ReduceTaskStartTimeStamp)&#123;<br><span class="hljs-comment">// eraser reduce task register info</span><br>reduceTask.ReduceTaskState = REDUCE_TASK_STATE_INIT<br>reduceTask.ReduceTaskAssignedWorkerId = NO_WORKER_ID<br>reduceTask.ReduceTaskStartTimeStamp = <span class="hljs-number">0</span><br><br>&#125; <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> reduceTask.ReduceTaskState == REDUCE_TASK_STATE_BLOCK &amp;&amp;<br>checkReduceTaskCanSetInit(reduceTask)&#123;<br><span class="hljs-comment">// 检查是否能够把某个reduce-task set init</span><br>reduceTask.ReduceTaskState = REDUCE_TASK_STATE_INIT<br>&#125;<br>&#125;<br>mutexLock.Unlock()<br>time.Sleep(<span class="hljs-number">100</span>*time.Millisecond*<span class="hljs-number">2</span>)<br>&#125;<br><br>&#125;<br></code></pre></td></tr></table></figure><p>&amp;#8195;&amp;#8195;对于管理metadata的节点来说，我觉得监控是十分重要的一个机制。<strong>感觉很多容错的措施都是建立在监控的基础上的</strong>，比如说运行在某个worker上面的任务，因为宕机等原因，造成该任务没有办法完成。如果没有额外的机制去处理的话，master将会永远等待这个“无法完成”的任务，这显然不合理。</p><p>&amp;#8195;&amp;#8195;因此，需要引入一个机制来帮助master筛选那些已经“坏掉的任务”。在这个lab中，我通过超时处理来达成这个目的。<strong>一般情况下，worker都能在规定时间内完成分发给它的任务，因为分发下去的任务都是一些子任务，并不会有很大的数据量，除非一些不可抗的因素（网络IO慢，worker负载高，宕机）发生，才会导致任务的超时。</strong></p><p>&amp;#8195;&amp;#8195;当一个任务被分发下去的时候，<strong>master便会记录该任务分发的时间，以及分发给哪个worker。</strong>一开始设计的时候，我仅仅是记录分发的时间，没有记录分发给哪个worker。</p><p>&amp;#8195;&amp;#8195;后面验证的时候发现了逻辑漏洞，如果不记录worker的话，当一个任务超时，master会把该任务重新设置为可分发状态。当旧的worker完成任务后，调用<code>task_finish</code>接口的时候，如果此时任务处于INIT状态，master显然能够这道此时的处理的<code>task_finish</code>是超时的任务。但是，如果master把这个超时的任务，重新分发给到了别的worker，那么master旧很难区分到底是谁调用了<code>task_finish</code>。<strong>因此，我加了一个workerId方便master进行校验。</strong></p><p>&amp;#8195;&amp;#8195;把这些该保存的信息，都记录下之后，便开启开启一个协程去处理超时。该协程是一个endless loop，并且在每个周期内都会检查所有</p><p>metadata，如果某个任务超时，便将它重新设置为初始化状态。这样即使，master收到已经超时的任务，它也有能力进行处理（一般直接忽略即可）。</p><p>&amp;#8195;&amp;#8195;虽然这种机制，能够处理上述的问题，但是也不是那么的完美。最大的问题就是，这个超时时间很难去给出一个很好的界定，首先网络本身就是不可靠的（除非，master和worker都在一个机房内，有专线进行沟通，但这地域容错性不高），还有worker也不是只处理一个任务可能还运行别的任务…..因此，如果把超时时间设置得太小，那么很容易发生超时；如果设置太大，那么超时机制的作用就会降低。</p><p>&amp;#8195;&amp;#8195;但是，我个人是比较喜欢设置稍大的超时时间的，主要有以下的考虑：</p><ul><li>超时显然是小概率的事件，因此设置稍大的超时时间也未尝不可，只需要在一定的时间内把该任务发现了就行</li><li>worker应该要有重试机制，一个任务在某个worker上彻底无法重做的概率也是很小的，如果是这种情况确实应该重新分发。但是如果是别的情况，显然让worker进行重做该任务，显然比master重新分发该任务让别的worker执行效率要高。</li></ul><h3 id="Done"><a href="#Done" class="headerlink" title="Done"></a>Done</h3><p>&amp;#8195;&amp;#8195;这个就不细说了，就是master定时检查，是否所有任务都已经完成，回复给调用的client。</p><h2 id="收获"><a href="#收获" class="headerlink" title="收获"></a>收获</h2><p>&amp;#8195;&amp;#8195;这个lab虽然不太难，但是做完之后收获还是不小。最大的一个感受就是，<strong>像这种依靠一个master进行分发的模型，如果能够维护好metadata的话，很多问题都能避免。</strong></p><p>&amp;#8195;&amp;#8195;还有就是，目前做的这个lab，因为时间关系很多方面都比较粗糙，比如说控制并发方面，我用了一个互斥锁就把所有metadata都锁起来。这样的操作导致该demo并发度并不会太高。优化的方案也想过，就是把互斥锁换成读写锁机制，还有学习concurrent_hashMap，在表中加分段加锁，这样就不会一次锁起整个表。</p><p>&amp;#8195;&amp;#8195;还有就是，一些持久化操作也做，比如可以定时把master的metadata都持久化到磁盘，这样能够提高系统的容错性…</p><p>​    </p><p>&amp;#8195;&amp;#8195;ok，就到这里吧，社畜还要接着上班…</p>]]></content>
    
    
    <categories>
      
      <category>数据库</category>
      
    </categories>
    
    
    <tags>
      
      <tag>分布式</tag>
      
      <tag>论文</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>消息队列学习笔记 - 2</title>
    <link href="/2021/11/25/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%9B%B8%E5%85%B3/message-queue-part-2/"/>
    <url>/2021/11/25/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%9B%B8%E5%85%B3/message-queue-part-2/</url>
    
    <content type="html"><![CDATA[<h3 id="消息队列的模型"><a href="#消息队列的模型" class="headerlink" title="消息队列的模型"></a>消息队列的模型</h3><p>​    在我一开始学习消息队列的时候，有些概念没有搞得很清楚，趁着今天早下班来梳理一下。</p><p>​    在消息队列中，什么是队列，什么是主题？他们之间有什么区别呢？还有它是怎么做的<strong>发布 - 订阅模型</strong>。</p><!--more--><h4 id="队列"><a href="#队列" class="headerlink" title="队列"></a>队列</h4><p>​    在早期的消息队列中，是用一个“队列(Queue)”来存储消息的。这里包含一个关键点，就是消息是按照到达服务器的顺序进行存储的，也是按照这个顺序来进行消费的，即<strong>先来先消费</strong>。</p><p>​    <img src="/../../images/%E6%B5%85%E8%B0%88%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97-2/image-20211125221456438.png" alt="image-20211125221456438"></p><p>​    如上图，生产者(上游服务)把消息推送到消息队列中去，这样消费者(下游)就能对这些消息进行处理。如果有多个消费者，并发地往同一个队列里面推送消息，那么其实这也还好问题不算太大。只要在消息队列上做一些操作，就能<strong>避免并发写带来的问题（比如说队列上加分布式锁，或者仿照GFS保证每次append都是原子的）。</strong></p><p>​    对于消费者并发，其实也可以仿照上述的做法，这样能避免消费者之间的并发问题。但是，这又带来了另外一个问题，<strong>这样会导致，一条消息只能被一个消费者消费。然而，很多场景，我们希望一条消息能够被多个系统所共享。</strong></p><p>​    <img src="/../../images/%E6%B5%85%E8%B0%88%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97-2/image-20211125222902977.png" alt="image-20211125222902977"></p><p>​    如图，订单系统生成了一条订单消息，而其他三个消费者系统之间并没有依赖关系，几乎可以说是独立的。那么，<strong>一条消息按道理来说同时被三个系统消费，是最好的选择。</strong>但是这时候，单队列就不能满足这个需求了。</p><p>​    一个比较一般的做法，就是为某个系统都创建一个队列。这时候，一条消息就会复制成多分然后投放到这些队列中去。这显然是一种十分笨拙的方法。</p><p>​    为了解决这个问题，出现了一种模型<strong>发布 - 订阅模型</strong>。</p><hr><h4 id="主题-发布-订阅模型"><a href="#主题-发布-订阅模型" class="headerlink" title="主题 , 发布 - 订阅模型"></a>主题 , 发布 - 订阅模型</h4><p>​    为了解决这个问题，演化出了一种模型 — <strong>发布 - 订阅</strong>。在该模型里面，发送消息的称为<strong>发布者</strong>。存储消息的容器称为<strong>主题（TOPIC）</strong>。消费消息的称为<strong>订阅者</strong>。</p><p>​    如果消费者想要从消息队列上得到消息，那么在<strong>接受消息之前，它需要订阅该主题。我个人理解，订阅是指在队列上，设置一个“专属的offset”</strong>。这样，队列中维护着不同订阅者的offset。</p><p>​    每个订阅者，消费完一个消息后，队列上对应的offset就会移动到下一条消息的地方。<strong>这就解决了单队列，消息不能被共享的问题。在这个模型中，不同订阅者的offset是独立的，消费完后消息也只是逻辑上出队。实际上并没有出队，也不影响别的队列的offset。</strong></p><hr><h4 id="RocketMQ的模型"><a href="#RocketMQ的模型" class="headerlink" title="RocketMQ的模型"></a>RocketMQ的模型</h4><h5 id="发布-订阅的缺陷"><a href="#发布-订阅的缺陷" class="headerlink" title="发布-订阅的缺陷"></a>发布-订阅的缺陷</h5><p>​    上面提到的<strong>发布 - 订阅模型</strong>，虽然解决了消息共享的问题，但在实际生产中仅仅依赖该模型的话，效率仍然是不够高的。<strong>因为，主题本质上仍就是单队列。这就让整个系统的并发性能不太行了。</strong></p><p>​    为什么这样说呢？其实是下面这个原因：</p><ul><li><strong>为了防止消息不丢失，消息队列都有”请求 - 确认”机制</strong></li></ul><p>​    这个机制到来了一个问题。offset，只有收到<strong>消息成功消费的确认</strong>，该offset才能进行移动。不然会出现，很奇怪的现象。</p><p>​    比如说，发布者发布了<strong>两条有顺序关系的消息</strong>到主题上。消息1推送给订阅者，但是在网络中丢失了。但是主题并不知道，而且还给订阅者推送消息2。<strong>这导致了，订阅者只收到了消息2，但是消息2和消息1是有顺序关系</strong>的，因此会导致订阅者的处理逻辑出现错误。</p><p>​    正是这个原因，订阅了“订单消息主题“的支付系统，该系统中只能有一个实例。即使多加了实例，也不能提高系统的效率。这就难以让人接受了。</p><hr><h5 id="主题多队列模型"><a href="#主题多队列模型" class="headerlink" title="主题多队列模型"></a>主题多队列模型</h5><p>​    为了在<strong>发布 - 订阅模型</strong>的基础上提高，消息队列的并发度。能够让一个订阅者上能够部署多个实例，RocketMQ的设计者在<strong>一个主题下面配置了多个队列。</strong>这些队列的功能都是一样的，都是收发消息。</p><p>​    发布者，发布消息的时候，通过<strong>路由规则把消息推送到主题下的某个队列中</strong>（通常是hash）。</p><p><img src="/../../images/%E6%B5%85%E8%B0%88%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97-2/image-20211125234415299.png" alt="image-20211125234415299"></p><p>​    因为有了多队列，订阅者也可以有多个实例，称为<strong>订阅者组。</strong>一般来说，订阅者组的实例数量最好是等于主题中队列的数量。</p><p>​    在“主题-单队列”的模型中，因为ack机制，导致了主题上订阅者不能有多个实例。在“主题-多队列”模型中，这个<strong>核心问题(ack带来的消息顺序问题）仍旧没有改变，它仅仅是在主题层面上扩充了队列，提高了并发性能。并没有改变，一个队列对应一个实例的要求。</strong></p><p>​    因此，订阅者组中，实例对象太少不能完全利用系统的性能；实例数量太多，必定会有实例被闲置。</p><p><img src="/../../images/%E6%B5%85%E8%B0%88%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97-2/image-20211125235549490.png" alt="image-20211125235549490"></p><p>​    在这个模型中，有几个值得注意的点：</p><p><strong>(1)一条消息在订阅组中是竞争关系</strong></p><figure class="highlight"><table><tr><td class="gutter"><div class="code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></div></td><td class="code"><pre><code class="hljs">结合上面提到的，发布者的路由。一条消息，会路由到主题中的某一个队列，不会出现在多个队列中。<br>而主题下的队列，因为ack机制，对于一个订阅者组只能绑定其中一个实例。<br>那么，很显然，这就导致了，一条消息传递到订阅者组中只能被其中一个实例进行消费了。<br></code></pre></td></tr></table></figure><p><strong>(2)一条消息在不同订阅者组中是共享的</strong></p><figure class="highlight erlang"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs erlang">消息被订阅者组<span class="hljs-number">1</span>消费完之后，还可以被订阅者组<span class="hljs-number">2</span>消费...<br><br><br></code></pre></td></tr></table></figure><p><strong>(3)在主题层面消息是无序的，但是在队列层面消息是有序的</strong></p><figure class="highlight gcode"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs gcode"><span class="hljs-comment">(1)</span>可以把有顺序关系hash到同一个队列中，因此队列角度来看消息是有序的。<br><span class="hljs-comment">(2)</span>那显然，主题层面上是无序的。<br><span class="hljs-comment">(3)</span>但是在主题层面来说，消息是“因果序”而非<span class="hljs-string">&quot;全序&quot;</span>。<br></code></pre></td></tr></table></figure><p>​    之前学习的时候，一直很困惑主题下的队列怎么跟订阅者组的对应关系，今天梳理一遍之后清晰很多了…好了先这样了，明天还要上班。这么再更一篇6.824的lab或者鸽了很久的tcp…</p>]]></content>
    
    
    <categories>
      
      <category>数据库</category>
      
    </categories>
    
    
    <tags>
      
      <tag>中间件</tag>
      
      <tag>消息队列</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>故障反思</title>
    <link href="/2021/11/19/%E5%B7%A5%E4%BD%9C%E7%BB%8F%E9%AA%8C%E7%9B%B8%E5%85%B3/error-review/"/>
    <url>/2021/11/19/%E5%B7%A5%E4%BD%9C%E7%BB%8F%E9%AA%8C%E7%9B%B8%E5%85%B3/error-review/</url>
    
    <content type="html"><![CDATA[<h3 id="安全问题"><a href="#安全问题" class="headerlink" title="安全问题"></a>安全问题</h3><p>​    最近看了很多运营事故的复盘，让我有种后背发凉的感觉。因为自己在公司实习的时候，在线上环境的操作都是很随意的。并没有每一步按照流程进行执行，试过了很多的危险操作，至今还没出事属实是侥幸。</p><h4 id="案例一：生产环境中执行危险脚本"><a href="#案例一：生产环境中执行危险脚本" class="headerlink" title="案例一：生产环境中执行危险脚本"></a>案例一：生产环境中执行危险脚本</h4><p>​    这是最近学校工作室发生的一起事故。事故的北京是这样的，工作室的师弟，手滑在正式环境上面误跑了“重新部署”的脚本。导致了，重要数据以及日志全部被删除。而且，对这些数据没有进行备份，导致了误删的东西不能恢复。</p><span id="more"></span><p><img src="/../../images/%E6%95%85%E9%9A%9C%E5%A4%8D%E7%9B%98/image-20211119232724108.png" alt="image-20211119232724108"></p><p>我觉得，这次事故的发生全是因为流程上有以下不规范的地方：</p><p><strong>(1)重要数据没有做好备份</strong></p><p>​    因为一开始对这些不够重视，没有做好数据的备份。导致事故发生之后，没有任何办法进行补充。<strong>针对这个，建议以后对重要的数据至少都在另一台机器上面进行备份。异步备份，或者是同步双写方等方案都行。总之一定要保证，事故发生之后一定要有补偿手段。</strong></p><p>​    这也是做好异地容灾的必要性。虽然这次是因为误跑脚本导致丢失，但是总有很多意外会导致数据的丢失，比如说磁盘损坏，地震……如果只有一份数据的话，那就真的很危险了。<strong>因此，有能力做异地容灾的话，建议还是做好这个措施。</strong></p><p><strong>(2)线上环境的流程过于简单</strong></p><p>​    仅仅执行了一个简单的命令就导致比较严重事故，这暴露了一个问题，<strong>线上的流程过于简单</strong>。我现在觉得，在生产的一些比较敏感的操作，至少要有确认和验证。这样才能尽可能减少误操作的发生。</p><p>​    在实习的时候，我一般的发布流程是这样的：(1)如果服务需要在测试环境上运行，我就直接在本地终端直接shell脚本，把服务推送到测试环境。 (2)但是，要把服务推送到正式环境则需要通过很繁琐的流程，最后还需要比较繁琐的确认操作。</p><p>​    一开始，我还经常吐槽线上环境的流程很复杂，现在终于明白公司为什么要制定这些流程规范了。</p><p>​    </p><p><strong>(3)“删除”不应该出现在生产环境中</strong></p><p>​    任何“物理删除”都不应该出现在生产环境中…这个就不仔细说了，那个删除数据的脚本就不应该出现在生产环境里面。<strong>在腾讯实习的时候，数据从来都没有物理删除的…只有逻辑删除。</strong></p><p>​    现在想想真的有点后背发凉，实习的时候导师直接把生产环境数据库的root权限给我…要是当时做了什么误操作，后果不堪设想。针对这次事故，<strong>以后开发中一定要有敬畏之心，注意流程上的规范。</strong></p><h4 id="案例二-后台雪崩"><a href="#案例二-后台雪崩" class="headerlink" title="案例二:后台雪崩"></a>案例二:后台雪崩</h4><p>​    背景是这样的，我们的服务部署在上海和广州。碰巧当天通信发生了故障，导致导致服务A(广州)调用服务B(上海)全部失败，并且客户端还不断发起重试…</p><p>​    随着时间的推移，请求量越积越多，等到网络通信的恢复的时候，所有流量瞬间涌到了服务B(上海那边)。导致服务B的节点大规模宕机。</p><p>​    当时不知道怎么回事，就想着实在不行就先重启试试。但是重启一台死一台…</p><p>​    最后故障是怎么解决的呢？无奈，只好在前端把流量入口关闭，然后再启动所有的节点，这样才慢慢把流量降下来…</p><p><strong>解决方案</strong></p><p>​    雪崩过载，是一种比较常见的故障。但是很多时候，但是针对该案例发生做出相应的赶紧和优化，但这有些治标不治本…最好的解决办法，就是建立“快速拒绝”的机制。</p><h4 id="案例三：硬件架构层面没做好"><a href="#案例三：硬件架构层面没做好" class="headerlink" title="案例三：硬件架构层面没做好"></a>案例三：硬件架构层面没做好</h4><p>​    这是四五年前，总监遇到的一个故障。当时的情况是这样的，有一个非常核心的业务部署在了上海，并且在软件架构上的层面已经做了比较充足的防备。业务部署了三台节点，并且三个节点互为住备..</p><p>​    按理说，这应该没啥问题。因为除非它三台机器同时挂掉，不然这个服务都是可用的…但是，当初忽略了一个问题，这三个节点都是链接到了同一台交换机上面。<strong>然后，当天交换机宕机了，导致核心服务百分百不可用…</strong></p><p><strong>启示</strong></p><p>​    这个故障给我们的启示是什么呢？就是即使你在软件层面上做好了防护，但是硬件层面没做好的话，还是十分危险的…因此从那次之后，架构层面上做了很多异地容灾的改造。</p><h3 id=""><a href="#" class="headerlink" title=""></a></h3>]]></content>
    
    
    <categories>
      
      <category>笔记</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>读论文《the google file system》</title>
    <link href="/2021/11/13/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/the-google-file-system/"/>
    <url>/2021/11/13/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/the-google-file-system/</url>
    
    <content type="html"><![CDATA[<p>​    最近读了谷歌的分布式文件系统，感觉收获很大。这篇文章啃下来还有点费解的，还有一些具体的设计不是很明白，欢迎大家来讨论～</p><p>​    <a href="https://storage.googleapis.com/pub-tools-public-publication-data/pdf/035fc972c796d33122033a0614bc94cff1527999.pdf">论文地址</a></p><span id="more"></span><h2 id="系统总体设计"><a href="#系统总体设计" class="headerlink" title="系统总体设计"></a>系统总体设计</h2><h3 id="前提假设"><a href="#前提假设" class="headerlink" title="前提假设"></a>前提假设</h3><ul><li><p>在分布式的文件系统里面，里面节点的硬件或者是其他一些资源都不会是质量很好，效率很高的（内存，CPU，磁盘，带宽等等）。虽然我们目标当然是用上最好的资源，但是这<strong>显然是一笔经济问题。</strong>因此，因为资源的限制，整个系统发生错误是在所难免的。<strong>为了提高系统的可用性，我们需要系统能够具备错误监视以及恢复的功能。</strong></p></li><li><p>分布式文件系统应该是<strong>针对大文件设计</strong>的，因此必须考虑如何在系统中更加有效地管理这些文件，作出一些优化。当然，小文件总是存在的，但是不应该过度设计算法去进行优化，这一点是从简化系统的设计进行考虑的，如果过度设计可能带来很多复杂的逻辑问题</p></li><li><p>从系统中读取文件，一般是两种场景。一个是，大段地连续读。另一个是，小段小段地读取。我们需要对其进行优化</p></li><li><p>针对文件的写入，我们要考虑如何处理并发写入的问题。并且写入的数据如何在副本之间进行复制。而且还要考虑系统的数据一致性问题，很显然如果强一致的话，会阻塞比较长的时间，这样用户体验其实不太好的。因此，需要根据CAP定理，权衡以及设计出一个比较合适的方案…</p></li></ul><h3 id="系统结构"><a href="#系统结构" class="headerlink" title="系统结构"></a>系统结构</h3><p>​    参考谷歌文件系统的设计，系统中部署一个master节点用来存储文件的控制信息（文件名，访问权限，文件名映射chunks的表），多个chunkserver服务器用来具体存储文件的真实数据。</p><p>​    为什么谷歌的这种设计，跟我们平常遇到的集群其实还是有很多的不一样。比如说，MySQL集群通常采用的是一主二从的设计，并且它所有的节点，存储的东西其实是几乎一样的。</p><p>​    但是谷歌的文件系统中，它是把文件的控制信息和数据分别存放在两个地方。除此以外，设计者并没有对master进行去中心化的操作。我想设计者可能是权衡了系统的容错和高性能之间作出的选择吧。虽然如此，我们也可以给master设计一些优化，让它尽可能地有更高的容错性。这个部分放到后面说。</p><p><img src="/../../images/the-google-file-system/image-20211113211503784.png" alt="image-20211113211503784"></p><p>​    先简单介绍一下，上面结构的一些概念。</p><p><strong>控制信息 metadata</strong></p><p>​    上面提到了，在这个结构中，文件的控制信息和数据是分开进行存放的。控制信息有很多，比如说chunk的位置，版本号，某个chunk的访问权限，文件有哪些chunk……</p><p>​    但是实质上，主要是两个mapping。</p><ul><li><p>文件名 — chunks的映射表：通过该表，我们可以查询到一个文件里面它由哪些chunk组成</p></li><li><p>Chunk — chunk位置的映射表：为了提高系统容错性，必然是需要对每一个chunk做备份的。因此，必须记录每个chunk及其备份到底部署到哪台机器上面，这样方便快速定位</p></li></ul><p><strong>chunk 和 chunkserver</strong></p><p>​    在上面的前提假设中提到，系统中存储的文件往往是很大很大的，很难一次部署到一台机器上。那么就需要把文件切分为若干个大小相等的unit，这个就称为chunk。</p><p>​    然后每个chunk的大小是64MB。这样做的好处就是能够减少系统和master压力，如果chunk的大小太小的话，访问同样大小的文件，必然要多次与chunkserver进行网络io；并且master也会花更多的内存去存储chunk的信息（因为chunk_size越小的话，每个文件的chunk就会越多）</p><p>​    然后每个chunk就保存在不同的chunkserver里面，chunkserver实际上就是一个运行了LINUX_FILE_SYSTEM的服务器。能够帮助我们读取对应的chunk。</p><p><strong>Single Master</strong></p><p>​    GFS采取了单主节点的设计。单master就意味着整个系统的中心化，就意味着整个鲁棒性不够强。因为很显然，当master宕机了，没有其他节点能够接手它的工作，会导致系统的停摆。</p><p>​    但是这种单master的设计会提高系统的性能。因为在各种分布式相关的问题上，核心其实就是让节点之间达成某种共识。由于，消息在网络中传递总是会发生错误的，因此要让节点达成共识，需要用到比较复杂的算法。例如，2PC，TCC这些算法。</p><p>​    因此，我们不应该抛开场景去谈技术选型。在设计分布式系统时，应该考虑使用场景。在谷歌分布式文件系统的论文中，系统的效率是反复提及的一个关键字。可能设计者权衡高容错性和高效率之间选择了高效率，从而没有采用去中心化的设计。</p><p>​    但是这并不意味着，我们不能对它的设计进行优化。即使是单主节点，中心化的设计，我们仍旧可以有一些手段去提高它的容错性。尽量降低，master宕机的风险。这个放到后面的章节详细说</p><p><strong>系统的数据一致性保障</strong></p><p>(1)系统保证master上的数据是一致的</p><p>​    对于master上面的控制信息，它的完整性很好保证，因为这些数据是部署到一台服务器上面的。因此很好操作。只需要一个 operation log 和 check point就能保证数据的一致性和完整性。这个放到后面的章节说</p><p>(2)对于文件的数据修改</p><p>​    在数据一致性方面，GFS并没有提供太多的一致性保障。它仅仅保障了，在一个chunk上面一次提交的记录是完整的。这个具体是怎么做的，放到后面说。</p><p>​    每一次对chunk进行，它可能进入到以下三种状态的其中之一：</p><p><img src="/../../images/the-google-file-system/image-20211113211953197.png" alt="image-20211113211953197"></p><ul><li><p>客户端如果从一个chunk的副本中进行读取，读取到的内容不同的话。那么这部分称它为<strong>不一致的(Inconsistent)</strong></p></li><li><p>如果客户端从哪一个副本里面都是读取到一样的内容，那么<strong>这部分文件就是一致的（consistent）</strong></p></li><li><p>如果客户端都能看到上一次修改的完整内容，那么我就说这部分文件是<strong>确定的(Defined)</strong></p></li></ul><h2 id="系统的交互细节"><a href="#系统的交互细节" class="headerlink" title="系统的交互细节"></a>系统的交互细节</h2><p>​    在设计工作中提到，在分布式系统中如果把控制信息和文件数据分开来存储，其实是一种很巧妙的设计。</p><p>​    也是基于这种思想，想要尽量少让master节点参与到真正的数据流动中，更想让他仅仅是处理和维护关于整个系统的控制信息。为了达成这个目的，需要设计一些额外的机制去进行保证。</p><h3 id="Primary的数据变更"><a href="#Primary的数据变更" class="headerlink" title="Primary的数据变更"></a>Primary的数据变更</h3><p>​    在系统中的每一个chunk，都做了两个备份。也就是说，同一个chunk，在整个系统的角度来看，都是保存了三份。这也就意味着，如果要保证数据的一致性，需要我们在一个chunk上面做了数据变更，需要把这个便更到别的地方。</p><p>​    这个问题，在顺序请求的情况下其实很容易处理同步，只需要把每个数据变更同时写到所有副本里面就可以了。这样就能保证，每个副本的数据都是一致的。</p><p>​    但是，在分布式文件系统中，并发写入的场景是大量存在的，如果不做任何优化的话，很容易造成数据不一致的问题。如下图，举个简单的例子。</p><p><img src="/../../images/the-google-file-system/image-20211113212320611.png" alt="image-20211113212320611"></p><p>​    此时，两个客户端想同时对一个chunk进行追加写操作。一般情况的处理，就是客户端同时把追加记录写入到所有副本中。但是并发请求的情况下这就会带来很多问题。我们假设client1写入的记录是记录1，同理client2是记录2。</p><p>​    我们知道，网络环境总是不稳定的。数据包在网络中的传递总是会有延迟的，<strong>因此我们无法保证，所有的副本都是以同样的顺序收到客户端传来的记录</strong>。</p><p>​    问题的关键找到了，也就是说如果系统能够有某些机制，能够确保所有副本都是以相同的顺序来处理请求，那么即使并发的情况下，也是能够保证数据的一致性的。</p><p>​    如何保证数据的按照同样的顺序被处理，这里提出两种解决方案，首先说明一下这两种方案实质上并没有什么优劣之分，都是很好的分布式方案，只是看场景进行选择罢了。</p><p><strong>方案一：消息队列</strong></p><p>​    我们的目标就是让所有节点按照顺序处理某一个请求。那么就很容易想到用消息队列去进行处理了。因为消息队列里面的消息，本来就是有序的！</p><p>​    只需要创建一个多生产者的消息队列，然后生成一个主题，让所有相关的chunk都去订阅该主题。</p><p>​    这样，所有的副本都能够以相同的顺序去处理请求了。那么最后的结果就是，所有的副本上的数据都会收敛到一致。</p><p><strong>方案二：租约</strong></p><p>​    其实这种方案是参考MySQL集群是如何同步数据的，在MySQL集群中，同步数据实质上是依靠master给出的binlog。其他slave节点就严格按照binlog的顺序去执行，update自身的记录。</p><p>​    因此，在分布式文件系统中也可以借鉴这种思想。在进行数据变更的时候，从所有副本上，挑选出一个让它成为primary。其他副本就严格，执行primary传送过来的顺序。</p><p>​    具体步骤是这样的：</p><ul><li><p>一个client想对某个chunk做数据变更，那么就会向master进行请求</p></li><li><p>master检查该chunk的所有副本是否存在primary。如果没有，选出一个并赋予其一个lease（租约，60s），在这段时间内让该chunk成为primary。并把所有副本，以及primary返回给client。</p></li><li><p>client向距离它最近的chunk发送数据（这些数据并不会立即写入，而是先缓存在本地）。chunk再沿着链路把数据蔓延的所有副本。</p></li><li><p>此时primary必然是收到了，primary按照他的写入顺序把决策通知到其他副本。</p></li><li><p>副本接收到后primary发来的信息后，再把本地缓存中的部分数据写入到对应的chunk中。</p></li></ul><p><img src="/../../images/the-google-file-system/image-20211113212639926.png" alt="image-20211113212639926"></p><p>​    基本上，通过这两种方案就能够解决大部分并发写入的问题。但是，很多情况下，为了提高数据的容错性或者说提高高可用性。往往会对整个集群做一个备份，形成一个数据中心。这时候，可以把不同的数据中心部署在不同的地方，提高异地容灾还有访问效率。</p><p>​    因此，数据中心之间的数据也需要进行同步。由于篇幅的限制，这部分没办法展开说明。我这里提供一个思路，其实数据中心如何让数据收敛到一致，还是需要一个确定的顺序，因此我们可以根据数据的写入时间，做一个顺序。这样，还是能使所有的数据收敛到一致。</p><h3 id="原子提交"><a href="#原子提交" class="headerlink" title="原子提交"></a>原子提交</h3><p>​    在总体设计思想里提到过，GFS并没有提供很强的数据一致性保障。GFS保证的是，对每个副本每一次写入，只有成功和失败两种（不存在每条数据仅写入一半的情况）。</p><p>​    GFS不保证所有副本的数据是一致的，这似乎跟上一小节提到的数据同步有点冲突。确实，如果严格按照上面的做法，是能够做到数据的强一致性。但还是那句话，不能抛开场景去谈技术选型。如果是某种关于资金的系统，确实是需要数据强一致性的要求，但GFS不是这种系统，在论文中反复提到GFS是一个极其注重效率，因此放松了对一致性的要求。<em><strong>*仅保证了，每次写入只有成功和失败两种状态。*</strong></em></p><p><img src="/../../images/the-google-file-system/image-20211113212735148.png" alt="image-20211113212735148"></p><p>​    现在，想要对某个chunk追加三条记录A,B,C。假设primary是第一个副本。因为写入的顺序是由primary决定的（其实可以理解为某个记录写在chunk的哪个地方）。</p><p>​    第二个副本，写入记录B的时候失败了，因此这个空间就空了出来。并回复一个error给客户端，然后客户端就会对该请求进行重试。最后就变成了如上图这样的结果。</p><p>​    这种稍微放松数据一致性的设计，带来了性能上的显著提升（因为2PC，TCC的强分布式事务方案，十分影响性能，一般开发中除非是很重要很重要的节点，不然很少会采用该方案）。但这就需要客户端进行配合，它需要客户端在读取数据的时候能够容忍，或者设计方案过滤掉这些重复的数据。</p><p>​    总而言之，这是一个权衡效率还有一致性之后得出的结果。对其他分布式的系统也有比较好的借鉴意义。</p><h2 id="Master的作用"><a href="#Master的作用" class="headerlink" title="Master的作用"></a>Master的作用</h2><p>​    在GFS中master节点作用，让我有种“统筹规划”的感觉。大部分关于系统全局的决策，都是master去执行。因为，master存储了整个系统的控制信息，有了这些能够让它判断当前情况下的局部最优解。</p><h3 id="Master上的并发控制"><a href="#Master上的并发控制" class="headerlink" title="Master上的并发控制"></a>Master上的并发控制</h3><p>​    在GFS中，很多在master上面执行的操作，它的耗时其实还是挺长的。比如说：创建快照的操作，虽然它是采用了写时复制COW的策略。复制之前要撤销所有chunkserver上面的租约。</p><p>​    因为，操作耗时很长并且请求操作频繁，设计者为了提高效率，并不希望在master上面的操作是串行执行，这会导致比较严重的头阻塞现象。因此，设计者把很多操作设计成了并发。这就涉及到了如何进行master上的并发处理了。</p><p>​    但是，这要跟上面提到的chunk副本的并发写入区分开来。chunk的并发写入，关键问题其实是在于如何找到一个确定的顺序，让所有副本都严格按照该顺序进行写入。而master的并发控制，<strong>其实关键问题在于共享资源的争夺</strong>。</p><p>​    因此，在master中的资源竞争，更加以来锁机制。先来看一下，master中的namespace（存储控制信息的数据结构）是怎么设计的。</p><p><img src="/../../images/the-google-file-system/image-20211113212908421.png" alt="image-20211113212908421"></p><p>​    它这里跟传统的设计有少许不一样。因为master想要把尽可能多的控制信息一次塞入内存中。它的namespace采用了压缩树的设计。<strong>就是根据前缀不断地进行压缩。</strong>然后树上的节点就是控制信息了。（其实这里只需要知道，namespace是一种多叉树的结构）</p><p>​    了解了它的数据结构之后，就可以针对它设计并发控制了。每次对master进行操作时，只需要在对应的那部分namesapce神奇读写锁。这个可以由自己编写的程序进行控制。</p><p>​    有了这个机制之后，就可以同时在namespace上面执行多个操作了。这显然提高了系统的性能在一定程度上也让系统更合理（比如说，你对文件的读写，显然不希望写的时候有读操作之类的，并且通过锁也可以控制并发写入的数量）</p><h3 id="chunk副本的创建"><a href="#chunk副本的创建" class="headerlink" title="chunk副本的创建"></a>chunk副本的创建</h3><p>​    每个chunk副本产生无外乎三种原因：新chunk的创建，特殊情况发生需要对副本重新复制，动态平衡（让服务器的负载更均匀）。</p><p>​    master决定是否要创建一个chunk副本，并且它决定把该副本初始化到哪一个chunkserver上面。因为，master掌握系统的全局信息，根据这些全局信息，能够让它作出决策到底在哪里放置这个chunk。</p><p>​    为了让系统的负载更加均衡，master一般考虑以下因素（这些因素都可以从master存储的控制信息中统计得到）：</p><ul><li><p>把新的chunk副本<strong>部署到磁盘空间利用率比较低的chunkserver</strong>上面。这样可以平衡服务器的负荷。</p></li><li><p>不希望一台服务器上有太多new init chunk，避免new chunk的数量超过一个阈值。因为在实际情况中，一个new chunk往往意味着频繁的写入。只有它被写满的情况下才会处于read-only状态。因此，要降低它们的数量，平衡服务器的负载。</p></li><li><p>为了保证高可用性，尽量让数据不要在一个子网内，或者说不要让chunk副本过于集中在同一个物理位置。</p></li></ul><p>​    为了保证数据的高可用性，当整个系统中副本的数量小于系统规定的阈值时，master会从存活的副本中，取出一个，然后复制并部署。</p><p>​    那么这就产生一个问题，如何在存活的副本中选取呢？一般基于以下因素进行考虑：</p><ul><li><p>版本号越新的chunk，优先级越高</p></li><li><p>为了减轻复制失败的影响，提高那些正在阻塞客户端请求的chunk的优先级</p></li></ul><p>​    综合考虑上述因素之后，master就会选出一个优先级最高的chunk进行克隆。</p><p>​    最后，为了保证服务器上的负载均衡。master会定期把某些chunk从负载高的服务器移动到负载低的服务器上面。</p><h3 id="控制chunk的删除"><a href="#控制chunk的删除" class="headerlink" title="控制chunk的删除"></a>控制chunk的删除</h3><p>​    分布式的文件系统，跟内存空间一样往往存在很多碎片。为了提高空间的利用率，必须有一个比较合适的算法对这些进行收集，不然如果出现类似内存泄漏的错误，最终导致我们的系统变得十分低效。</p><p>​    在GFS中，它的回收策略设计十分巧妙，它使整个系统变得更简单并且可靠。设计者可能是借鉴了Redis中的垃圾回收策略，采用了一种“懒回收”的思想，一定程度上提高了系统的性能</p><p><strong>具体操作</strong></p><p>​    当客户端调用了一个接口进行删除文件的操作，master并不会真的马上进行删除。<strong>master首先会在operationlog里面记录下这个删除操作，然后在对应的namespace空间里作出相应的举动，然后再把该文件（或者说chunks）的删除时间记录下来，仅此而已</strong>。</p><p>​    这时候我们可以说，该文件已经被“删除”了。文件已经被隐藏起来，外界无法通过master对该文件继续进行访问。</p><p>​    等到时机合适的时候（整个系统相对空闲，CPU负载不高，或者定期清理），master通过HREATBEAT通讯信号与所有chunkserver进行沟通。master与chunkserver比对，看看什么chunk没有，没有的就进行删除，通知存储这些隐藏chunk的chunkserver执行真正的删除操作。</p><p>​    这种做法带来许多的好处：</p><ul><li><p>能够提高系统的相应速度，让系统先专注处理眼前的请求，等到相对空闲的时候再进行删除。这会让客户端的体验好很多。</p></li><li><p>显然，这种攒一波再处理的方式，有点类似Kafka的消息推送处理。这在一定程度上也是可以提高系统处理垃圾的速度，因为频繁的切换工作线程和处理线程必然会带来很多开销。</p></li><li><p>这种lazily-delete的机制，显然有一定时间的后悔期的。万一用户误删了数据，显然是能够撤回这个操作的。</p></li><li><p>在分布式系统上，错误是经常发生的，有可能有些chunk在某个server上面，但是master并不知道。因此，通过这种定期扫描和比对，可以删除掉那些不被master记录下来的chunk。</p></li></ul><p><strong>处理不可用的chunk</strong></p><p>​    master还有另外一个作用，就是处理不可用的chunk（其实这也算一种垃圾回收，不过分开来讲）。</p><p>​    在分布式系统中，错误在所难免。如果在更新版本号的时候chunkserver宕机了，没有更新成功那么该chunk就会变得不可用…或者说，chunkserver上的磁盘。总之，总会有一些意外发生导致chunk不可用，这时候就要对其进行清理了。（会server上面会通过校验和&#x2F;跟master比对版本号等操作确认该chunk是否发生意外）。</p><p>​    master确认该chunk变得不可用之后，变会启动一次删除操作，并且re-replica操作。保证系统中的数据高可用。</p><h2 id="系统的容错性"><a href="#系统的容错性" class="headerlink" title="系统的容错性"></a>系统的容错性</h2><p>​    构建分布式系统最大的挑战之一就是如何建立一个高容错的系统，在前面的总体设计中提到。构成分布式集群的机器，通常都不会采用最好的资源。因此，在整个系统中错误是必然发生的。<br>​<br>​    这导致我们不能够完全相信机器，因此需要采取一些特殊的机制去保障我们的系统能够在错误必然发生的情况下还能提供服务。</p><h3 id="提高系统的可用性"><a href="#提高系统的可用性" class="headerlink" title="提高系统的可用性"></a>提高系统的可用性</h3><p>​    GFS通过下面两种机制，提高系统的可用性：快恢复和数据备份。</p><p><strong>快恢复</strong><br>​    不管是master还是所有的chunkserver，所有节点都会定时的对自身进行一次全量备份。防止意外发生的情况下，出现数据丢失。</p><p>​    但仅仅做到这一步还是不够，因为它仅能恢复到上一次备份的时间节点上面。因此，想要节点崩溃前的状态还需要另一种机制进行支撑。节点需要把每次发生的数据变更记录到日志里面，并且在真正执行变更前，先进行日志的提交（log ahead write原则）。</p><p>​    然后通过全量备份和log，就可以把节点恢复到任意的时间点。这里是借鉴了innodb的crash-safe机制还有redis中的aof和rdb备份方式。</p><p><strong>数据备份 — master备份</strong></p><p>​    chunk的备份就不说了，上面的技术细节已经讲的很详细了。这里想要讨论的是master的备份。</p><p>​    上面的总体设计提到，为了提高整个系统的效率，对master采用了中心化的思想。也就是说全局的控制信息就只有单节点master进行提供。这种设计使得系统效率很高，但是降低了容错性。</p><p>​    虽然如此，还是可以给Master加上一些保险措施，减少它宕机的风险。为了提高系统的容错性，设计者采取了 log 和 checkpoint 的办法。在每次变更操作前，都先写入日志。然后我猜测，这个日志应该是循环写的，因此设置一checkpoint（参考我之前mysql的文章）。只要这个日志写满了，就进行刷盘，把当前的数据都持久化到硬盘。</p><p>​    因此，如果master宕机了。可以通过log还有checkpoint进行恢复，把磁盘里的备份拿出来，重放一次log里面的操作。为了进一步提高系统的容错性，这些log不仅仅存在master上，还会存储在其他机器上面，这些机器称为”shadow“。值得注意的是，这跟raflt中主节点挂了，选出一个新的主节点不同。这个shadow，只能负责读取的功能，不能对数据做修改。</p><p>​    在某种程度上来说，单master如果挂了，还是需要人工介入进行修复。虽然GFS已经通过各种措施去提高，但还是不能完全解决问题，仍旧有一点点缺陷。但是，我想这个应该是提高系统性能的代价吧。如果针对master再做一个集群的话，可能会带来比较复杂的共识问题，这应该是设计者权衡之后作出的选择吧。</p>]]></content>
    
    
    <categories>
      
      <category>数据库</category>
      
    </categories>
    
    
    <tags>
      
      <tag>分布式</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>消息队列学习笔记 - 1</title>
    <link href="/2021/11/05/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%9B%B8%E5%85%B3/message-queue-part-1/"/>
    <url>/2021/11/05/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%9B%B8%E5%85%B3/message-queue-part-1/</url>
    
    <content type="html"><![CDATA[<h2 id="消息队列可以解决哪些问题？"><a href="#消息队列可以解决哪些问题？" class="headerlink" title="消息队列可以解决哪些问题？"></a>消息队列可以解决哪些问题？</h2><p>结合我们日常的开发工作，来聊聊怎么使用消息队列。因为我实习的时候是做电商业务的，所以接下来的大部分例子，我都是以电商业务来举例。</p><h3 id="异步处理"><a href="#异步处理" class="headerlink" title="异步处理"></a>异步处理</h3><p>在电商的一个下单步骤中，大致可以分为以下步骤：</p><ul><li>前端收到请求</li><li>网关进行转发</li><li>风控</li><li>库存锁定（扣库存）</li><li>对应的购物车扣减，更新统计数据……</li></ul><p>​    如果这个步骤没有优化，并且是同步进行处理的。那么这个流程的调用链就会很长，客户端发起一个下单请求，会等待很久才能返回一个结果，这造成的用户体验是很差的。</p><!--more--><p>​    但是，上述步骤中，并不是所有操作的实时性要求都很高。<strong>经过分析，我们可以发现，只要库存锁定了，我们就可以认为，这笔订单已经生成了。其他的一些譬如统计的操作，可以让后台相对来说不那么着急执行。</strong>这实际上，是一种异步提高性能的操作，可以交给消息队列来做。</p><p><img src="/../../images/%E6%B5%85%E8%B0%88%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97-1/image-20211105215612029.png" alt="image-20211105215612029"></p><p>​    你看，这样一来，从用户的角度来看，服务的调用链就明显短了很多。可以看到，消息队列可以用作异步处理，这样做的好处有很多：</p><ul><li>缩短调用链，更快的返回结果</li><li>如果下单并发量大的情况下，可以用更多的资源去处理下单请求。等到峰值过去后，再去处理后续步骤</li><li>提高了系统的性能</li></ul><h3 id="流量控制"><a href="#流量控制" class="headerlink" title="流量控制"></a>流量控制</h3><p>​    上面说到了消息队列能够缩短调用链，异步处理我们的请求。甚至在下单请求比较多的时候，还能有比较好的效果。<strong>但是有一个值得注意的场景，如果前端收到大量的请求，直接全部涌到了调用链的入口，请求量太大超过了承受上限，那会发生什么问题呢？</strong></p><ul><li>请求太多，直接把服务打爆了，宕机下线</li><li>请求达到网关上线后，后面来的请求网关无法接收，导致请求丢失。</li></ul><p>​    上面这个，其实是电商中经常会出现的场景，因此我们需要我们的下单服务有自我保护的能力，也就是我们的服务，应该是要按照能力去处理请求，避免出现流量过大打爆服务的情况。<strong>因此，我们可以在流量的入口使用消息队列，达到隔离网关和后续服务的作用，起到了限流以及保护的作用。</strong></p><p>​    流量控制其实有两种方式，第一种就是让服务根据自身的能力往消息队列里面拿数据去消费，第二种就是通过令牌桶的形式。以上就是一般的流量控制策略，可以根据具体的场景来进行选择</p><h3 id="服务解耦"><a href="#服务解耦" class="headerlink" title="服务解耦"></a>服务解耦</h3><p>​    什么是服务之间的耦合呢？我个人的理解是，服务之间依赖关系很强。举个例子，当一个新的订单创建时，一般会有这些操作发生：</p><ul><li>支付系统，发起支付流程</li><li>物流系统更新</li><li>商家系统通知到商家</li><li>然后风控检测是否合法</li><li>…</li></ul><p>​    这些下游的服务都是依赖订单给出的数据，而且下游的服务一般也只是需要订单数据的其中一部分。随着业务的扩大，可能会新增服务或者原来的服务的接口需要改动。</p><p>​    但是每一次变更，必然需要订单系统进行修改（如果其他服务的调用，直接写在订单系统的代码里面的话），这样会十分麻烦。</p><p>​    针对这种情况，就可以通过消息队列来进行解耦。我们可以在消息队列上面发布一个<strong>TOPIC</strong>，订单服务往队列里面塞订单数据，然后下游服务就订阅该<strong>TOPIC</strong>。这样一来服务之间的耦合就解除了，订单服务就不用理会下游如何变化，是不是很方便</p><h2 id="主流消息队列组件的优缺点"><a href="#主流消息队列组件的优缺点" class="headerlink" title="主流消息队列组件的优缺点"></a>主流消息队列组件的优缺点</h2><p>​    我在鹅厂实习的时候，leader给我开小灶的时候经常说到一句话，<strong>不要抛开场景谈技术选型。必须很了解某个组件&#x2F;方案的特点，才能确定项目中为什么使用它。</strong></p><p>​    so，接下来总结一下，目前市面上常见的主流消息队列</p><h3 id="RabbitMQ"><a href="#RabbitMQ" class="headerlink" title="RabbitMQ"></a>RabbitMQ</h3><p><img src="/../../images/%E6%B5%85%E8%B0%88%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97-1/image-20211106195714386.png" alt="image-20211106195714386"></p><p>​    </p><p><strong>特点</strong></p><ul><li><p>RabbitMQ跟它的名字一样：跟兔子一样快。说明它是一个相当轻量级的消息队列，开箱即用，易于部署。</p></li><li><p>RabbitMQ还有一个比较灵活的特点，它和其他厂商的消息队列相比，多了一个<strong>Exchange</strong>。这个模块可以理解为一个交换机，它内置的路由规则十分灵活，甚至你可以配置属于自己的路有规则</p></li><li><p>客户端语言丰富，RabbitMQ支持的编程语言十分多，如果你是用一个比较少众的语言进行开发，我相信RabbitMQ会比较适合你。</p></li></ul><p><strong>缺点</strong></p><ul><li><p>RabbitMQ对消息堆积的问题不友好，没有什么好的处理方案。因为设计者认为，<strong>大量的消息堆积是一种不健康的行为，要去避免。</strong>因此当出现大量消息堆积的时候，性能会比较差。（虽然原本的性能也见不得有多好）</p></li><li><p>相对其他主流的消息队列来说，性能实在是不够看，每秒钟的处理能力在十万这个数量级。虽然说能够handle大多数的场景，<strong>但是如果你的项目对性能要求非常高，那么不建议你使用RabbitMQ。</strong></p></li><li><p>编写RabbitMQ的语言十分小众，如果到时候遇到问题要修改源码，难度有点大</p></li></ul><h3 id="RocketMQ"><a href="#RocketMQ" class="headerlink" title="RocketMQ"></a>RocketMQ</h3><p>​    阿里巴巴开源的消息队列，历经多次双十一的考验，因此它的性能和稳定性相当值得信赖。</p><p>​    在总结RockerMQ的特点的时候，似乎很难找到让人印象深刻的特点。几乎很多事情都做的很好。<strong>值得一提的是，经过几次双十一的优化，RocketMQ对业务的时延性做了不少优化，如果业务场景很在意时延，推荐使用RockerMQ。</strong></p><h3 id="Kafka"><a href="#Kafka" class="headerlink" title="Kafka"></a>Kafka</h3><p>​    Kafka，是Apache基金会下的一个消息队列的项目。在它的初衷，它是用来处理海量日志的。</p><p><strong>特点</strong></p><ul><li>Kafka与周边生态兼容性十分好，尤其是跟大数据相关的组件，都支持Kafka</li><li>Kafka的性能十分好，能够轻松达到几十万这个数量级，在配置比较好的情况下，达到百万级也挺容易的。</li><li>Kafaka采用批处理和异步发送的思想</li></ul><p><strong>缺点</strong></p><ul><li>对在线业务可能不够友好，如果时延要求低的话尽量不使用Kafka。 （因为采用了异步批处理的方式，收到消息并不会马上发送，而是会攒起来，等等再发。）</li></ul><h3 id="三种消息队列小结"><a href="#三种消息队列小结" class="headerlink" title="三种消息队列小结"></a>三种消息队列小结</h3><p>参考阿里巴巴官网给出的数据</p><table><thead><tr><th align="center">功能</th><th>RocketMQ</th><th>RocketMQ 开源</th><th>Kafka</th><th>Kafka 开源</th><th>RabbitMQ</th></tr></thead><tbody><tr><td align="center">可靠性</td><td>- 同步刷盘 <br/>- 同步双写 <br/>- 超3份数据副本</td><td>- 同步刷盘<br/>- 异步刷盘</td><td>- 同步刷盘 <br/>- 同步双写 <br/>- 超3份数据副本</td><td>异步刷盘<br/>丢数据概率极高</td><td>同步刷盘</td></tr><tr><td align="center">低延时</td><td>- 支持低延时<br/>- 效率极高</td><td>不支持</td><td>支持低延时</td><td>不支持</td><td>不支持</td></tr><tr><td align="center">定时消息</td><td>支持<br/>可精确到秒级</td><td>支持<br/>只支持18个固定 Level</td><td>不支持</td><td>不支持</td><td>支持</td></tr><tr><td align="center">事务消息</td><td>支持</td><td>不支持</td><td>不支持</td><td>不支持</td><td>不支持</td></tr><tr><td align="center">顺序消息</td><td>- 支持<br/>- 跟它的结构有关</td><td>- 支持<br/>- 跟它的结构有关</td><td>不支持</td><td>支持</td><td>不支持</td></tr><tr><td align="center">全链路消息轨迹</td><td>支持</td><td>不支持</td><td>不支持</td><td>不支持</td><td>不支持</td></tr><tr><td align="center">消息堆积能力</td><td>- 百亿级<br/>- 不影响性能</td><td>- 百亿级<br/>- 影响性能</td><td>- 百亿级<br/>- 不影响性能</td><td>不支持</td><td>不支持</td></tr><tr><td align="center">消息重试</td><td>支持</td><td>支持</td><td>不支持</td><td>不支持</td><td>支持</td></tr><tr><td align="center">消息堆积查询</td><td>支持</td><td>支持</td><td>支持</td><td>不支持</td><td>不支持</td></tr><tr><td align="center">性能 - 常规</td><td>百万级</td><td>十万级</td><td>百万级</td><td>百万级</td><td>万级</td></tr><tr><td align="center">性能 - 十万TOPIC</td><td>百万级</td><td>十万级</td><td>百万级</td><td>差</td><td>差</td></tr><tr><td align="center">性能 - 海量消息堆积场景</td><td>百万级</td><td>十万级</td><td>百万级</td><td>差</td><td>差</td></tr></tbody></table>]]></content>
    
    
    <categories>
      
      <category>数据库</category>
      
    </categories>
    
    
    <tags>
      
      <tag>中间件</tag>
      
      <tag>消息队列</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>redis单线程为什么这么快？</title>
    <link href="/2021/11/04/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%9B%B8%E5%85%B3/why-single-thread-model-in-redis-is-so-fast/"/>
    <url>/2021/11/04/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%9B%B8%E5%85%B3/why-single-thread-model-in-redis-is-so-fast/</url>
    
    <content type="html"><![CDATA[<p>​    今天我们来讨论一个问题，“为什么单线程模型的redis，会这么快？”。在我们学习redis的时候，给我们的第一感觉就是，它很快。然而，慢慢深入的学习中，我们发现redis实际上是一个单线程模型。然而单线程模型跟快，往往是矛盾的。那么，今天我们就来探讨一下这个问题，<strong>redis的单线程模型是什么，而且为什么它很快</strong>?</p><p>​    要弄明白这个问题，我们要了解redis单线程的设计以及多路复用的机制。So，let’s go！</p><h2 id="Redis单线程模型"><a href="#Redis单线程模型" class="headerlink" title="Redis单线程模型"></a>Redis单线程模型</h2><p>​    首先，我们需要搞清楚redis的单线程模型它到底指的是什么？<strong>实际上，redis的单线程模型是指Redis的网络IO和键值对读写是由一个现场完成的，该线程所做的东西，就是保证redis能够对外提供存储和读取服务。</strong></p><p>​    然而，redis的其他功能就不是由上面说的线程去做的。举个例子，redis的bgsave功能就是fork一个子进程出来，后台进行数据的备份。类似地还有很多，比如异步删除，集群的数据同步都是fork出不同的进程来进行处理。</p><h3 id="为什么redis不采用多线程？"><a href="#为什么redis不采用多线程？" class="headerlink" title="为什么redis不采用多线程？"></a>为什么redis不采用多线程？</h3><p>​    首先要明确一点，<strong>redis是一个IO密集型的程序。</strong></p><p>​    刚开始学习多线程的时候，我们听到一个说法，多线程程序能够很大的提高系统的“吞吐量”。其实不然，我们还是要结合场景去看待这个事情，要分清应用是<strong>属于CPU密集型还是IO密集型。</strong></p><p>​    那为什么不采用多线程呢？我个人觉得有以下几点的原因：</p><ul><li>原因一：多线程之间切换开销大，随着线程数目的增加，系统的吞吐率会遇到瓶颈。</li></ul><p><img src="/../../images/%E6%B5%85%E8%B0%88redis%E5%8D%95%E7%BA%BF%E7%A8%8B%E4%B8%BA%E4%BB%80%E4%B9%88%E8%BF%99%E4%B9%88%E5%BF%AB%EF%BC%9F/image-20211104161327695.png" alt="image-20211104161327695"></p><p>​    redis的性能瓶颈在于网络IO，因此即使是提高线程的数目，但是大部分还是会处于IO状态，并没有能够很好的提高系统的性能。因此，<strong>redis设计者对于该部分（处理客户端的连接）设计成了单线程。</strong></p><p>​    有人会问了，如果用一个线程去处理所有客户端的连接，这个效率会不会很慢？<strong>其实不会，这得益于Linux的IO多路复用机制</strong></p><ul><li>原因二：多线程对于共享资源的处理，有额外的开销</li></ul><figure class="highlight asciidoc"><table><tr><td class="gutter"><div class="code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></div></td><td class="code"><pre><code class="hljs asciidoc"><span class="hljs-bullet">- </span>这个就不细说了，对共享资源进行加锁，保持同步。学过操作系统的懂得都懂。<br><span class="hljs-bullet">- </span>并发访问控制一直是多线程开发中的一个难点问题，如果没有精细的设计，比如说，只是简单地采用一个粗粒度互斥锁，就会出现不理想的效果<br></code></pre></td></tr></table></figure><h3 id="redis单线程为什么快？"><a href="#redis单线程为什么快？" class="headerlink" title="redis单线程为什么快？"></a>redis单线程为什么快？</h3><p>​    通常单线程的处理能力都比较差，但是redis却能够轻松达到每秒十万级的处理能力。这我们不得不惊叹redis巧妙的设计了。</p><ul><li>redis大部分操作都在内存上完成，并且采用的数据结构十分简单且高效，因此即使是在单线程的情况下，也有很强的处理能力</li><li>另一方面，上面说了redis的瓶颈其实在于网络IO，设计者采用了<strong>IO多路复用的机制，让其能够并发处理客户端请求。</strong></li></ul><h2 id="Redis与IO多路复用"><a href="#Redis与IO多路复用" class="headerlink" title="Redis与IO多路复用"></a>Redis与IO多路复用</h2><p>​    接下来，我们来看看网络操作的IO模型（Socket编程）以及有哪些地方会引起阻塞。因为redis用单线程进行处理客户端请求，如果这个线程被阻塞了，必然会很影响redis的性能，那么我们看看redis是怎么设计的。</p><h3 id="处理一个Get请求"><a href="#处理一个Get请求" class="headerlink" title="处理一个Get请求"></a>处理一个Get请求</h3><p>以redis处理一个Get请求为例，它的步骤大致是这样的：</p><ul><li><p>Redis服务器，创建一个主动套接字（Socket），并绑定到某个端口上（bind）</p></li><li><p>服务器，监听（listen）该端口，如果客户端有请求过来，则建立一个半监听套接字</p></li><li><p>三次握手完成后，建立连接（accept），在Linux中一个TCP连接是用文件描述符Fd来表示</p></li><li><p>服务器监听该TCP连接，看是否有数据，如果有则取出来并解析。</p></li><li><p>服务器解析完请求后（假设是Get请求），则执行get命令，得到结果并通过socket返回给客户端</p></li></ul><p>​    以上这些步骤除了在本地处理get请求外，都是属于网络IO的范畴。既然是单线程，那么最普通的做法就是用一个线程去执行上面这些步骤。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">resolution</span><span class="hljs-params">()</span></span>&#123;<br><br><span class="hljs-comment">// 1.设置关键字并绑定</span><br>  <span class="hljs-comment">// 2.监听是否有客户端请求</span><br>  <span class="hljs-keyword">while</span>(<span class="hljs-literal">true</span>)&#123;<br>    Socket sc = <span class="hljs-built_in">listen</span>()  <br>      <span class="hljs-comment">// 3.完成三次握手</span><br>      <span class="hljs-built_in">accept</span>(sc)；<br>      <br>      <span class="hljs-comment">// 4.监听socket数据并解析</span><br>        <br>      <span class="hljs-comment">// 5.处理</span><br>        <br>      <span class="hljs-comment">// 6.回传结果</span><br>  &#125;<br>  <br>&#125;<br></code></pre></td></tr></table></figure><p>​    一般来说，引起阻塞的步骤其实主要有两个。步骤3（accept），如果redis监听客户端请求，得到一个监听关键字，但是客户端和服务器没有完成第三次握手，导致连接无法建立，但是我们看代码，这必然会引起其他客户端也无法跟服务器建立连接。</p><p>​    步骤四，服务器监听该socket，如果一直得不到信息，同样也会影响别的客户端。</p><p>​    这就回导致，redis效率很低。不过幸好，socket编程支持异步模式。</p><h3 id="非阻塞的Socket编程"><a href="#非阻塞的Socket编程" class="headerlink" title="非阻塞的Socket编程"></a>非阻塞的Socket编程</h3><p>其实主要有两点：</p><ul><li>针对<strong>监听套接字，</strong>监听关键字调用accept( )后，可以去处理别的事情了，即使没有收到第三次握手的请求</li><li>针对<strong>连接套接字，</strong>调用接受recv( )后，就可以去处理别的事情了，即使该Socket没有收到数据</li></ul><p>​    这种机制，就保证了Redis线程，并不会阻塞在IO的某一个步骤。虽然如此，这也仅仅保障了Redis处理客户端连接的线程不会被阻塞，但不能让他高效处理大量的客户端请求。</p><p>​    为了能处高效处理大量的客户端请求，就需要用到Linux的多路复用</p><h3 id="redis中的多路复用"><a href="#redis中的多路复用" class="headerlink" title="redis中的多路复用"></a>redis中的多路复用</h3><p>​    如果不知道多路复用是什么，可以点击—-&gt; <a href="https://www.bilibili.com/video/BV1qJ411w7du?from=search&seid=6128933502391223667&spm_id_from=333.337.0.0">IO多路复用视频</a></p><p>​    该机制下，<strong>可以同时在内核监听多个套接字。</strong>一旦有请求到达并且完成，就会把它交给redis线程去处理。这就实现了一个Redis线程，同时处理多个客户端请求的效果。</p><p><img src="/../../images/%E6%B5%85%E8%B0%88redis%E5%8D%95%E7%BA%BF%E7%A8%8B%E4%B8%BA%E4%BB%80%E4%B9%88%E8%BF%99%E4%B9%88%E5%BF%AB%EF%BC%9F/image-20211104172608591.png" alt="image-20211104172608591"></p><p>​    当内核中监听到请求到达时，就会为不同的套接字注册不同的回调函数。并把它塞到事件队列里面。</p><p>​    这些事件会被放进一个事件队列，Redis 单线程对该事件队列不断进行处理。这样一来，Redis 无需一直轮询是否有请求实际发生，这就可以避免造成 CPU 资源浪费。</p><p>​    同时，Redis 在对事件队列中的事件进行处理时，会调用相应的处理函数，这就实现了基于事件的回调（<strong>针对不同的fd，注册不同的回调函数）。</strong>因为 Redis 一直在对事件队列进行处理，所以能及时响应客户端请求，提升 Redis 的响应性能。</p><p>​    这就是Redis单线程的设计以及它的巧妙之处！</p>]]></content>
    
    
    <categories>
      
      <category>数据库</category>
      
    </categories>
    
    
    <tags>
      
      <tag>中间件</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>《代码整洁之道》 --- 写出优雅的代码</title>
    <link href="/2021/10/31/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/clean-code/"/>
    <url>/2021/10/31/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/clean-code/</url>
    
    <content type="html"><![CDATA[<h2 id="变量名"><a href="#变量名" class="headerlink" title="变量名"></a>变量名</h2><h3 id="原则一：名副其实"><a href="#原则一：名副其实" class="headerlink" title="原则一：名副其实"></a>原则一：名副其实</h3><ul><li>变量名和函数名或类名，一定要让人知道它是干什么用的。<strong>如果一个变量，需要注释来补充，则不是一个好的变量名。</strong></li></ul><figure class="highlight java"><table><tr><td class="gutter"><div class="code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></div></td><td class="code"><pre><code class="hljs java"><span class="hljs-comment">// 如果代码中到处出现d，则会让人十分困惑</span><br><span class="hljs-keyword">int</span> d ; <span class="hljs-comment">// count time in days</span><br></code></pre></td></tr></table></figure><ul><li>减少代码的<strong>模糊度</strong></li></ul><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">public</span> List&lt;<span class="hljs-keyword">int</span>[]&gt; getThem()&#123;<br>    <br>    List&lt;<span class="hljs-keyword">int</span>[]&gt; list1 = <span class="hljs-keyword">new</span> ArrayList&lt;&gt;();<br>    <span class="hljs-keyword">for</span>(<span class="hljs-keyword">int</span>[] x : theList)&#123;<br>        <br>        <span class="hljs-keyword">if</span>(x[<span class="hljs-number">0</span>] == <span class="hljs-number">4</span>)&#123;<br>            list1.add(x);<br>        &#125;<br>        <br>    &#125;<br>    <br>    <span class="hljs-keyword">return</span> list1;<br>&#125;<br></code></pre></td></tr></table></figure><p>​    <span id="more"></span></p><p>​    上面这段代码存在几个问题，有很多东西，如果不结合上下文（其他代码）来看的话，我们很难快速知道该段代码到底想表达什么东西：</p><p>（1）theList 是什么东西？类型是什么</p><p>（2）4 表达什么意思</p><p>（3）X[0]，有什么特殊的吗？</p><p>（4）List1，又是什么东西</p><p>（5）getThem又是什么意思</p><p>​    假设代码的场景，正在开发一款扫雷游戏，theList是所有单元格存储集合，[0]表示该单元格的状态，4表示已经标记。显然，list1是存储已经标记的所有单元格。因此，上述代码可以改为</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">public</span> List&lt;<span class="hljs-keyword">int</span>[]&gt; getAllTagCell()&#123;<br>    <br>    List&lt;<span class="hljs-keyword">int</span>[]&gt; tagCellList = <span class="hljs-keyword">new</span> ArrayList&lt;&gt;();<br>    <span class="hljs-keyword">for</span>(<span class="hljs-keyword">int</span>[] cell : gameboard)&#123;<br>        <br>        <span class="hljs-keyword">if</span>(cell[CELL_STATUS] == TAG_THE_CELL)&#123;<br>            tagCellList.add(x);<br>        &#125;<br>        <br>    &#125;<br>    <br>    <span class="hljs-keyword">return</span> tagCellList;<br>&#125;<br><br><span class="hljs-comment">// 甚至可以进一步封装</span><br><span class="hljs-function"><span class="hljs-keyword">public</span> List&lt;Cell&gt; <span class="hljs-title">getAllTagCell</span><span class="hljs-params">()</span></span>&#123;<br>    <br>    List&lt;Cell&gt; tagCellList = <span class="hljs-keyword">new</span> ArrayList&lt;&gt;();<br>    <span class="hljs-keyword">for</span>(Cell cell : gameboard)&#123;<br>        <br>        <span class="hljs-keyword">if</span>(Cell.isTagged())&#123;<br>            tagCellList.add(x);<br>        &#125;<br>        <br>    &#125;<br>    <br>    <span class="hljs-keyword">return</span> tagCellList;<br>&#125;<br></code></pre></td></tr></table></figure><h3 id="原则二：做有意义的区分"><a href="#原则二：做有意义的区分" class="headerlink" title="原则二：做有意义的区分"></a>原则二：做有意义的区分</h3><p>(1)变量名后加数字</p><p>​    因为同一个作用域里（通常指某个function内），不能够出现相同名字的变量。因此很常见的办法就是，在变量后面加数字。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-title">arrsTransfer</span><span class="hljs-params">(<span class="hljs-keyword">int</span>[] n1,<span class="hljs-keyword">int</span>[] n2)</span></span>&#123;<br>    <span class="hljs-keyword">for</span>(<span class="hljs-keyword">int</span> i=<span class="hljs-number">0</span>;i&lt;n1.length;i++)&#123;<br>        n1[i]=n2[i];<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>​    很显然，这是把数组n1拷贝到n2。这里有个问题，如果不写注释的情况下，很难知道是 n1 —&gt; n2，还是 n2 —&gt; n1。</p><p>​    因此，我们把n1和n2，改为destination和source。代码的可读性就好很多了。</p><p>(2)没意义的区别</p><p>​    比如说，有一个Person类，你很难说出Person，PersonInfo，People，这几个变量有什么区别。<strong>如果不做特殊约定的话</strong></p><p>​    同样，a和the也很难区分。</p><h3 id="原则三：尽量避免缩写，除非这个缩写是大家的共识"><a href="#原则三：尽量避免缩写，除非这个缩写是大家的共识" class="headerlink" title="原则三：尽量避免缩写，除非这个缩写是大家的共识"></a>原则三：尽量避免缩写，除非这个缩写是大家的共识</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Record</span></span>&#123;<br>    <span class="hljs-keyword">private</span> <span class="hljs-keyword">long</span> genymdhms;<br>    <span class="hljs-keyword">private</span> <span class="hljs-keyword">long</span> modymdhms; <span class="hljs-comment">//years month day hour minutes second</span><br>&#125;<br><br><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Record</span></span>&#123;<br>    <span class="hljs-keyword">private</span> <span class="hljs-keyword">long</span> generationTimestamp;<br>    <span class="hljs-keyword">private</span> <span class="hljs-keyword">long</span> modifyTimestamp;<br>&#125;<br></code></pre></td></tr></table></figure><p>​    如果不是大家的共识，没有人知道<code>ymdhms</code>表示什么东西。</p><h3 id="原则四：常量尽量起别名"><a href="#原则四：常量尽量起别名" class="headerlink" title="原则四：常量尽量起别名"></a>原则四：常量尽量起别名</h3><p>​    不直接使用常量，而用别名有两个好处。</p><ul><li>代码可读性更强</li><li>便于搜索</li></ul><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">public</span> List&lt;<span class="hljs-keyword">int</span>[]&gt; getThem()&#123;<br>    <br>    List&lt;<span class="hljs-keyword">int</span>[]&gt; list1 = <span class="hljs-keyword">new</span> ArrayList&lt;&gt;();<br>    <span class="hljs-keyword">for</span>(<span class="hljs-keyword">int</span>[] x : theList)&#123;<br>        <br>        <span class="hljs-keyword">if</span>(x[<span class="hljs-number">0</span>] == <span class="hljs-number">4</span>)&#123;<br>            list1.add(x);<br>        &#125;<br>        <br>    &#125;<br>    <br>    <span class="hljs-keyword">return</span> list1;<br>&#125;<br></code></pre></td></tr></table></figure><p>​    以这段代码为例子，如果直接使用0和4，我们不明白这代表什么意思。可读性很差。</p><p>​    并且在修改代码的时候，我们直接搜索4，必然会出现一大堆无关的东西，因此，我们改用别名来操作。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-keyword">const</span> (<br>CELL_STATUTE = <span class="hljs-number">0</span><br>    CELL_BE_TAGGED = <span class="hljs-number">4</span><br>)<br></code></pre></td></tr></table></figure><h3 id="原则五：每个概念一个词"><a href="#原则五：每个概念一个词" class="headerlink" title="原则五：每个概念一个词"></a>原则五：每个概念一个词</h3><ul><li>同一个类中的方法，有getXXX，fetchXXX ；findXXX，selectXXX，这种会让人很困惑。<strong>我们统一使用get，find这样会更好</strong></li><li>例如，manager，controller，driver也会让人困惑，统一manager好了</li></ul><h3 id="原则六：有意义的前缀"><a href="#原则六：有意义的前缀" class="headerlink" title="原则六：有意义的前缀"></a>原则六：有意义的前缀</h3><p>​    设想你有名为<code>firstName</code>,<code>lastName</code>,<code>street</code>,<code>houseNumber</code>,<code>city</code>。把他们放一块，很显然形成一个地址，但是单独来看就不知道是什么了。</p><p>​    可以在变量前加个前缀，就很显而易见了，例如<code>addressFirstName</code></p><h2 id="函数"><a href="#函数" class="headerlink" title="函数"></a>函数</h2><p>先看一段很糟糕的代码</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><code class="hljs java"> <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span>  String <span class="hljs-title">testableHtml</span><span class="hljs-params">(PageData pageData, <span class="hljs-keyword">boolean</span> includeSuiteSetup)</span> <span class="hljs-keyword">throws</span> Exception</span>&#123;<br><br>        WikiPage wikiPage = pageData.getWikiPage();<br>        StringBuffer buffer = <span class="hljs-keyword">new</span> StringBuffer();<br><br>        <span class="hljs-keyword">if</span>(pageData.hasAttribute(<span class="hljs-string">&quot;test&quot;</span>))&#123;<br>            <span class="hljs-keyword">if</span>(includeSuiteSetup)&#123;<br>                WikiPage suiteSetup = PageCrawlerImpl.getInheritedPage();<br>                <span class="hljs-keyword">if</span>(suiteSetup != <span class="hljs-keyword">null</span>)&#123;<br>                    WikiPagePath pagePath = suiteSetup.getFullPath();<br>                &#125;<br>            &#125;<br>        &#125;<br>        buffer.append(pageData.getContent());<br><br>        <span class="hljs-keyword">if</span>(pageData.hasAttribute(<span class="hljs-string">&quot;test&quot;</span>))&#123;<br>            <span class="hljs-keyword">if</span>(includeSuiteSetup)&#123;<br>               <br>                &#125;<br>            &#125;<br>        &#125;<br>        <br>        <br><br>        <span class="hljs-keyword">return</span> <span class="hljs-string">&quot;&quot;</span>;<br>&#125;<br></code></pre></td></tr></table></figure><p>​    这段代码不光长，而且很复杂（if判断很多，而且还是嵌套判断），有大量的字符串。导致整段代码理解起来非常费解。有太多不同层级的抽象，奇怪的字符串，以及if嵌套。</p><p>​    但是，我们可以做一点抽象和重构，就能在几行代码内就解决问题。我们看一下重构后的代码：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs java"><br><span class="hljs-keyword">private</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">final</span> string TEST_ATTRIBUTE_TAG = <span class="hljs-string">&quot;Test&quot;</span>;<br><span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> String <span class="hljs-title">renderPageWithSetupsAndTeardowns</span><span class="hljs-params">(PageData pageData,<span class="hljs-keyword">boolean</span> isSetUp)</span> throw <span class="hljs-title">Exception</span><span class="hljs-params">()</span></span>&#123;<br>    <br>    <span class="hljs-keyword">boolean</span> isTestPage = pageData.hasAttribute(TEST_ATTRIBUTE_TAG);<br>    <span class="hljs-keyword">if</span>(isTestPage)&#123;<br>        WikiPage testPage = pageData.getWikiPage();<br>        String newPageContent = <span class="hljs-keyword">new</span> StringBuffer();<br>        includeSetupPage(XXX);<br>        newPageContent.append(pageData.getContent());<br>        includeTeardownPage(XXX);<br>        pageData.setContent(newPageContent.toString());<br>    &#125;<br>    <br>    <span class="hljs-keyword">return</span> pageData.getHtml();<br>&#125;<br></code></pre></td></tr></table></figure><p>​    我们可以很清晰的看到这段代码到底干了什么事情，总的来说是两件事。处理setUpPage和TearDownPage，并且把内容塞入一个testPage中。</p><h3 id="原则一：函数应该尽可能短"><a href="#原则一：函数应该尽可能短" class="headerlink" title="原则一：函数应该尽可能短"></a>原则一：函数应该尽可能短</h3><p>​    《clean code》提倡代码最好压缩到20行左右。我个人觉得这个标准过于严苛了，做到以下几点我个人觉得就可以了</p><ul><li>如果某段中，对某个对象的几个(&gt;&#x3D;2)字段修改，最好把他进行封装</li></ul><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">People</span></span>&#123;<br>    String name;<br>    <span class="hljs-keyword">int</span> age;<br>    <span class="hljs-keyword">int</span> sex;<br>&#125;<br><span class="hljs-comment">// 重构前</span><br><span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">testFunciton</span><span class="hljs-params">(RpcReq req,RpcRsp rsp)</span></span>&#123;<br>    <br>    <span class="hljs-comment">// ......</span><br>    <br>    People people = <span class="hljs-keyword">new</span> People();<br>    people.name = req.name;<br>people.age = req.age;<br>    people.sex = req.sex;<br>    <br>    <span class="hljs-comment">// ......</span><br>&#125;<br><br><span class="hljs-comment">// 重构后</span><br><span class="hljs-function"><span class="hljs-keyword">public</span> People <span class="hljs-title">getPeopleItemByReq</span><span class="hljs-params">(RpcReq req)</span></span>&#123;<br>    People people = <span class="hljs-keyword">new</span> People();<br>    people.name = req.name;<br>people.age = req.age;<br>    people.sex = req.sex;<br><br>    <span class="hljs-keyword">return</span> people;<br>&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">testFunciton</span><span class="hljs-params">(RpcReq req,RpcRsp rsp)</span></span>&#123;<br>    <br>    <span class="hljs-comment">// ......</span><br>    <br>    People people = getPeopleItemByReq(req);<br>    <br>    <span class="hljs-comment">// ......</span><br>&#125;<br><br><br></code></pre></td></tr></table></figure><ul><li>处理逻辑进行分装，保证每段处理逻辑只做一件事</li></ul><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">private</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">final</span> string TEST_ATTRIBUTE_TAG = <span class="hljs-string">&quot;Test&quot;</span>;<br><span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> String <span class="hljs-title">renderPageWithSetupsAndTeardowns</span><span class="hljs-params">(PageData pageData,<span class="hljs-keyword">boolean</span> isSetUp)</span> throw <span class="hljs-title">Exception</span><span class="hljs-params">()</span></span>&#123;<br>    <br>    <span class="hljs-keyword">boolean</span> isTestPage = pageData.hasAttribute(TEST_ATTRIBUTE_TAG);<br>    <span class="hljs-keyword">if</span>(isTestPage)&#123;<br>        WikiPage testPage = pageData.getWikiPage();<br>        String newPageContent = <span class="hljs-keyword">new</span> StringBuffer();<br>        includeSetupPage(XXX);<br>        newPageContent.append(pageData.getContent());<br>        includeTeardownPage(XXX);<br>        pageData.setContent(newPageContent.toString());<br>    &#125;<br>    <br>    <span class="hljs-keyword">return</span> pageData.getHtml();<br>&#125;<br></code></pre></td></tr></table></figure><p>​    像这段代码，把setupPage和includeTeardown的处理逻辑封装了，然后封装之后因为他们是同层级的功能，又能封装一次，就让函数非常简洁</p><ul><li>一个函数内，尽量少if。if内的条件，以及后续的处理逻辑，也可以进行封装<ul><li>建议if里面不要再嵌套if，除非实在没办法</li></ul></li></ul><h3 id="原则二：只做一件事情"><a href="#原则二：只做一件事情" class="headerlink" title="原则二：只做一件事情"></a>原则二：只做一件事情</h3><p>​    一开始的那段代码，做了很多事情。(1)创建传冲去 (2)获取页面信息 (3)渲染路径 (4)添加字符串…但是重构之后，就变得简单了很多，制作了一件事，把setup和tearDown放入到测试页面中。其他事情，放到如何getSetUpPage和tearDownPage中。</p><p><strong>如何判断该函数是否符合只做一件事的标准？我个人觉得符合下面条件就可以了</strong></p><ul><li>函数做的事情，跟函数名描述的一样</li><li>函数是否再继续拆分</li><li>但是，没必要过于追求函数只做一件事，个人觉得，函数里面所做的事情，都是同一层级的，那问题也不大，我们把该函数封装起来就好了，因为追求所有函数都只做一件事是很难的。<strong>应该追求的是，大部分的函数都只做一件事</strong></li></ul><h3 id="原则三：每个函数一个抽象层级"><a href="#原则三：每个函数一个抽象层级" class="headerlink" title="原则三：每个函数一个抽象层级"></a>原则三：每个函数一个抽象层级</h3><p><strong>自顶向下规则</strong></p><ul><li>该函数，要做设置和拆分<ul><li>设置<ul><li>如果这是套件，则套件设置步骤<ul><li>套件设置步骤：XXXX</li></ul></li><li>如果不是套件，则普通步骤<ul><li>普通步骤:XXXX</li></ul></li></ul></li><li>拆分</li></ul></li></ul><h3 id="原则四：switch-和-if-else"><a href="#原则四：switch-和-if-else" class="headerlink" title="原则四：switch 和 if else"></a>原则四：switch 和 if else</h3><p>​    写出短小的switch语句很难，因为switch这个语法就是定义为做同多件事情。我们看一下下面这段代码</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs java"><br><span class="hljs-function"><span class="hljs-keyword">public</span> Money <span class="hljs-title">caculatePay</span><span class="hljs-params">(Employee e)</span></span>&#123;<br>    <span class="hljs-keyword">switch</span>(e.type)&#123;<br>        <span class="hljs-keyword">case</span> COMMISSIONED:<br>            caculateCommissionPay(e);<span class="hljs-keyword">break</span>;<br>        <span class="hljs-keyword">case</span> HOURLY:<br>            caculateHourlyPay(e);<span class="hljs-keyword">break</span>;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>这段代码有两个比较重大的问题：</p><ul><li>如果Employee添加新的type，那么必需修改该函数 <strong>（我们期望的当然是改动越小越好）</strong></li><li>显然类似结构的代码会在很多地方，如果新加类型，改动就会非常大了</li></ul><p>​    这种问题的根本原因是几个不同type的Employee耦合在了一起，那么解决方案就是把switch隐藏在工厂方法的底层。那么只要创建Employee的时候，指定type就好了</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs java"><br><span class="hljs-keyword">public</span> <span class="hljs-keyword">abstract</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Employee</span></span>&#123;<br>    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-title">caculatedPay</span><span class="hljs-params">()</span></span>;<br>    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-title">payDate</span><span class="hljs-params">()</span></span>;<br>&#125;<br><br><span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">SalaryEmployee</span> <span class="hljs-title">extend</span> <span class="hljs-title">Employee</span></span>&#123;<br>    <span class="hljs-comment">//...</span><br>&#125;<br><br><span class="hljs-keyword">public</span> calss HourlyEmployee extend Employee&#123;<br>    <br>&#125;<br><span class="hljs-comment">// 工厂</span><br><span class="hljs-function"><span class="hljs-keyword">public</span> class <span class="hljs-title">EmployFactory</span><span class="hljs-params">()</span></span>&#123;<br>    <span class="hljs-function">Employee <span class="hljs-title">makeEmployee</span><span class="hljs-params">(<span class="hljs-keyword">int</span> emlpoyeeType)</span></span>&#123;<br>        <span class="hljs-keyword">switch</span>(employeeType)&#123;<br>            <span class="hljs-keyword">case</span> SALARY:<br>                <span class="hljs-keyword">return</span> <span class="hljs-keyword">new</span> SalaryEmployee();<br>            <span class="hljs-keyword">case</span> HOURLY:<br>                <span class="hljs-keyword">return</span> <span class="hljs-keyword">new</span> HourlyEmployee();<br>        &#125;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>​    把type隐藏在工厂方法里面，上述的问题大部分都能够解决。并且代码的可拓展性会变得更好。</p><h3 id="原则五：起一个好的函数名"><a href="#原则五：起一个好的函数名" class="headerlink" title="原则五：起一个好的函数名"></a>原则五：起一个好的函数名</h3><ul><li>不要害怕长名称，长名称总比短而令人费解的名称好</li><li>命名方式保持一致</li></ul><p>目前遇到起名很烦躁的情况是Dao层，给自己定下这些规范</p><p><strong>(1)主键 &#x2F; 唯一键查询</strong></p><p>Select + XXX + By + PrimaryKey</p><p><strong>(2)批量查询</strong></p><p>Find + XXX + By + field1_field2…</p><h3 id="原则六：尽量减少函数参数"><a href="#原则六：尽量减少函数参数" class="headerlink" title="原则六：尽量减少函数参数"></a>原则六：尽量减少函数参数</h3><div class="code-wrapper"><pre><code class="hljs"> 对于函数的参数 0个最好，1个可以接受，2个还行，3个底线，超过3个不能接受。如果传递真的超过三个，考虑以下两个方面：</code></pre></div><ul><li>能不能做函数拆分？</li><li>把参数进行封装</li></ul>]]></content>
    
    
    <categories>
      
      <category>笔记</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>开发中遇到的一些问题</title>
    <link href="/2021/10/07/the-problems-of-using-git/"/>
    <url>/2021/10/07/the-problems-of-using-git/</url>
    
    <content type="html"><![CDATA[<h2 id="git回滚"><a href="#git回滚" class="headerlink" title="git回滚"></a>git回滚</h2><p><img src="/../images/the-problems-of-using-git/image-20211107185612968.png" alt="image-20211107185612968"></p><h3 id="–hard"><a href="#–hard" class="headerlink" title="–hard"></a>–hard</h3><p>​    直接回滚到那个版本提交完的时候</p><h3 id="–soft"><a href="#–soft" class="headerlink" title="–soft"></a>–soft</h3><p>​    回到那个版本，但此时更新的操作，仍在缓存区</p><h3 id="–mixed"><a href="#–mixed" class="headerlink" title="–mixed"></a>–mixed</h3><p>​    回到那个版本，更新的操作在工作区，还没add</p><h2 id="golang-m1-编译的问题"><a href="#golang-m1-编译的问题" class="headerlink" title="golang m1 编译的问题"></a>golang m1 编译的问题</h2><figure class="highlight gradle"><table><tr><td class="gutter"><div class="code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></div></td><td class="code"><pre><code class="hljs gradle">bartonhuang@BARTONHUANG-MB3 MVPPayCustomerServer % go build<br># github.com<span class="hljs-regexp">/shirou/g</span>opsutil/cpu<br>..<span class="hljs-regexp">/../</span>..<span class="hljs-regexp">/../g</span>o_path<span class="hljs-regexp">/pkg/m</span>od<span class="hljs-regexp">/github.com/</span>shirou<span class="hljs-regexp">/gopsutil@v2.19.12+incompatible/</span>cpu/cpu_darwin_cgo.go:<span class="hljs-number">13</span>:<span class="hljs-number">5</span>: warning: <span class="hljs-string">&#x27;TARGET_OS_MAC&#x27;</span> is not defined, evaluates to <span class="hljs-number">0</span> [-Wundef-prefix=TARGET_OS_]<br><br></code></pre></td></tr></table></figure><p>解决办法：</p><ul><li>go get github.com&#x2F;shirou&#x2F;gopsutil</li></ul>]]></content>
    
    
    <categories>
      
      <category>笔记</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>浅谈数据库的锁(二)</title>
    <link href="/2021/10/06/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%9B%B8%E5%85%B3/database-lock/"/>
    <url>/2021/10/06/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%9B%B8%E5%85%B3/database-lock/</url>
    
    <content type="html"><![CDATA[<h3 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h3><p>​    今天这篇文章，讲的主要是下面两个内容：(1)gap lock 和 next - key lock (2)锁，到底是锁的是什么东西？</p><p><strong>并且想要解决几个令人困惑的问题</strong></p><ul><li><p>在主键，唯一键，普通索引，以及非索引字段加锁，究竟锁住来了什么东西？</p></li><li><p>不同的查询条件，锁住什么东西？</p></li><li><p>条件中的等值不存在，锁住什么？</p></li></ul><span id="more"></span><h3 id="间隙锁-gap-lock"><a href="#间隙锁-gap-lock" class="headerlink" title="间隙锁 gap lock"></a>间隙锁 gap lock</h3><p>​    为什么有间隙锁，其实这个是幻读带来的。产生幻读的原因在之前的文章说过了，(1)通过条件查询 (2)应用层逻辑判断 (3)根据条件进行DML操作。</p><p>​    如果一个事务符合这三个特点，就很可能有幻读的问题。因为(3)的DML操作的前提条件依赖(1)的一致性试图。但是如果有别的事务，破坏了这个条件，并且在当前事务执行(3)之前先提交了。那么(3)它依赖的条件，虽然在当前条件的视图中看起来是自洽的，但是实际上前提条件已经被破坏。这就是幻读产生的原因。</p><p>​    因此，需要一个锁，把(1)中查询出来的全部锁住。不仅如此，甚至对”不存在的，并且在条件范围内的也要锁住“，参考<strong>创建用户名的例子</strong></p><p>​    so，gap lock应运而生。</p><p><strong>接下的讨论基本都是在此表的基础上展开</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><div class="code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></div></td><td class="code"><pre><code class="hljs mysql">CREATE TABLE `t` (<br>  `id` int(11) NOT NULL,<br>  `c` int(11) DEFAULT NULL,<br>  `d` int(11) DEFAULT NULL,<br>  PRIMARY KEY (`id`),<br>  KEY `c` (`c`)<br>) ENGINE=InnoDB;<br><br>insert into t values<br>(0,0,0),(5,5,5),<br>(10,10,10),(15,15,15),<br>(20,20,20),(25,25,25);<br></code></pre></td></tr></table></figure><h4 id="gap-lock-如何解决幻读"><a href="#gap-lock-如何解决幻读" class="headerlink" title="gap lock 如何解决幻读"></a>gap lock 如何解决幻读</h4><p>​    产生幻读的原因是，行锁只能锁住行，但是新插入记录这个动作，要更新的是记录之间的“间隙”。</p><p>​    因此，为了解决幻读问题，InnoDB 只好引入新的锁，也就是间隙锁 (Gap Lock)。 </p><p><img src="/../../images/%E6%B5%85%E8%B0%88%E6%95%B0%E6%8D%AE%E5%BA%93%E4%B8%AD%E7%9A%84%E9%94%81/1633519488361.png" alt="1633519488361"></p><p>​    然后，如何解决幻读呢？如上图，其实根据(1)条件进行查询之后，会对那些间隙进行加锁。只要间隙上面有了锁，那么其他事务无法对其进行DML操作。</p><p>​    and,我们还要讨论一下，gap lock阻塞的是什么东西。其实很简单，就两个特点：</p><ul><li>跟gap lock发生冲突的是 往间隙里面进行插入操作</li><li>gap lock 跟 gap lock之间是不冲突的。<ul><li>(0,10)和(2,9)或者( 1,11)都是不冲突的</li><li>间隙之间有无交集都是不冲突的</li></ul></li></ul><h4 id="next-key-lock-间隙锁升级"><a href="#next-key-lock-间隙锁升级" class="headerlink" title="next - key lock 间隙锁升级"></a>next - key lock 间隙锁升级</h4><p>​     间隙锁和行锁合称 next-key lock，每个 next-key lock 是前开后闭区间。 如果上面，那个表用了<code>select * from t for update</code>。那么就会出现七个next-key lock。</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs">(-∞,0]、(0,5]、(5,10]、(10,15]、(15,20]、(20, 25]、(25, +supremum]<br></code></pre></td></tr></table></figure><h3 id="锁到底锁的是什么？"><a href="#锁到底锁的是什么？" class="headerlink" title="锁到底锁的是什么？"></a>锁到底锁的是什么？</h3><p><strong>1.以下讨论的都是写锁(排他锁)，share mode没必要讨论</strong></p><p><strong>2.都是基于上面创建的表，进行讨论</strong></p><p>要讨论锁到底锁的是什么，大致要分以下几种情况来讨论：</p><ul><li>主键(唯一索引)，条件命中</li><li>主键(唯一索引)，条件不命中 &#x2F; 条件模糊</li><li>普通索引，条件命中</li><li>普通字段，条件命中</li></ul><h4 id="主键，条件命中"><a href="#主键，条件命中" class="headerlink" title="主键，条件命中"></a>主键，条件命中</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs mysql"># session1<br>begin;<br>select * from t where  id = 5 for update;<br></code></pre></td></tr></table></figure><p><img src="/../../images/%E6%B5%85%E8%B0%88%E6%95%B0%E6%8D%AE%E5%BA%93%E4%B8%AD%E7%9A%84%E9%94%81/1633523911801.png" alt="1633523911801"></p><p>ok,我们来看一下，这种情况下的锁是怎么样的。<strong>在主键存在的情况下，加锁的情况是这样的：</strong></p><ul><li>只有命中的那条数据，加上了row lock</li><li>主键命中的情况不存在gap lock</li></ul><p><img src="/../../images/%E6%B5%85%E8%B0%88%E6%95%B0%E6%8D%AE%E5%BA%93%E4%B8%AD%E7%9A%84%E9%94%81/1633525680043.png" alt="1633525680043"></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs mysql"># 主键命中的情况下，只有那条数据加行锁<br>select * from t where id = 0 for update;# no block<br>update t set c = 1 where id = 0;# no block<br>insert into t values(4,4,4);# no block<br>select * from t where id = 5 for update;# block<br></code></pre></td></tr></table></figure><p><img src="/../../images/%E6%B5%85%E8%B0%88%E6%95%B0%E6%8D%AE%E5%BA%93%E4%B8%AD%E7%9A%84%E9%94%81/1633524009750.png" alt="1633524009750"></p><p><img src="/../../images/%E6%B5%85%E8%B0%88%E6%95%B0%E6%8D%AE%E5%BA%93%E4%B8%AD%E7%9A%84%E9%94%81/1633524119971.png" alt="1633524119971"></p><p><img src="/../../images/%E6%B5%85%E8%B0%88%E6%95%B0%E6%8D%AE%E5%BA%93%E4%B8%AD%E7%9A%84%E9%94%81/1633524553095.png" alt="1633524553095"></p><h4 id="主键，条件不命中"><a href="#主键，条件不命中" class="headerlink" title="主键，条件不命中"></a>主键，条件不命中</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs mysql"># session1<br>begin;<br>select * from t where  id = 4 for update;<br></code></pre></td></tr></table></figure><p><img src="/../../images/%E6%B5%85%E8%B0%88%E6%95%B0%E6%8D%AE%E5%BA%93%E4%B8%AD%E7%9A%84%E9%94%81/1633524712913.png" alt="1633524712913"></p><p>在条件不命中的情况下，锁是这样的：</p><ul><li>行与行之间加上gap lock</li><li>所有<strong>行记录都不加row lock</strong></li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs mysql"># session2<br>select * from t where id = 0 for update;# no block<br>select * from t where id = 5 for update;# no block<br>select * from t where id = 2 for update;# no block<br>update t set c = 1 where id = 0;# no block<br>insert into t values(4,4,4);# block gap lock 阻塞了insert操作<br></code></pre></td></tr></table></figure><p><img src="/../../images/%E6%B5%85%E8%B0%88%E6%95%B0%E6%8D%AE%E5%BA%93%E4%B8%AD%E7%9A%84%E9%94%81/1633524903236.png" alt="1633524903236"></p><h4 id="索引，条件命中"><a href="#索引，条件命中" class="headerlink" title="索引，条件命中"></a>索引，条件命中</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs mysql"># session1<br>begin;<br>select * from t where  c = 5 for update;<br></code></pre></td></tr></table></figure><p><img src="/../../images/%E6%B5%85%E8%B0%88%E6%95%B0%E6%8D%AE%E5%BA%93%E4%B8%AD%E7%9A%84%E9%94%81/1633526324007.png" alt="1633526324007"></p><p>普通索引，条件命中的情况下，锁的情况是这样的：</p><ul><li>命中的，<strong>是行锁，行锁加在主键上</strong></li><li>其余是<strong>gap lock，gap lock加在其他索引树上(在该表中，加载索引c的b树上</strong></li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs mysql"># session2<br><br># 对于差出来的数据，加的是行锁<br>select * from t where id = 0 for update;# block<br>select * from t where id = 5 for update;# block<br><br># 貌似对 字段c的索引树，加了gap lock<br>update t set c = 4 where id = 0;# block id=0有行锁被阻塞<br>update t set c = 5 where id = 10;# next-key lock阻塞<br><br># gap lock。这个插入失败，我觉得是在 c索引树插入node失败了<br>insert into t values(4,4,4);# block gap lock<br><br># gap lock只是加在c索引树上<br>update t set d = 5 where id = 10;# no block <br><br># 因为查出来的是行锁，被阻塞住了<br>update t set d = 5 where id = 5;# block<br></code></pre></td></tr></table></figure><ul><li>对于查索引命中的行，加的是行锁。</li></ul><p><img src="/../../images/%E6%B5%85%E8%B0%88%E6%95%B0%E6%8D%AE%E5%BA%93%E4%B8%AD%E7%9A%84%E9%94%81/1633601439484.png" alt="1633601439484"></p><p><img src="/../../images/%E6%B5%85%E8%B0%88%E6%95%B0%E6%8D%AE%E5%BA%93%E4%B8%AD%E7%9A%84%E9%94%81/1633601727061.png" alt="1633601727061"></p><p>​    id &#x3D; 25,不是查出来的数据，可以更新d字段。</p><p>​    <strong>个人认为，行锁是加在主键上的，这样可以避免 通过别的索引，修改已经查出来的行</strong></p><ul><li>在对应的索引树上，加gap lock。不影响其他索引树</li></ul><p><img src="/../../images/%E6%B5%85%E8%B0%88%E6%95%B0%E6%8D%AE%E5%BA%93%E4%B8%AD%E7%9A%84%E9%94%81/1633602359760.png" alt="1633602359760"></p><p>(1)对于<code>update t set d = 5 where id = 10</code></p><p>​    因为，行锁只加在查询出的(id &#x3D; 0 和 id &#x3D; 5)两条数据里。gap lock是加载字段c的索引上。当这条记录更新完成，并不会更新<strong>字段c的索引树。</strong>因此能够运行</p><p>(2)对于<code>update t set c = 4 where id = 0</code></p><p>​    显然是因为行锁，这语句被阻塞了。</p><p>(3)对于<code>update t set c = 5 where id = 10</code></p><p>​    id &#x3D; 10不是查出来的数据，但是对行记录更新完成后，因为操作的是索引字段c，因此需要对字段c的索引树进行修改。修改索引树的过程遇到gap lock被阻塞了</p><h4 id="索引，条件不命中"><a href="#索引，条件不命中" class="headerlink" title="索引，条件不命中"></a>索引，条件不命中</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs mysql"># session1<br>begin;<br>select * from t where c = 4 for update;<br></code></pre></td></tr></table></figure><p><img src="/../../images/%E6%B5%85%E8%B0%88%E6%95%B0%E6%8D%AE%E5%BA%93%E4%B8%AD%E7%9A%84%E9%94%81/1633526953542.png" alt="1633526953542"></p><p>该情况下，加锁的情况：</p><ul><li>只对整个字段c索引树加gap lock</li><li>不存在 row lock</li></ul><p><strong>原因不解释了，跟上面的差不多</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs mysql"># session2<br>begin;<br>select * from t where id = 0 for update;# no block<br>select * from t where id = 2 for update;# no block<br>select * from t where id = 5 for update;# no block<br>select * from t where id = 10 for update;# no block<br>insert into t values(4,4,4);# block<br>update t set c = 4 where id = 0;# block<br>update t set d = 100 where id = 10;# no block<br></code></pre></td></tr></table></figure><h4 id="普通字段"><a href="#普通字段" class="headerlink" title="普通字段"></a>普通字段</h4><p>表中的数据</p><p><img src="/../../images/%E6%B5%85%E8%B0%88%E6%95%B0%E6%8D%AE%E5%BA%93%E4%B8%AD%E7%9A%84%E9%94%81/1633603077198.png" alt="1633603077198"></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs mysql"># session1<br>begin;<br>select * from t where d = 5 for update;<br></code></pre></td></tr></table></figure><p><strong>对于非索引字段，整个表都是加的表锁</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs mysql"># session2<br>select * from t where id = 0 for update;<br>select * from t where id = 10 for update;<br>select * from t where c = 10 for update;<br></code></pre></td></tr></table></figure><h4 id="行锁到底锁的是主键还是普通索引？"><a href="#行锁到底锁的是主键还是普通索引？" class="headerlink" title="行锁到底锁的是主键还是普通索引？"></a>行锁到底锁的是主键还是普通索引？</h4><p>​    为了验证我们的想法，我们需要在原来的表中，新建一个索引。这个索引就建在字段C上面吧</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs mysql">create index `field_d`<br>on t(`d`);<br></code></pre></td></tr></table></figure><p><img src="/../../images/%E6%B5%85%E8%B0%88%E6%95%B0%E6%8D%AE%E5%BA%93%E4%B8%AD%E7%9A%84%E9%94%81/1633604169520.png" alt="1633604169520"></p><p><img src="/../../images/%E6%B5%85%E8%B0%88%E6%95%B0%E6%8D%AE%E5%BA%93%E4%B8%AD%E7%9A%84%E9%94%81/1633604640176.png" alt="1633604640176"></p><p>​    ok，现在原来的表中有两个普通索引c和d了。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs mysql"># session1<br>begin;<br>select * from t where c = 5; # 对id = 5的加行锁 (目前不清楚行锁在哪)<br><br># session2<br>begin * from t where d = 5; # 对 id = 0 和 5 加行锁<br></code></pre></td></tr></table></figure><p>分析：</p><ul><li>已知，索引树c和索引树d是独立的。</li><li>如果行锁加载索引树上，那么索引树c上对id&#x3D;5的加行锁，不影响在索引树d对id&#x3D;5加行锁</li><li>如果加载主键上，必然被阻塞。</li></ul><p><img src="/../../images/%E6%B5%85%E8%B0%88%E6%95%B0%E6%8D%AE%E5%BA%93%E4%B8%AD%E7%9A%84%E9%94%81/1633604773965.png" alt="1633604773965"></p><p>​    ok，索引树d的操作被阻塞了，显然，行锁是加在主键上的。</p>]]></content>
    
    
    <categories>
      
      <category>数据库</category>
      
    </categories>
    
    
    <tags>
      
      <tag>MySQL</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>数据库的隔离性</title>
    <link href="/2021/10/05/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%9B%B8%E5%85%B3/MySQL%E7%9A%84%E9%9A%94%E7%A6%BB%E6%80%A7/"/>
    <url>/2021/10/05/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%9B%B8%E5%85%B3/MySQL%E7%9A%84%E9%9A%94%E7%A6%BB%E6%80%A7/</url>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>​    大多数数据库都是支持多个客户端同时访问。如果读取得是不同得数据，那肯定没有什么问题；但如果访问相同得记录，就可能遇到并发问题。<br>​<br>​    而且，网上大部分的文章都是谈论 “读-写并发“带来的问题，但”写-写并发“讨论的很少。再进一步说，对于<strong>幻读</strong>，解决的办法一般也是指可串行化，但是2PC的可串行化会让数据库的效率很低很低。<br>​<br>​    因此，下面想谈谈数据库的隔离性。</p><p><img src="/../../images/%E6%B5%85%E8%B0%88MySQL%E7%9A%84%E9%9A%94%E7%A6%BB%E6%80%A7/1633436392828.png" alt="1633436392828"></p><!--more--><h2 id="读-提交"><a href="#读-提交" class="headerlink" title="读-提交"></a>读-提交</h2><p>&amp;#8195;&amp;#8195;读-提交是最基本的事务隔离级别，它只是提供以下两个保证。</p><ul><li>读数据时，只能看到已经成功提交的数据  <strong>(防止脏读)</strong></li><li>写数据时，不会覆盖已经已经提交成功的数据 <strong>(防止脏写)</strong></li></ul><p><strong>防止脏写 写写并发</strong></p><p>&amp;#8195;&amp;#8195;如果两个事务同时尝试更新相同的对象，会发生什么情况呢？我们不清楚写入的顺序，但可以想象后写的操作，会覆盖较早写入的操作。</p><table><thead><tr><th align="center">Session A</th><th align="center">Session B</th></tr></thead><tbody><tr><td align="center">begin</td><td align="center">begin</td></tr><tr><td align="center">update data &#x3D; 123</td><td align="center"></td></tr><tr><td align="center"></td><td align="center">update data &#x3D; 456</td></tr><tr><td align="center">commit</td><td align="center">commit</td></tr></tbody></table><p>&amp;#8195;&amp;#8195;很显然，如果不做什么特殊的处理，那么seesionB的写入会覆盖A的写入。</p><p><strong>如果A在提交前，需要查询一次data，然后交付应用层进行处理的话，很显然就会出现逻辑上的错误。</strong></p><p><strong>防止脏写能避免这些问题</strong></p><ul><li>当一个记录，被两个事务同时写入的时候。能够避免 旧的写入被覆盖掉</li></ul><h3 id="如何实现读提交？"><a href="#如何实现读提交？" class="headerlink" title="如何实现读提交？"></a>如何实现读提交？</h3><p>数据库通常<strong>使用行锁来防止脏写</strong>：</p><ul><li>当事务想修改某个对象时，需要获得这个对象的写锁</li><li>然后一直持有该锁，知道事务被提交</li><li>另一个事务想获得锁，如果失败，则会被阻塞</li></ul><p>那数据库如何<strong>防止脏读</strong>：</p><ul><li>当事务想要读取某个对象时，那就给对象加一个读锁</li><li>如果此时有事务想要修改，那就要加写锁，但是读锁，写锁互斥。所以写锁加不上去</li><li>同理，如果某个对象有写锁，那么读锁也加不上去。</li></ul><h2 id="MVCC-和-可重复读"><a href="#MVCC-和-可重复读" class="headerlink" title="MVCC 和 可重复读"></a>MVCC 和 可重复读</h2><p>&amp;#8195;&amp;#8195;表面上，读-提交这个隔离级别，可能会认为它已经满足了事务所需要的一切特征。但是，还是字面意思，如果一个事务的过程中，如果两次查询不一样，那么肯定是不行的。</p><p>我们看一个例子</p><p><img src="/../../images/%E6%B5%85%E8%B0%88MySQL%E7%9A%84%E9%9A%94%E7%A6%BB%E6%80%A7/1633437092102.png" alt="1633437092102"></p><p>&amp;#8195;&amp;#8195;两次，查询不一样，显然不行的。我们，其实更想要的是，在事务开启，到事务的提交。在这段时间里，我们对同一个对象的查询结果是 <strong>一致的，自洽的</strong></p><p>&amp;#8195;&amp;#8195;快照级别是解决上面问题最常见的手段。其总体想法是，每个事务都从数据库的一致性快照中读取。然后，每次查询，都从这个一致性快照里面进行查询。因此，在这个事务的生存期间，读到数据，都是自洽的。</p><h3 id="如何实现MVCC"><a href="#如何实现MVCC" class="headerlink" title="如何实现MVCC"></a>如何实现MVCC</h3><p>&amp;#8195;&amp;#8195;在事务启动的时候，就会”拍一个快照”。<strong>这个快照是基于整个库的。</strong>我们看一下，这个快照是怎么执行的。</p><p>&amp;#8195;&amp;#8195;InnoDB引擎中，开启一个事务的时候，会分配一个 transaction ID，这个是完全严格递增的。</p><p>&amp;#8195;&amp;#8195;然后，每个数据都有很多个版本。当一个事务对某个对象进行更新时，会生成一条记录，大致是<code>transaction id | 对象的值 | 上一条记录的位置</code></p><p><img src="/../../images/%E6%B5%85%E8%B0%88MySQL%E7%9A%84%E9%9A%94%E7%A6%BB%E6%80%A7/1633438091862.png" alt="1633438091862"></p><p>​    上图，是一个对象的若干个版本。 <strong>分别由事务id是10，15，17，25来更新的。</strong></p><p>​    当一个事务启动时，会产生一个快照，这个快照其实是一个数组。里面的内容都是<strong>在当前事务启动时，所有还没提交的事务id。</strong> </p><p>​    so,read - view &#x3D; [ 事务id1(低水位)，事务id2….事务idN(一般是当前事务)(高水位)]</p><p><img src="/../../images/%E6%B5%85%E8%B0%88MySQL%E7%9A%84%E9%9A%94%E7%A6%BB%E6%80%A7/1633438516538.png" alt="1633438516538"></p><p>​    那么，我们就分情况来讨论一下可见性。当我们遍历，对象的版本链时，可以根据它的版本ID进行可见判断，分为以下几种情况</p><ul><li>版本ID &lt; 低水位<ul><li>表明，这个版本，在事务启动之前就已经提交了，因此当前事务是能看见的</li></ul></li><li>版本ID &gt; 高水位<ul><li>说明，这个版本，是事务启动之后才提交的，当前事务是无法看见这个版本</li></ul></li><li>版本ID 在两个水位之间<ul><li>如果版本ID，不在事务的Read-View中，显然还是能看见的。<strong>因为Read-View记录的是，事务启动时，仍然没被提交的事务ID。所以，如果版本ID不在Read-View中，那么这个版本必然是被提交的</strong></li><li>如果版本ID，在Read-View中，显然，是不可见的。</li></ul></li></ul><h3 id="当前读"><a href="#当前读" class="headerlink" title="当前读"></a>当前读</h3><p>​    如果事务启动之后，执行update操作，那么一般来说是在最新的版本上面更新的。</p><h2 id="防止更新丢失"><a href="#防止更新丢失" class="headerlink" title="防止更新丢失"></a>防止更新丢失</h2><p>​    当目前为止，所讨论的<strong>读-提交</strong>和<strong>Read-View</strong>，都是只解读事务遇到并发时可以看到什么**(读-写并发)。**</p><p>​    总体来说，还没有真正解决两个写事务之间的并发。</p><p>​    当两个事务在同样的数据对象执行类似操作，由于隔离性，后写的操作，不知道前写的事务做了什么东西。因此，会导致第一次写的记录，会丢失。例如：</p><ul><li>两个用户同时编辑一个wiki页面，so，必然后保存的人，会覆盖前写的内容。</li></ul><h3 id="CAS自动检测冲突"><a href="#CAS自动检测冲突" class="headerlink" title="CAS自动检测冲突"></a>CAS自动检测冲突</h3><p>​    如果两个事务并发写同一个对象。可以借鉴CAS的思想来进行检测冲突。</p><p>​    每次update的时候做一次 Compare and Set操作，如果CAS成功则提交该事务。如果CAS失败，则放弃并终止这个事务。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><div class="code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></div></td><td class="code"><pre><code class="hljs mysql">-- 原子并发<br>update table set field = &#x27;new content&#x27;<br>where id = &#x27;111&#x27; and field = &#x27;old content&#x27;;<br></code></pre></td></tr></table></figure><h3 id="多数据副本的写并发"><a href="#多数据副本的写并发" class="headerlink" title="多数据副本的写并发"></a>多数据副本的写并发</h3><p>​    参考，多数据重新的数据同步，采用lamport时间戳，来进行同步。</p><p><strong>其他加锁的操作，防止写并发较为常见，不展开了</strong></p><h2 id="幻读和可串行化"><a href="#幻读和可串行化" class="headerlink" title="幻读和可串行化"></a>幻读和可串行化</h2><p>​    下面来讲讲幻读。首先想到一个这样的场景，某个医院的调班制度是这样的:如果当前值班的人数大于2，那么就可以调班。如果事务是按照，下面的顺序进行执行的话，就会出现错误。</p><p><img src="/../../images/%E6%B5%85%E8%B0%88MySQL%E7%9A%84%E9%9A%94%E7%A6%BB%E6%80%A7/1633441183758.png" alt="1633441183758"></p><p>​    在他们开启查询时，都发现值班人数是大于2的。应用层，逻辑处理之后，发现可以调班。因此执行调班操作，但是执行完毕之后，值班人数为0。</p><p>​    这种问题，快照隔离是处理不了的。因为两个事务开启时，创建的快照在整个事务的生存期间，是自洽的。因此，都会看到2。</p><p>​    更多的幻读，写倾斜例子：</p><ul><li>会议室预定系统</li><li>超卖问题</li><li>棋盘问题，对于每个棋子我们可以加锁，但是我们想要避免落到同一个地方则比较困难。因为两个移动棋子的事务并发启动的时候，每个Read-View，都看到”同一个地方“是空的，因此都向往那里移动。</li><li>创建用户名问题，原理同上</li></ul><p>​    <strong>这种问题，称为幻读问题，而且这些问题一般符合下面这些特点：</strong></p><ul><li>Step1：根据某个条件，查询出一些记录 （结果可以是空）</li><li>Step2：查询记录交付给应用层进行逻辑判断</li><li>Step3：应用层决策交给DB进行处理，<strong>增删查改</strong><ul><li>这个操作，会影响先前select的结果。</li></ul></li><li>只要符合上述这些条件，都很容易引起幻读的问题。</li></ul><h3 id="如何解决写倾斜or幻读问题"><a href="#如何解决写倾斜or幻读问题" class="headerlink" title="如何解决写倾斜or幻读问题"></a>如何解决写倾斜or幻读问题</h3><p>对于避免写倾斜，其实有很多方案。</p><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs markdown">1.可串行化，避免写倾斜。<br><span class="hljs-bullet"> -</span> 采用2PC，当一个事务提交/中止的时候，才把锁给释放。<br><span class="hljs-bullet"> -</span> 但是这种操作，效率很低<br><br>2.版本向量的办法，(maybe，我也不是很确定这个行不行)<br></code></pre></td></tr></table></figure><h3 id="可串行化"><a href="#可串行化" class="headerlink" title="可串行化"></a>可串行化</h3><p>​    可串行化是最强的隔离级别，它在一定程度上保证事务的并发，让最后的结果看起来一次只有一个事务进行执行。一般来说，实现可串行化有下面三种方案</p><ul><li>严格串行执行</li><li>2PC</li><li>可串行化的快照隔离</li></ul><p>​    下面，我将简单介绍一下 串行执行 和2PC。详细讲讲可串行化的快照，因为这是一个比较新的算法，如果没有意外的话，以后数据库实现可串行化都会采用这个算法，因为效率大大提高了。</p><h3 id="串行执行—单线程"><a href="#串行执行—单线程" class="headerlink" title="串行执行—单线程"></a>串行执行—单线程</h3><p>​    解决并发的根本手段就是避免并发：就是每次只有一个线程在CPU执行。完全回避了并发会遇到的各种隔离性问题，数据共享问题。</p><p>​    但是直到最近，数据库设计者才真正考虑用单线程实现串行的隔离 (比如说redis)。</p><p>​    我觉得原因可能有两种：</p><ul><li>硬件提升很快，现在内存，CPU提升比较大。内存能够一次性容纳很多数据，因此避免了磁盘IO的损耗</li><li>单线程，避免了频繁的上下文切换</li></ul><p><strong>综上，单线程模型，效率还能接受，但不到万不得已，不建议用</strong></p><h3 id="2PC"><a href="#2PC" class="headerlink" title="2PC"></a>2PC</h3><p>​    就是对事务操作的对象加锁，区间锁之类的。然后到最后提交才释放。</p><p>​    因为加锁了导致效率很低，很多事务被阻塞住了。</p><p>​    下篇文章再仔细讲讲区间锁，这里先不讲了。</p><h3 id="可串行快照"><a href="#可串行快照" class="headerlink" title="可串行快照"></a>可串行快照</h3><p>​    虽然<strong>两阶段锁可以保证串行化</strong>，但是性能差强人意并且无法拓展。有句话说，你隔离得越严实，性能就会越差。那么性能和隔离性之间是否无法兼得？</p><p>​    未必，最近出现了一种叫做**可串行化快照(Serializable Snapshot Isolation)**的技术。它提供完整性的隔离保证，并且性能损耗较小。</p><p>​    但是，SSI仍旧需要在实践中检验它的性能，相信以后会称为未来数据库的标配。</p><p><strong>乐观和悲观</strong></p><p>​    2PC显然是一种悲观的思想，它基于这样的设计思想：<strong>如果某些操作能引起并发错误，那么干脆就直接放弃，等到安全的时候再让该事务进行</strong></p><p>​    相比之下，可串行化快照是一种乐观的思想：</p><ul><li>事务不管怎么样都会执行，都是在执行的过程中会记录一些信息，帮助自己判断。</li><li>等到事务将要提交的时候，数据库底层会判断是否出现冲突(根据记录的信息)，如果发生冲突的话，事务重试</li></ul><p>​    但是，这个有一个前提，就是<strong>事务之间竞争不是很大</strong>。如果竞争很大的话，这种算法最终会退化成2PC的效率。</p><h2 id="可穿行快照具体实现"><a href="#可穿行快照具体实现" class="headerlink" title="可穿行快照具体实现"></a>可穿行快照具体实现</h2><p>​    顾名思义，可串行化快照是基于快照的。也就是说，数据库的所有操作都是基于事务中的一致性快照。<strong>在这个的基础上，增加了相关算法来检测，写入之间的串行化冲突</strong>。</p><h3 id="基于过期时间来确定的"><a href="#基于过期时间来确定的" class="headerlink" title="基于过期时间来确定的"></a>基于过期时间来确定的</h3><p>​    在讨论<strong>写倾斜</strong>的时候，讨论过写倾斜有三个特点。(1)根据条件查询 (2)应用层逻辑判断 (3)进入db修改，这个修改对先前的查询有影响。</p><p>​    因此，当前事务在快照隔离的情况下，数据可能在查询期间，就被其他事务修改。<strong>因此当前的接下来决策信息，会被干扰了。</strong></p><p>​    所以，要避免写倾斜产生。关键在于要让数据库检测，<strong>当前事务对某个对象的修改是否会对别的事务对该对象的查询有影响。</strong></p><p>大致可以分为两种情况来讨论：</p><ul><li><p>查询是否作用于一个即将过期的MVCC对象 (当前事务在读取对象之前，该对象已经有别的事务未提交的写入，该对象对当前事务不可见)</p></li><li><p>检查写入是否会影响之前的读取  (可能会影响应用层的逻辑判断)</p></li></ul><h3 id="写入-未提交-读取"><a href="#写入-未提交-读取" class="headerlink" title="写入(未提交) - 读取"></a>写入(未提交) - 读取</h3><p><img src="/../../images/%E6%B5%85%E8%B0%88MySQL%E7%9A%84%E9%9A%94%E7%A6%BB%E6%80%A7/1633451169315.png" alt="1633451169315"></p><p>​    上面这个例子，如果是基于MVCC的隔离下。事务43的提交是晚于事务42的提交的。那么也就是说，事务42是可以提交成功的，那么就会改变 值班人数 &gt;&#x3D; 2这个条件。虽然事务43的Read - View里面，仍旧是2个人值班(虽然实际上前提条件已经变了)。</p><p>​    这样，数据库要跟踪那些因为MVCC可见性问题带来的<strong>被忽略的写操作</strong>。</p><p><strong>如何解决这个问题？</strong></p><ul><li>对符合前提条件的记录，建立一张表。</li><li>对这些查询出来记录，进行修改的时候，插入一条记录 [record | <strong>create_transaction id</strong> | delete transaction id]</li><li>等到事务提交的时候，检查一下该表。<ul><li>如果这个更新不是自己做的，那么就中止本次事务的提交(因为前提条件被别的事务破坏了)</li><li>如果是自己的transaction id，那么就提交</li></ul></li></ul><h3 id="更新是否影响之前的读"><a href="#更新是否影响之前的读" class="headerlink" title="更新是否影响之前的读"></a>更新是否影响之前的读</h3><p><img src="/../../images/%E6%B5%85%E8%B0%88MySQL%E7%9A%84%E9%9A%94%E7%A6%BB%E6%80%A7/1633451743812.png" alt="1633451743812"></p><p><strong>具体实现</strong></p><ul><li>维护一张读表</li><li>更新的时候，看看读表中是否有数据。如果有则通知对应的事务，让其在提交时放弃并重试。</li></ul><p>​    在上面这个例子中时这样的。两个事务42，43对db进行查询。因此读表插入两条记录，记录了两个事务分别读取了什么记录。</p><p>​    当事务42对<code>record 1234</code>进行更新后，在读表中查到<code>record 1234</code>的更新会影响到事务43。那么就通知到事务43，并且让他提交时放弃并重试。</p><p>​    <strong>ok，以上就是本章想要探讨的全部内容。如果想要交流讨论的，欢迎邮箱联系~</strong></p>]]></content>
    
    
    <categories>
      
      <category>数据库</category>
      
    </categories>
    
    
    <tags>
      
      <tag>MySQL</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>结合内核态和线程结构谈谈 --- 为什么线程切换比进程快?</title>
    <link href="/2021/10/04/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80%E7%9B%B8%E5%85%B3/%E7%BB%93%E5%90%88%E5%86%85%E6%A0%B8%E6%80%81%E5%92%8C%E7%BA%BF%E7%A8%8B%E7%BB%93%E6%9E%84%E8%B0%88%E8%B0%88-%E4%B8%BA%E4%BB%80%E4%B9%88%E7%BA%BF%E7%A8%8B%E5%88%87%E6%8D%A2%E6%AF%94%E8%BF%9B%E7%A8%8B%E5%BF%AB/"/>
    <url>/2021/10/04/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80%E7%9B%B8%E5%85%B3/%E7%BB%93%E5%90%88%E5%86%85%E6%A0%B8%E6%80%81%E5%92%8C%E7%BA%BF%E7%A8%8B%E7%BB%93%E6%9E%84%E8%B0%88%E8%B0%88-%E4%B8%BA%E4%BB%80%E4%B9%88%E7%BA%BF%E7%A8%8B%E5%88%87%E6%8D%A2%E6%AF%94%E8%BF%9B%E7%A8%8B%E5%BF%AB/</url>
    
    <content type="html"><![CDATA[<h3 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h3><p>​    看过之前两篇文章，应该都大致了解了两件事情。</p><ul><li><p>在Linux系统里面，进程线程几乎没有区别，没有为线程设置额外的调度算法，数据结构</p></li><li><p>进程&#x2F;线程调度其实经历这几个阶段</p><ul><li><p>进程A —&gt; 陷入到内核态，内核进程A</p></li><li><p>内核进程A —&gt; 进程调度器 —&gt; 内核进程B</p></li><li><p>内核进程B —&gt; 进程B</p></li><li><p>既然如此必然经过页表，跟栈的切换</p></li></ul></li></ul><p>​    之后，我思考一个问题，为什么说线程切换的效率要比进程低呢？线程切换的时候不也要走内核空间吗？进入内核空间就需要切换页表栈，一样有开销。</p><p>​    而且线程也没有特殊的调度算法和数据结构。带着这个问题我继续深入研究….</p><span id="more"></span><h3 id="切换的开销"><a href="#切换的开销" class="headerlink" title="切换的开销"></a>切换的开销</h3><p>​    我们知道，进程是资源分配的单位，不同进程之间，很显然它的内存空间和栈空间是隔离的，进程A一般不能访问进程B的地址空间。</p><p>​    线程，作为一种轻量级进程，同一进程下的线程起码是共享地址空间的。</p><p>​    所以一般来说，进程切换需要切换地址空间也就是(page table)，线程之间的切换则不需要page table。</p><p>​    这是这个问题的一般答案。但是有没有考虑过一个问题。(1)线程跟进程的结构很相似，没有区别也没有特别的调度算法 (2)也就是说，即使是线程，调度的时候也要进入内核态。但是内核态程序是有自己的页表的。</p><p>​    因此，不管怎么样，即使是同一进程下的线程切换，仍旧需要进入到内核态，切换到内核程序的页表。<strong>这样，似乎上面的答案就不成立了？</strong></p><p>​    因此，我仔细阅读了，陷入内核空间的代码。</p><h4 id="切换的过程"><a href="#切换的过程" class="headerlink" title="切换的过程"></a>切换的过程</h4><p>​    具体过程就不说了，以时间片到期为例。</p><ul><li>内核的timer到期后，产生一个中断，发起一个进程调度</li><li>进程A —&gt; 陷入到内核态，内核进程A</li><li>内核进程A —&gt; 进程调度器 —&gt; 内核进程B</li><li>内核进程B —&gt; 进程B</li></ul><p>​    这就是进程之间的调度的过程。那么我们就看看，陷入内核的时候发生了什么事情？</p><ul><li>系统调用 - ecall</li><li>usersevc-trampoline page</li><li>usertrap</li></ul><h4 id="ecall究竟做了什么"><a href="#ecall究竟做了什么" class="headerlink" title="ecall究竟做了什么"></a>ecall究竟做了什么</h4><p>​    再次仔细阅读ecall的源码，发现ecall其实就做了这几件事情</p><figure class="highlight armasm"><table><tr><td class="gutter"><div class="code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></div></td><td class="code"><pre><code class="hljs armasm"><span class="hljs-number">1</span>.把mode位 切换为 supervisor mode<br><span class="hljs-number">2</span>.保存当前<span class="hljs-built_in">PC</span>的值到 SEPC<br><span class="hljs-number">3</span>.取出SPEVC trap指令的第一条放入<span class="hljs-built_in">PC</span><br></code></pre></td></tr></table></figure><p>​    所以，ecall执行的东西并不多。并且这样就算已经陷入到内核态了，<strong>因为能够执行内核指令</strong>。但是此时页表和栈仍然没有切换。</p><p>​    为什么ecall这样设计？参考上一篇文章，这样设计是为了ecall的效率。</p><p>​    <strong>因此，进行线程调度的时候，进入内核态的过程应该是不会切换内存的。</strong></p>]]></content>
    
    
    <categories>
      
      <category>Operate System</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>浅谈用户态和内核态以及系统调用</title>
    <link href="/2021/10/03/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80%E7%9B%B8%E5%85%B3/talk-about-thread-by-kernal-mode/"/>
    <url>/2021/10/03/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80%E7%9B%B8%E5%85%B3/talk-about-thread-by-kernal-mode/</url>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>&amp;#8195;&amp;#8195;为了保证操作系统的<strong>强隔离性</strong>，设计者实现了“supervisor mode” 和 “虚拟内存”，来保证进程之间互相隔离。</p><p>&amp;#8195;&amp;#8195;我们可以认为user&#x2F;kernel mode是分隔用户空间和内核空间的边界，用户空间运行的程序运行在user mode，内核空间的程序运行在kernel mode。操作系统位于内核空间。</p><p><img src="/../../images/%E6%B5%85%E8%B0%88%E7%94%A8%E6%88%B7%E6%80%81%E5%92%8C%E5%86%85%E6%A0%B8%E6%80%81%E4%BB%A5%E5%8F%8A%E7%B3%BB%E7%BB%9F%E8%B0%83%E7%94%A8/1633247506349.png" alt="1633247506349"></p><p>&amp;#8195;&amp;#8195;一般来说，用户态的应用程序运行在用户态空间里面。但是，一些比较重要的函数,操作会发生在内核空间。因此，内核空间拥有更多的权限，能够访问更多的底层数据结构，以及指令。</p><p>&amp;#8195;&amp;#8195;那么，我们来看看如何从 用户态陷入到内核态 <strong>(trap)</strong></p> <span id="more"></span> <h2 id="Trap机制"><a href="#Trap机制" class="headerlink" title="Trap机制"></a>Trap机制</h2><p>今天我想导论一下，程序是如何完成用户空间到内核空间的切换。每当发生下面的以下情况发生时：</p><ul><li>程序需要系统调用</li><li>程序出现缺页，页表错误</li><li>设备发出了中断</li></ul><p>都会发生mode的切换。这种切换机制叫做<code>trap</code>。</p><p>&amp;#8195;&amp;#8195;下面，举一个Shell进程，执行<code>write()</code>系统调用的例子。<strong>看看程序是如何完成用户态到内核态的切换</strong>。</p><p><img src="/../../images/%E6%B5%85%E8%B0%88%E7%94%A8%E6%88%B7%E6%80%81%E5%92%8C%E5%86%85%E6%A0%B8%E6%80%81%E4%BB%A5%E5%8F%8A%E7%B3%BB%E7%BB%9F%E8%B0%83%E7%94%A8/1633247995037.png" alt="1633247995037"></p><p>&amp;#8195;&amp;#8195;我们有一点需要知道的是，当用户态程序进入到系统态的时候，这个过程中硬件的状态非常重要，需要我们保存下来。<strong>因为，trap过程中需要设置cpu状态，这样才能让内核程序运行（这里我理解是保存CPU的现场或者说上下文信息）。</strong></p><p>&amp;#8195;&amp;#8195;因此，为了恢复用户态程序，需要把切换时的CPU现场保存下来。需要注意的寄存器有下面这些</p><ul><li>32位用户寄存器</li><li>stack pointer (指向程序的栈)</li><li>pc</li><li>mode位 (标志系统处于哪个状态，user mode or supervisor mode)</li><li>STAP — Supervisor Address Translation and Protection — (包含指向page table的地址)</li><li>STVEC — (trap指令的起始地址)</li><li>SEPC — (执行trap过程中，保存PC)</li><li>SSRACTCH — (保存trapfram的地址)<ul><li><strong>trapfram是用来保存CPU现场的一个重要数据结构</strong></li></ul></li></ul><p>&amp;#8195;&amp;#8195;可以肯定，<code>trap机制</code>刚执行的时候，<strong>cpu的状态是运行用户程序的状态</strong>。</p><p>&amp;#8195;&amp;#8195;因此，<strong>刚运行trap指令的时候，我们需要做一些操作（保存当前CPU的上下文）。</strong>这样才能运行内核中的C程序。</p><ul><li><p>保留32位寄存器，因为这是恢复的根本</p></li><li><p>PC，同上</p></li><li><p>把<code>supervi mode</code>设置为内核态</p></li><li><p>STAP页表寄存器此时指向用户程序的页表，需要执行内核程序的话理所当然需要内核程序的页表。</p><ul><li><code>trapframe</code>中有<strong>指向内核的页表</strong>的地址</li><li>把内核页表的地址，与当前<code>STAP</code>寄存器中，用户程序的页表地址交换</li></ul></li><li><p>也就是说，此时<code>trapframe</code>中有用户程序的页表，<code>STAP</code>中有内核程序的页表</p></li><li><p><code>Stack pointer </code>也要指向进程内核栈。因为C程序的运行需要一个栈空间</p></li></ul><p>以上，就是<code>trap机制</code>大概执行了什么事情。接下来我们从代码的角度来进行分析。简单来说，<strong>就是在CPU里面的状态位，设置为能够运行内核程序的状态。并且保存用户程序的CPU上下文。</strong></p><h2 id="Trap代码执行流程"><a href="#Trap代码执行流程" class="headerlink" title="Trap代码执行流程"></a>Trap代码执行流程</h2><p>&amp;#8195;&amp;#8195;Shell执行<code>write( )系统调用</code>。从Shell的角度来看，<code>write( )</code>是一个C函数调用。但是，从汇编的角度来看，<code>write( )</code>通过<code>ecall num</code>，来具体执行系统调用。</p><p>&amp;#8195;&amp;#8195;ecall指令会切换到<code>kernal mode</code>中去。在这个过程中执行的是一个汇编语言写的函数<code>uservec</code>。这个函数是内核代码<code>trampoline.s</code>的一部分。</p><p><img src="/../../images/%E6%B5%85%E8%B0%88%E7%94%A8%E6%88%B7%E6%80%81%E5%92%8C%E5%86%85%E6%A0%B8%E6%80%81%E4%BB%A5%E5%8F%8A%E7%B3%BB%E7%BB%9F%E8%B0%83%E7%94%A8/1633249004333.png" alt="1633249004333"></p><p>&amp;#8195;&amp;#8195;之后，在这个汇编函数，代码跳转到了由C语言实现的函数<code>usertrap</code>中。该函数在<code>trap.c</code>中。</p><p><img src="/../../images/%E6%B5%85%E8%B0%88%E7%94%A8%E6%88%B7%E6%80%81%E5%92%8C%E5%86%85%E6%A0%B8%E6%80%81%E4%BB%A5%E5%8F%8A%E7%B3%BB%E7%BB%9F%E8%B0%83%E7%94%A8/1633249051852.png" alt="1633249051852"></p><p>在<code>usertrap( )</code>中执行了一个<code>syscall</code>指令，然后该指令通过<code>number</code>。在一个表里面，找到该<code>number</code>对应的系统调用。</p><p><img src="/../../images/%E6%B5%85%E8%B0%88%E7%94%A8%E6%88%B7%E6%80%81%E5%92%8C%E5%86%85%E6%A0%B8%E6%80%81%E4%BB%A5%E5%8F%8A%E7%B3%BB%E7%BB%9F%E8%B0%83%E7%94%A8/1633249130252.png" alt="1633249130252"></p><p><code>sys_write</code>会将显式数据输出到<code>console</code>上面，当它完成了之后，它会返回给<code>syscall函数</code>。</p><p><img src="/../../images/%E6%B5%85%E8%B0%88%E7%94%A8%E6%88%B7%E6%80%81%E5%92%8C%E5%86%85%E6%A0%B8%E6%80%81%E4%BB%A5%E5%8F%8A%E7%B3%BB%E7%BB%9F%E8%B0%83%E7%94%A8/1633249265805.png" alt="1633249265805"></p><p>​    <strong>上面就是我们如何从用户态陷入到内核态，执行系统调用的过程，但是现在需要考虑是如何从内核态返回给用户态</strong></p><p>​    在<code>syscall函数</code>中，会调用一个函数叫做<code>usertrapret</code>，它也位于<code>trap.c</code>中，这个函数完成了部分方便在C代码中实现的返回到用户空间的工作。</p><p><img src="/../../images/%E6%B5%85%E8%B0%88%E7%94%A8%E6%88%B7%E6%80%81%E5%92%8C%E5%86%85%E6%A0%B8%E6%80%81%E4%BB%A5%E5%8F%8A%E7%B3%BB%E7%BB%9F%E8%B0%83%E7%94%A8/1633249347666.png" alt="1633249347666"></p><p>​    <strong>除此之外，最终还有一些工作只能在汇编语言中完成。这部分工作通过汇编语言实现，并且存在于<code>trampoline.s</code>文件中的<code>userret</code>函数中。</strong></p><p><img src="/../../images/%E6%B5%85%E8%B0%88%E7%94%A8%E6%88%B7%E6%80%81%E5%92%8C%E5%86%85%E6%A0%B8%E6%80%81%E4%BB%A5%E5%8F%8A%E7%B3%BB%E7%BB%9F%E8%B0%83%E7%94%A8/1633249369876.png" alt="1633249369876"></p><p>​    最终，在汇编代码中调用机器指令，返回到了用户控件中。</p><p><img src="/../../images/%E6%B5%85%E8%B0%88%E7%94%A8%E6%88%B7%E6%80%81%E5%92%8C%E5%86%85%E6%A0%B8%E6%80%81%E4%BB%A5%E5%8F%8A%E7%B3%BB%E7%BB%9F%E8%B0%83%E7%94%A8/1633249399340.png" alt="1633249399340"></p><h2 id="ecall指令执行前的状态"><a href="#ecall指令执行前的状态" class="headerlink" title="ecall指令执行前的状态"></a>ecall指令执行前的状态</h2><p>&amp;#8195;&amp;#8195;从那个sh执行<code>write( )系统调用</code>，我们看一看执行ecall前后的寄存器状态。</p><p>&amp;#8195;&amp;#8195;这是write的代码，很简单</p><p><img src="/../../images/%E6%B5%85%E8%B0%88%E7%94%A8%E6%88%B7%E6%80%81%E5%92%8C%E5%86%85%E6%A0%B8%E6%80%81%E4%BB%A5%E5%8F%8A%E7%B3%BB%E7%BB%9F%E8%B0%83%E7%94%A8/1633250221799.png" alt="1633250221799"></p><p>现在，我要让XV6开始运行。我期望的是XV6在Shell代码中正好在执行ecall之前就会停住。</p><p><img src="/../../images/%E6%B5%85%E8%B0%88%E7%94%A8%E6%88%B7%E6%80%81%E5%92%8C%E5%86%85%E6%A0%B8%E6%80%81%E4%BB%A5%E5%8F%8A%E7%B3%BB%E7%BB%9F%E8%B0%83%E7%94%A8/1633250263072.png" alt="1633250263072"></p><p>从gdb可以看出，<strong>我们下一条要执行的指令就是ecall。</strong>我们来检验一下我们真的在我们以为自己在的位置，让我们来打印程序计数器（Program Counter），正好我们期望在的位置0xde6。</p><p><img src="/../../images/%E6%B5%85%E8%B0%88%E7%94%A8%E6%88%B7%E6%80%81%E5%92%8C%E5%86%85%E6%A0%B8%E6%80%81%E4%BB%A5%E5%8F%8A%E7%B3%BB%E7%BB%9F%E8%B0%83%E7%94%A8/1633250283383.png" alt="1633250283383"></p><p>此时寄存器的状态</p><p><img src="/../../images/%E6%B5%85%E8%B0%88%E7%94%A8%E6%88%B7%E6%80%81%E5%92%8C%E5%86%85%E6%A0%B8%E6%80%81%E4%BB%A5%E5%8F%8A%E7%B3%BB%E7%BB%9F%E8%B0%83%E7%94%A8/1633250314013.png" alt="1633250314013"></p><p><code>STAP页表寄存器</code>状态以及内容</p><p><img src="/../../images/%E6%B5%85%E8%B0%88%E7%94%A8%E6%88%B7%E6%80%81%E5%92%8C%E5%86%85%E6%A0%B8%E6%80%81%E4%BB%A5%E5%8F%8A%E7%B3%BB%E7%BB%9F%E8%B0%83%E7%94%A8/1633250345496.png" alt="1633250345496"></p><p><img src="/../../images/%E6%B5%85%E8%B0%88%E7%94%A8%E6%88%B7%E6%80%81%E5%92%8C%E5%86%85%E6%A0%B8%E6%80%81%E4%BB%A5%E5%8F%8A%E7%B3%BB%E7%BB%9F%E8%B0%83%E7%94%A8/1633250357155.png" alt="1633250357155"></p><p>&amp;#8195;&amp;#8195;<strong>最后两页明显不一样，因为这是<code>trampoline page </code>和 <code>trapframe page</code>的地址空间</strong>，当我们进入到<code>supervisor mode</code>就能访问者两页。</p><h2 id="ecall执行后的状态"><a href="#ecall执行后的状态" class="headerlink" title="ecall执行后的状态"></a>ecall执行后的状态</h2><p>当我们执行完ecall之后，查看一下PC的地址。很明显这是一个比较大的值，与ecall执行前的Oxde6不一样。</p><p><img src="/../../images/%E6%B5%85%E8%B0%88%E7%94%A8%E6%88%B7%E6%80%81%E5%92%8C%E5%86%85%E6%A0%B8%E6%80%81%E4%BB%A5%E5%8F%8A%E7%B3%BB%E7%BB%9F%E8%B0%83%E7%94%A8/1633250494236.png" alt="1633250494236"></p><p>​    </p><p>再查看一下<code>page table</code>。发现<code>page table</code>没有变化</p><p><img src="/../../images/%E6%B5%85%E8%B0%88%E7%94%A8%E6%88%B7%E6%80%81%E5%92%8C%E5%86%85%E6%A0%B8%E6%80%81%E4%BB%A5%E5%8F%8A%E7%B3%BB%E7%BB%9F%E8%B0%83%E7%94%A8/1633250542800.png" alt="1633250542800"></p><p>​    </p><p>我们发现，此时PC中的值跟<code>trampoline page</code>的值十分相似。那么我们查看一下<code>trampoline page</code>中的指令。</p><p><img src="/../../images/%E6%B5%85%E8%B0%88%E7%94%A8%E6%88%B7%E6%80%81%E5%92%8C%E5%86%85%E6%A0%B8%E6%80%81%E4%BB%A5%E5%8F%8A%E7%B3%BB%E7%BB%9F%E8%B0%83%E7%94%A8/1633250613680.png" alt="1633250613680"></p><p>​    </p><p>这些指令是内核在<code>supervisor mode</code>中将要执行的最开始的几条指令，也是在<code>trap机制</code>中最开始要执行的几条指令。</p><p>因为gdb有一些奇怪的行为，我们实际上已经执行了位于<code>trampoline page</code>最开始的一条指令（也就是csrrw指令）。</p><p>我们查看32位寄存器的值，发现并没有改变。所以寄存器还是用户数据。再观察一下发现。</p><p><img src="/../../images/%E6%B5%85%E8%B0%88%E7%94%A8%E6%88%B7%E6%80%81%E5%92%8C%E5%86%85%E6%A0%B8%E6%80%81%E4%BB%A5%E5%8F%8A%E7%B3%BB%E7%BB%9F%E8%B0%83%E7%94%A8/1633250690543.png" alt="1633250690543"></p><p>​    </p><p>&amp;#8195;&amp;#8195;当前执行的指令是把CPU的状态进行一个保存。<strong>也就是说<code>trampoline page</code>的指令是保存cpu寄存器的</strong></p><p>&amp;#8195;&amp;#8195;我们现在在这个地址0x3ffffff000，也就是上面<code>page table</code>输出的最后一个<code>page</code>，这是<code>trampoline page</code>。我们现在正在trampoline page中执行程序，这个<code>page</code>包含了内核的<code>trap</code>处理代码。<strong>ecall并不会切换<code>page table</code>，这是ecall指令的一个非常重要的特点。</strong></p><figure class="highlight sas"><table><tr><td class="gutter"><div class="code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></div></td><td class="code"><pre><code class="hljs sas">1.此时 <span class="hljs-meta">page</span> register 仍旧是用户态的页表<br>2.只不过是把 用户态页表 最后的那一项(tampoline <span class="hljs-meta">page</span>)起始地址放到PC中<br>3.每一个用户态代码最后一定有这两页 trapfram <span class="hljs-meta">and</span> trampoline <span class="hljs-meta">page</span><br></code></pre></td></tr></table></figure><h2 id="ecall做的事情"><a href="#ecall做的事情" class="headerlink" title="ecall做的事情"></a>ecall做的事情</h2><ul><li><p>第一，把<code>user mode</code>设置为<code>supervisor mode</code></p></li><li><p>第二，把当前的PC值放到SEPC寄存器中，<strong>以便系统调用结束后，能够恢复原来的程序位置</strong></p><ul><li>至于保存CPU现场，是<code>trampoline page</code>里面的指令做的事情。所以，此时PC里面的指令是<code>trampoline page</code></li></ul></li><li><p>第三，ecall会跳转到<code>SPEVC寄存器</code>指向的指令</p></li></ul><p><strong>打印当前PC，是<code>trampolin page</code>的地址，也是SPEVC的地址</strong></p><p><img src="/../../images/%E6%B5%85%E8%B0%88%E7%94%A8%E6%88%B7%E6%80%81%E5%92%8C%E5%86%85%E6%A0%B8%E6%80%81%E4%BB%A5%E5%8F%8A%E7%B3%BB%E7%BB%9F%E8%B0%83%E7%94%A8/1633251142484.png" alt="1633251142484"></p><p><strong>打印<code>SEPC寄存器</code>，是用户态PC的值</strong></p><p><img src="/../../images/%E6%B5%85%E8%B0%88%E7%94%A8%E6%88%B7%E6%80%81%E5%92%8C%E5%86%85%E6%A0%B8%E6%80%81%E4%BB%A5%E5%8F%8A%E7%B3%BB%E7%BB%9F%E8%B0%83%E7%94%A8/1633251176774.png" alt="1633251176774"></p><p><strong>所以执行完ecall，我们仅仅是改变了supervisor mode 和 pc的值</strong></p><p>此时页表和栈的信息，仍旧是用户程序的。因此，我们接下来的工作：</p><ul><li>保存32位现场(trampoline page代码)</li><li>切换<code>page table</code></li><li>切换<code>进程栈空间</code></li></ul><h2 id="为什么ecall做的事情这么少"><a href="#为什么ecall做的事情这么少" class="headerlink" title="为什么ecall做的事情这么少"></a>为什么ecall做的事情这么少</h2><p>&amp;#8195;&amp;#8195;实际上，我们也可以通过在硬件上进行处理，通过修改硬件让ecall帮我们执行完这些。但是，RISC-V秉持了这样一个观点：<strong>ecall只完成尽量少必须要完成的工作，其他的工作都交给软件完成。</strong></p><p>&amp;#8195;&amp;#8195;这里的原因是，RISC-V设计者想要为软件和操作系统的程序员提供最大的灵活性，这样他们就能按照他们想要的方式开发操作系统。</p><p>&amp;#8195;&amp;#8195;让ecall指完成基本的功能，那些开销很大的操作，有可能是不用做的，那么就没必要放到ecall里面，让ecall指令更加的效率。</p><ul><li>举个例子<strong>，因为这里的ecall是如此的简单，或许某些操作系统可以在不切换page table的前提下，执行部分系统调用。</strong>切换page table的代价比较高，如果ecall打包完成了这部分工作，那就不能对一些系统调用进行改进，使其不用在不必要的场景切换page table。</li><li>某些操作系统同时将user和kernel的虚拟地址映射到一个page table中，这样在user和kernel之间切换时根本就不用切换page table。对于这样的操作系统来说，如果ecall切换了page table那将会是一种浪费，并且也减慢了程序的运行。</li><li>或许在一些系统调用过程中，一些寄存器不用保存，而哪些寄存器需要保存，哪些不需要，取决于于软件，编程语言，和编译器。通过不保存所有的32个寄存器或许可以节省大量的程序运行时间，所以你不会想要ecall迫使你保存所有的寄存器。</li><li>最后，对于某些简单的系统调用或许根本就不需要任何stack，所以对于一些非常关注性能的操作系统，ecall不会自动为你完成stack切换是极好的。</li></ul><p>所以，ecall尽量的简单可以提升软件设计的灵活性。</p><h2 id="uservec函数"><a href="#uservec函数" class="headerlink" title="uservec函数"></a>uservec函数</h2><h3 id="保存CPU现场"><a href="#保存CPU现场" class="headerlink" title="保存CPU现场"></a>保存CPU现场</h3><p>&amp;#8195;&amp;#8195;刚才提到了<code>trampoline page</code>里面的代码是为了保存寄存器状态。但是现在有一个问题。</p><p>&amp;#8195;&amp;#8195;在大多数的OS里面，是不能直接访问物理内存的，需要通过<code>page table</code>做一个映射。因此我们需要拿到<code>kernal的page table</code>。但是目前为止，我们并不知道它的<code>page table</code>地址。</p><p>​    并且更新page table的寄存器，我们需要先把用户程序的<code>page table</code>进行保存，这样我们才能再修改。</p><p>​    因此总结一下我们需要解决的两个问题：</p><figure class="highlight sas"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs sas">- 我们需要知道kernal <span class="hljs-meta">page</span> <span class="hljs-meta">table</span> 的起始地址<br>- 我们需要保存user <span class="hljs-meta">page</span> <span class="hljs-meta">table</span>，这样才能使用它的寄存器<br></code></pre></td></tr></table></figure><p>&amp;#8195;&amp;#8195;这个做法其实十分简单，还记得user page table，最后的两页是什么内容吗？<code>trampoline page </code>和 <code>trapfram page</code>的起始地址。</p><p>&amp;#8195;&amp;#8195;我们看看<code>trapfram page</code>中究竟存储的是什么东西？</p><p><img src="/../../images/%E6%B5%85%E8%B0%88%E7%94%A8%E6%88%B7%E6%80%81%E5%92%8C%E5%86%85%E6%A0%B8%E6%80%81%E4%BB%A5%E5%8F%8A%E7%B3%BB%E7%BB%9F%E8%B0%83%E7%94%A8/1633252276286.png" alt="1633252276286"></p><p>&amp;#8195;&amp;#8195;很显然，trapfram的字段都是对应着CPU里面的寄存器。但是多了五个数据，这是<strong>内核事先存放好的数据</strong></p><ul><li>比如，第一个字段就存放着kernal page的地址</li><li>第二个字段是栈</li><li>第三个是usertrap代码的起始地址</li><li>第四个是SEPC寄存器</li></ul><p><strong>所以很显然了，我们需要的kernal page就在trapframe中就可以找到。</strong></p><p>&amp;#8195;&amp;#8195;另一半的答案在于我们之前提过的<code>SSCRATCH寄存器</code>。(可以理解为box)</p><p>&amp;#8195;&amp;#8195;在回到用户态之前，内核会把<code>trapframe page</code>的地址保存在这个寄存器。更重要的是<code>csrrw</code>指令，能够交换两个寄存器的值。</p><p>&amp;#8195;&amp;#8195;我们看一下<code>trampoline.s</code>的代码</p><p><img src="/../../images/%E6%B5%85%E8%B0%88%E7%94%A8%E6%88%B7%E6%80%81%E5%92%8C%E5%86%85%E6%A0%B8%E6%80%81%E4%BB%A5%E5%8F%8A%E7%B3%BB%E7%BB%9F%E8%B0%83%E7%94%A8/1633252617219.png" alt="1633252617219"></p><p>第一件事情，就是交换<code>a0</code>和<code>ssratch</code>两个寄存器的内容，我们通过gdb查看一下。显然a0就是等于<code>trapframe </code></p><p><img src="/../../images/%E6%B5%85%E8%B0%88%E7%94%A8%E6%88%B7%E6%80%81%E5%92%8C%E5%86%85%E6%A0%B8%E6%80%81%E4%BB%A5%E5%8F%8A%E7%B3%BB%E7%BB%9F%E8%B0%83%E7%94%A8/1633252661829.png" alt="1633252661829"></p><p>打印一下<code>ssractch</code>，显然就是之前的a0</p><p><img src="/../../images/%E6%B5%85%E8%B0%88%E7%94%A8%E6%88%B7%E6%80%81%E5%92%8C%E5%86%85%E6%A0%B8%E6%80%81%E4%BB%A5%E5%8F%8A%E7%B3%BB%E7%BB%9F%E8%B0%83%E7%94%A8/1633252692044.png" alt="1633252692044"></p><p>&amp;#8195;&amp;#8195;所以我们现在将a0的值保存起来了，并且我们有了指向<code>trapframe page</code>的指针。现在我们正在朝着保存用户寄存器的道路上前进。通过计算位移，来保存寄存器的内容到<code>trapframe</code>。</p><figure class="highlight less"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs less">总结一下<span class="hljs-selector-tag">trampoline</span> <span class="hljs-selector-tag">page</span>是怎么保存的<br><span class="hljs-selector-tag">1</span>.不能直接访问内存，还是需要通过虚拟内存进行访问<br><span class="hljs-selector-tag">2</span>.需要保存<span class="hljs-selector-tag">cpu</span>现场<br><br>(<span class="hljs-number">1</span>)事先把<span class="hljs-selector-tag">trapframe</span>的地址保存起来，进入<span class="hljs-selector-tag">supervisor</span>后，执行置换指令，这样就得到一个相对位移的起点了<br>(<span class="hljs-number">2</span>)然后就可以很顺利执行<span class="hljs-selector-tag">CPU</span>现场保存<br></code></pre></td></tr></table></figure><h3 id="切换栈空间"><a href="#切换栈空间" class="headerlink" title="切换栈空间"></a>切换栈空间</h3><p>&amp;#8195;&amp;#8195;程序现在仍然在<code>trampoline</code>的最开始，也就是<code>uservec函数</code>的最开始，仅仅执行了CPU现场保存。我在寄存器拷贝的结束位置设置了一个断点，我们在gdb中让代码继续执行，现在我们停在了下面这条ld（load）指令。</p><p><img src="/../../images/%E6%B5%85%E8%B0%88%E7%94%A8%E6%88%B7%E6%80%81%E5%92%8C%E5%86%85%E6%A0%B8%E6%80%81%E4%BB%A5%E5%8F%8A%E7%B3%BB%E7%BB%9F%E8%B0%83%E7%94%A8/1633253140983.png" alt="1633253140983"></p><p>也就是，加载trapfram中的第八个字节到<code>stack_pointer</code>寄存器中。我们查看一些<code>trapframe</code>中第八个字节是什么东西？</p><p><img src="/../../images/%E6%B5%85%E8%B0%88%E7%94%A8%E6%88%B7%E6%80%81%E5%92%8C%E5%86%85%E6%A0%B8%E6%80%81%E4%BB%A5%E5%8F%8A%E7%B3%BB%E7%BB%9F%E8%B0%83%E7%94%A8/1633253213711.png" alt="1633253213711"></p><p>&amp;#8195;&amp;#8195;显然很明显，该指令就是切换到内核栈上。这是这个进程的kernel stack。因为XV6在每个kernel stack下面放置一个guard page，所以kernel stack的地址都比较大。</p><figure class="highlight arduino"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs arduino"><span class="hljs-number">1.</span>栈寄存器 切换到 kernal程序的栈空间。(因为要开始执行内核程序)<br><span class="hljs-number">2.</span>kernal的stack point一开始就在trapframe中初始化好了<br></code></pre></td></tr></table></figure><h3 id="切换page寄存器"><a href="#切换page寄存器" class="headerlink" title="切换page寄存器"></a>切换page寄存器</h3><p>​    有一条指令是向t1寄存器写入数据。<strong>这里写入的是<code>kernel page table</code>的地址，</strong>我们可以打印t1寄存器的内容。</p><p><img src="/../../images/%E6%B5%85%E8%B0%88%E7%94%A8%E6%88%B7%E6%80%81%E5%92%8C%E5%86%85%E6%A0%B8%E6%80%81%E4%BB%A5%E5%8F%8A%E7%B3%BB%E7%BB%9F%E8%B0%83%E7%94%A8/1633253345893.png" alt="1633253345893"></p><p>&amp;#8195;&amp;#8195;这条指令执行完成之后，当前程序会从<code>user page table</code>切换到<code>kernel page table</code>。现在我们在QEMU中打印<code>page table</code>，可以看出与之前的page table完全不一样。</p><p><img src="/../../images/%E6%B5%85%E8%B0%88%E7%94%A8%E6%88%B7%E6%80%81%E5%92%8C%E5%86%85%E6%A0%B8%E6%80%81%E4%BB%A5%E5%8F%8A%E7%B3%BB%E7%BB%9F%E8%B0%83%E7%94%A8/1633253378219.png" alt="1633253378219"></p><p>​    以上，就是从用户态陷入到内核态的所有流程。</p>]]></content>
    
    
    <categories>
      
      <category>Operate System</category>
      
    </categories>
    
    
    <tags>
      
      <tag>MIT6.S081</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>进程和线程的区别</title>
    <link href="/2021/10/03/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80%E7%9B%B8%E5%85%B3/%E6%B5%85%E8%B0%88%E8%BF%9B%E7%A8%8B%E5%92%8C%E7%BA%BF%E7%A8%8B%E7%9A%84%E5%8C%BA%E5%88%AB/"/>
    <url>/2021/10/03/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80%E7%9B%B8%E5%85%B3/%E6%B5%85%E8%B0%88%E8%BF%9B%E7%A8%8B%E5%92%8C%E7%BA%BF%E7%A8%8B%E7%9A%84%E5%8C%BA%E5%88%AB/</url>
    
    <content type="html"><![CDATA[<h3 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h3><p>​    一般来说，很多人都是认为进程跟线程的区别是这样的。进程是资源分配的基本单位，线程是CPU调度的基本单位。</p><p>​    虽然，这个说法没什么错。可是实际上，在Linux &#x2F; Unix这样的操作系统中，进程和线程之间的区别并没有想像中那么大。<strong>他们都是用同一种结构体进行描述的，并且创建进程和线程所使用的函数或者说创建进程线程的过程非常类似。</strong></p><p>​    所以说，我们其实可以认为，进程和线程他们是同一种东西。</p> <span id="more"></span> <h3 id="进程"><a href="#进程" class="headerlink" title="进程"></a>进程</h3><h4 id="关于进程的结构体"><a href="#关于进程的结构体" class="headerlink" title="关于进程的结构体"></a>关于进程的结构体</h4><h5 id="struct-thread-info"><a href="#struct-thread-info" class="headerlink" title="struct thread_info"></a>struct thread_info</h5><p>​    在进程的内核栈的底部，有一个数据结构(struct thread_info)。该数据结构里面的字段存储着进程的一些信息。</p><p><img src="/../../images/%E6%B5%85%E8%B0%88%E8%BF%9B%E7%A8%8B%E5%92%8C%E7%BA%BF%E7%A8%8B%E7%9A%84%E5%8C%BA%E5%88%AB/1633192286077.png" alt="1633192286077"></p><p>​    至于，为什么存在地步。我想可能是为了适配硬件(CPU)，因为不知道CPU是否设计有寄存器保留这个thread_info。因此OS的设计者倾向把他放在<strong>进程内核栈的底部，这样能很方便在内核中找到对应的进程描述符</strong>。</p><figure class="highlight c"><table><tr><td class="gutter"><div class="code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></div></td><td class="code"><pre><code class="hljs C"><span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">thread_info</span>&#123;</span><br>    <span class="hljs-class"><span class="hljs-keyword">struct</span><span class="hljs-title">task_struct</span>*<span class="hljs-title">task</span>;</span><span class="hljs-comment">// 进程描述符</span><br>    <span class="hljs-class"><span class="hljs-keyword">struct</span><span class="hljs-title">exec_domain</span> *<span class="hljs-title">exe_domain</span>;</span><span class="hljs-comment">// 执行信息</span><br>    <span class="hljs-keyword">unsigned</span> <span class="hljs-keyword">int</span>flag;<span class="hljs-comment">// 标志</span><br>    <span class="hljs-keyword">unsigned</span> <span class="hljs-keyword">int</span>status;<span class="hljs-comment">// 执行状态</span><br>    <span class="hljs-keyword">unsigned</span> <span class="hljs-keyword">int</span>cpu;<span class="hljs-comment">// cpu num</span><br>    <span class="hljs-keyword">int</span>address_limit;<span class="hljs-comment">// </span><br>    <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">restart_block</span><span class="hljs-title">block</span>;</span><span class="hljs-comment">//</span><br>    <br>&#125;<br></code></pre></td></tr></table></figure><h5 id="struct-task-struct"><a href="#struct-task-struct" class="headerlink" title="struct task_struct"></a>struct task_struct</h5><p>​    task_struct 也称为进程描述符，该描述符包含进程的所有信息。</p><p>​    在32位的机器上，进程描述符有1.7K。该描述符包含的信息：进程打开的文件，地址空间，挂起信号，进程状态…</p><p><img src="/../../images/%E6%B5%85%E8%B0%88%E8%BF%9B%E7%A8%8B%E5%92%8C%E7%BA%BF%E7%A8%8B%E7%9A%84%E5%8C%BA%E5%88%AB/1633193036539.png" alt="1633193036539"></p><p>​    <strong>一般来说，内核访问进程(包括进程的调度…means,只要使用到进程)，都是通过获得进程的task_struct来进行操作的。</strong></p><p>​    因此，最好就是把task_struct的指针放到寄存器中。但是，可能因为硬件设计的缺陷，并不是所有CPU都有足够多的寄存器去保存task_struct的指针。</p><p>​    <strong>因此，把task_struct放到thread_info，在放到进程的内核栈中保存是一种比较高雅的做法了。</strong>通过相对位移，就可以计算出thread_info在内核中的位置，然后取得task_struct的指针</p><h4 id="关于进程的上下文"><a href="#关于进程的上下文" class="headerlink" title="关于进程的上下文"></a>关于进程的上下文</h4><p>​    简单来说，就是当前进程运行的时候，CPU寄存器所保存的值。如果进行进程调度，需要把CPU的现场保存，这样才能让当前的进程在未来得以恢复。</p><h4 id="进程的创建"><a href="#进程的创建" class="headerlink" title="进程的创建"></a>进程的创建</h4><p>​    Unix采用了与众不同的进程创建方式。简单来说，分解为两个单独的函数执行<strong>fork()和exec()。</strong></p><p>​    fork通过拷贝当前进程，创建一个子进程，子进程和父进程的区别仅仅在于<strong>PID,PPID,一些资源(根据fork传入的参数确定哪些资源共享),统计量的不同。</strong></p><p>​    exec负责读取可执行文件，并且让他载入内存开始运行</p><h5 id="内存的写时拷贝"><a href="#内存的写时拷贝" class="headerlink" title="内存的写时拷贝"></a>内存的写时拷贝</h5><p>​    为了加快fork拷贝进程的效率，一开始fork出来的子进程跟父进程是共享内存空间的。</p><p>​    只在需要写入的时候，数据才会真正被复制，往后使得各个进程“真正”意义上拥有自己独立的地址空间。<strong>也就是说，资源只有在写入的时候才会被复制，只读的时候共享。</strong>这种推迟复制的技术，使得拷贝效率大大提高。</p><p>​    因此，fork的唯一开销，就是复制父进程的描述符。</p><h5 id="fork-—-gt-clone系统调用"><a href="#fork-—-gt-clone系统调用" class="headerlink" title="fork() — &gt; clone系统调用"></a>fork() — &gt; clone系统调用</h5><p>​    在Linux里面，fork( )通过在内核中调用clone，实现进程之间的拷贝。</p><p>​    然后，在内核中，clone通过do_fork( )实现大部分进程创建的工作。</p><ul><li>位子进程创建内核栈，thread_info，task_struct。<strong>所有都与当前进程相同</strong></li><li>复制完成后，把task_struct内许多成员设为初始值(主要是统计量)</li><li>然后更新一些mode，最主要的有两个<strong>内核态权限位 和 执行位</strong></li><li>分配pid</li><li>然后根据传递的参数决定，拷贝&#x2F;共享哪些资源</li><li>最后返回一个子进程的指针，并且马上exec( )</li></ul><h4 id="进程的终结"><a href="#进程的终结" class="headerlink" title="进程的终结"></a>进程的终结</h4><p>​    进程终结其实在Linux里面也具体分为两个步骤。(1)调用exit( ) 系统调用，<strong>不管是主动调用，还是被动调用。</strong>主动释放进程所拥有的资源。 (2)调用完exit之后，进程实际上已经被销毁，只是进程描述符还没清空，因此需要委托父进程进行销毁。</p><h5 id="exit做了哪些工作"><a href="#exit做了哪些工作" class="headerlink" title="exit做了哪些工作"></a>exit做了哪些工作</h5><ul><li>删除进程的timer定时器</li><li>删除指向内存的指针，<strong>如果该内存只有当前进程使用，则释放该内存</strong></li><li>把进程开除出IPC调度队列</li><li>把进程占用的资源，释放(计数减1)</li><li>给子进程重新找养父</li><li>这些做完之后，切换到别的进程。</li><li>此时进程实际上已经被kill，但是描述符仍旧在 （处于僵死状态）</li></ul><h5 id="删除进程描述符"><a href="#删除进程描述符" class="headerlink" title="删除进程描述符"></a>删除进程描述符</h5><p>​    调用exit( )后，尽管线程已经僵死不能再运行，但是系统仍旧保留着进程的描述符。<strong>这样做的目的是让，系统能够在子进程终结后，仍能获取它的信息。</strong></p><p>​    因此，系统设计者，把进程析构设计成<strong>资源释放和描述符的删除</strong>两个步骤。</p><hr><h3 id="线程"><a href="#线程" class="headerlink" title="线程"></a>线程</h3><p>​    Linux实现线程的机制非常独特。甚至从kernal的角度来说，系统没有线程这个概念。系统没有为线程准备特殊的数据结构和调度算法。</p><p>​    线程仅仅被视为一些共享资源的进程。每个线程都有自己的task_struct。所以在内核中，线程看起来就是进程**(仅仅和其他进程共享地址空间，资源)**</p><h4 id="线程的创建"><a href="#线程的创建" class="headerlink" title="线程的创建"></a>线程的创建</h4><p>​    具体操作也是调用fork( )。不过fork传入的参数是，子进程和父进程之间共享的资源。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs C">clone(CLONE__VM | CLONE_FS | CLONE_FILES | CLONE_SIGHAND , <span class="hljs-number">0</span>)<br></code></pre></td></tr></table></figure><p>​    传递给clone( )的参数，决定了新创建的进程行为方式以及父子之间共享的资源种类。下面是常见的参数。</p><p><img src="/../../images/%E6%B5%85%E8%B0%88%E8%BF%9B%E7%A8%8B%E5%92%8C%E7%BA%BF%E7%A8%8B%E7%9A%84%E5%8C%BA%E5%88%AB/1633194725511.png" alt="1633194725511"></p><p><strong>so,从系统内核的角度来说，进程和线程的区别是不大的，可以说是没有区别</strong></p><p>​    </p>]]></content>
    
    
    <categories>
      
      <category>Operate System</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>浅谈数据迁移的方案</title>
    <link href="/2021/10/02/data-transfer-server/"/>
    <url>/2021/10/02/data-transfer-server/</url>
    
    <content type="html"><![CDATA[]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>why B+ tree?</title>
    <link href="/2021/10/02/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%9B%B8%E5%85%B3/why-B-tree/"/>
    <url>/2021/10/02/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%9B%B8%E5%85%B3/why-B-tree/</url>
    
    <content type="html"><![CDATA[<p>​    数据库的索引，我想都并不陌生，简单来说，索引的出现就是为了帮助更快的进行查询。索引就像书的目录一样，帮助你快速定位想要的章节所在的地方。</p><p>​    索引能用的数据结构有很多，hash，有序数组，二叉树平衡树，红黑树，B树，B+树……但是为什么innodb引擎，最后选择B+树作为索引？下面我们来聊聊索引的各种优缺点</p><h2 id="Hash索引"><a href="#Hash索引" class="headerlink" title="Hash索引"></a>Hash索引</h2><p>​    索引 - 记录所在的位置，实质上很像很像一种 K-V结构。那么哈希表是对这种结构的检索效率是很高的。</p><p>​    下面，我从使用的角度来简单分析一下这种数据结构。</p><p>​    </p><p>​    哈希表是一种以 K - V 键值对来存储数据的数据结构。插入的时候根据key值，算出该键值对所在的数组位置。然后从该位置拉出一个链表，然后进行插入。</p><p><img src="https://static001.geekbang.org/resource/image/0c/57/0c62b601afda86fe5d0fe57346ace957.png" alt="img"></p><span id="more"></span><h3 id="缺点一"><a href="#缺点一" class="headerlink" title="缺点一"></a>缺点一</h3><p>​    这种数据结构做索引有个比较明显的缺点：<strong>hash冲突</strong>，对于hash表这种数据哈希冲突在所难免，这也是hash索引影响性能的一个原因。</p><p>​    不妨假设一个这样的场景，100w条记录的数据库因为hash冲突比较严重，需要进行扩容。一般来说，扩容有两种方案 (1)直接扩容 (2)渐进式rehash。</p><p>​    我的想法是，两种扩容方法对于这个量级的数据库来说都不太好。</p><ul><li>方案一，<strong>同步阻塞的时间过长了</strong> </li><li>对于方案二，因为rehash是需要<strong>fork一个子进程来进行rehash，这必然在一定程度上影响CPU的性能</strong>。</li></ul><h3 id="缺点二"><a href="#缺点二" class="headerlink" title="缺点二"></a>缺点二</h3><p>​    范围查询不友好，这点放在B树B+树说。对范围查询友好的索引，一般来说只有这两个。</p><p><strong>Q:如果采用SSD，检索&#x2F;IO很快，hash索引的范围查询时间会和B+树差不多嘛？</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><div class="code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></div></td><td class="code"><pre><code class="hljs bash">我个人觉得不会，举个查询age在18~60的范围查询。<br>首先，我们要明确一件事<span class="hljs-built_in">hash</span>函数，只能对一个key进行哈希。不能对 两个（若干个）key之间的间隙进行<span class="hljs-built_in">hash</span>，也就是说 18~60，哈希函数只能 <span class="hljs-built_in">hash</span>(18)..<span class="hljs-built_in">hash</span>(19)..<span class="hljs-built_in">hash</span>(20)....<span class="hljs-built_in">hash</span>(60)。<br>它不能直接<span class="hljs-built_in">hash</span>(18~60)。因此从这点来说，我觉得<span class="hljs-built_in">hash</span>索引即使采用SSD，它的范围查询效率还是很难让人接受的。而且我举得例子还是整形的情况，如果该字段是浮点数类型，那么就要从浮点数的最小精度开始枚举，这种开销显然十分巨大。<br></code></pre></td></tr></table></figure><h3 id="缺点三"><a href="#缺点三" class="headerlink" title="缺点三"></a>缺点三</h3><p>​    个人觉得，hash索引的并发度不会太好。以下，仅讨论 <strong>间隙锁（范围锁）</strong>。为什么这么说呢？其实从他的结构上我们就可以看出来</p><ul><li><p>hash索引在数据的组织上，并没有逻辑上的有序，因此没办法向B+树那样直接加锁。并且对于空的记录，没办法锁</p></li><li><p>这锁加在哪里？加在节点上吗？那么第一步是要对范围内的记录进行查询，上面已经说了，哈希索引对范围查询不友好，因此不行。</p></li><li><p>锁加在链表（数组），这样加锁的话，显然不行，因为该链表上的数据不是所有的节点都符合加锁的条件的。</p><p>因此，考虑以上原因，hash索引的并发性真的不够强。</p><p>   所以，<strong>哈希表这种结构适用于只有等值查询的场景</strong>，比如 Memcached 及其他一些 NoSQL 引擎。 对于redis来说哈希是一个很重要的数据结构。</p></li></ul><h2 id="有序数组索引"><a href="#有序数组索引" class="headerlink" title="有序数组索引"></a>有序数组索引</h2><p><img src="/../../images/why-B-tree/1635774550939.png" alt="1635774550939"></p><p>​    有序数组很简单，就是拿数组进行存储。但是这个存储是有条件的：<strong>插入的数据必须是严格自增的</strong>。如果你插入了 1，10。那么下一条的数据只能大于10，不能插入9。</p><p>​    为什么要这样？<strong>原因很简单，避免空间的浪费。</strong></p><p>​    并且，这种索引的查询效率很好，因为可以用到二分查找。因为在存储的时候逻辑上是有序的，因此它范围查询也很好。</p><p>​    <strong>因此，只要它的场景符合，插入的数据都是严格自增的，那么就可以采用这种索引。</strong></p><h2 id="二叉树索引"><a href="#二叉树索引" class="headerlink" title="二叉树索引"></a>二叉树索引</h2><p>​    这里就不说普通的二叉树了，因为普通的二叉树可能会出现树高不平衡的问题。下面所说的树都是平衡树。</p><p><img src="https://static001.geekbang.org/resource/image/04/68/04fb9d24065635a6a637c25ba9ddde68.png" alt="img"></p><p>​    这种数据结构的特点，不管是对于查找还是插入都十分友好。并且不像<strong>有序数组索引那样，要求索引字段必须是严格自增的。</strong></p><p>​    理论上，二叉树的效率是很高的，但是为什么实际上数据库的存储都不使用二叉树？<strong>这个问题的答案是因为，一般来说索引很大，不可能只存在于内存上，一定要写入磁盘里面。</strong></p><p>​    我们可以假设一个场景，100万条记录的表，它的二叉树高大概在20左右。我们知道在磁盘中，以块来存储的。那么查询一条数据，最坏的情况就是<strong>20 x 10ms &#x3D; 200 ms。</strong>这个查询速度难以让人接受。</p><h2 id="为什么使用N叉树"><a href="#为什么使用N叉树" class="headerlink" title="为什么使用N叉树"></a>为什么使用N叉树</h2><p>​    为了让一个查询尽量地少读磁盘，就必须让查询的过程中尽量少访问数据块。为了减少磁盘的IO，不妨考虑以下N叉树。</p><p>​    为什么要用N叉树，我们看N叉树的节点，一个节点存储多条数据，而且每个节点内的数据在逻辑上都是有序的。而数据块，也是存储多个数据。<strong>那么，我们可以不可以把数据块抽象成N叉树的节点呢？</strong>答案是，这种做法完全可行。</p><figure class="highlight verilog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs verilog">以InnoDB为例，磁盘和内存交互的单位大小是<span class="hljs-number">16</span>KB。假设，只有一个索引字段（bigint）的情况下，我们看看可以存储多少个记录，而且树高是多少。<br>索引字段bigint 占<span class="hljs-number">8</span><span class="hljs-keyword">byte</span> 和 <span class="hljs-number">6</span>Byte指向下一页的指针 （为什么是<span class="hljs-number">48</span><span class="hljs-keyword">bit</span>，因为目前<span class="hljs-number">64</span>位的硬件实际上只能支持<span class="hljs-number">256</span>TB，因此只需要<span class="hljs-number">48</span><span class="hljs-keyword">bit</span>来寻址）<br>所以 N = <span class="hljs-number">16</span>KB / <span class="hljs-number">14</span>B ≈ <span class="hljs-number">1200</span>。因此每页能存放<span class="hljs-number">1200</span>条记录（该记录不是真的记录，只是用来方便查找的）。<br>一般来说，B+树树高为<span class="hljs-number">4</span>,那么最多存储 <span class="hljs-number">1200</span>^<span class="hljs-number">3</span> = <span class="hljs-number">17</span>亿条数据。也就是说，从<span class="hljs-number">17</span>亿数据中，只需要三次查盘就可以了。<br></code></pre></td></tr></table></figure><p>​    OK，所以我们不使用二叉树作为我们的索引，是因为磁盘适配性。总的来说，采用B+树来个人感觉只是它的普适性最强，在各种各样的场景中都还有不错的效率。</p><p>​    但是，如果针对特殊的场景的话，我们还是可以选择其他索引的。</p>]]></content>
    
    
    <categories>
      
      <category>数据库</category>
      
    </categories>
    
    
    <tags>
      
      <tag>MySQL</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>浅谈数据库的锁(一)</title>
    <link href="/2021/10/02/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%9B%B8%E5%85%B3/mysql-lock/"/>
    <url>/2021/10/02/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%9B%B8%E5%85%B3/mysql-lock/</url>
    
    <content type="html"><![CDATA[<h3 id="全局锁和表锁-—-server层"><a href="#全局锁和表锁-—-server层" class="headerlink" title="全局锁和表锁 — server层"></a>全局锁和表锁 — server层</h3><h4 id="全局锁"><a href="#全局锁" class="headerlink" title="全局锁"></a>全局锁</h4><p>​    顾名思义，全局锁就是给整个数据库实例进行加锁。命令是<code>Flush tables with read lock</code>。</p><p>​    当需要整个数据库进入只读状态时，就用这个命令。<strong>一般来说,只有全局备份才会使用这个命令，但即使是做全局备份，我也不推荐使用这个锁。</strong></p><p>​    因为对全局加锁，带来的坏处很多很多。</p><ul><li><p>对全局进行加锁，那么基本上所有操作都会被阻塞，通常情况业务就会停摆。</p></li><li><p>如果在从库进行备份，主库传来的binlog，从库不能执行。这会加大主从数据库之间的延迟</p></li><li><p>通过Read - View来进行全局备份，效率更高。</p></li></ul><h5 id="保留全局锁的原因"><a href="#保留全局锁的原因" class="headerlink" title="保留全局锁的原因"></a>保留全局锁的原因</h5><p>​    为了让不支持事务的存储引擎也能够保持一致性。全局锁，每次只会让一个“事务”操作数据库。</p><span id="more"></span><h4 id="表级锁"><a href="#表级锁" class="headerlink" title="表级锁"></a>表级锁</h4><p>MySQL里面表级别的锁有两种:</p><ul><li>一种是表锁</li><li>另一种是元数据锁 (meta data lock，MDL)。</li></ul><h5 id="表锁-—-DML"><a href="#表锁-—-DML" class="headerlink" title="表锁 — DML"></a>表锁 — DML</h5><p>表锁，又分为 read lock 和 write lock。表级读写锁有以下特点：</p><ul><li><p>很显然跟其他读写锁一样，都是符合<strong>读读共享，读写和写写是互斥的</strong></p></li><li><p>除此以外，还有另外 表锁不仅限制别的事务的操作，还有限制当前持有锁的事务的操作</p></li></ul><figure class="highlight css"><table><tr><td class="gutter"><div class="code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></div></td><td class="code"><pre><code class="hljs css">特别值得注意的有以下两点，其他都跟别读写规则一样<br><span class="hljs-number">1</span>.持有读锁的事务<span class="hljs-selector-tag">A</span> 会阻塞想要修改该对象的事务<span class="hljs-selector-tag">B</span><br><span class="hljs-number">2</span>.持有读锁的事务<span class="hljs-selector-tag">A</span>，接下来事务<span class="hljs-selector-tag">A</span>也只能对该对象进行读操作，写操作也是不允许的。<br></code></pre></td></tr></table></figure><h5 id="MDL锁-—-DDL"><a href="#MDL锁-—-DDL" class="headerlink" title="MDL锁 — DDL"></a>MDL锁 — DDL</h5><p>​    为什么要有MDL锁？想象一下这种场景，事务A在对表1进行查询(查询到一半)，此时另外一个事务B要对表进行结构上的增加字段。</p><p>​    那么，我们希望查询出来的结果，一半是旧的表结构，另一半是新的表结构，多一些字段吗？显然不。</p><p>​    因此，就需要额外的措施去进行一下限制。但是这依靠<strong>表读写锁是做不到的。因为表读写锁，仅仅限制的是DML操作，对DDL操作没有做任何限制。</strong></p><p>​    因此，需要另外一种锁去限制表的DDL操作，也就是<strong>MDL锁</strong></p><p><strong>MDL如何起作用？</strong></p><p>其实它的作用原理，跟读写锁非常相似:</p><ul><li><p>当事务对表的数据做 DML操作时，事务对该表加 MDL读锁。</p><ul><li>因为读锁之间共享，所以不影响别的事务对表的MDL操作</li></ul></li><li><p>当事务要对表做DDL操作时，事务对表加MDL写锁。</p><ul><li>因为读写之间互斥，只要有事务在DML，那么表结构修改就会被阻塞</li><li>同理，只要DDL还没被提交，那么别的事务对表的DML就会被阻塞</li><li>这样保证了，查询出来的数据，结构都是一样的</li></ul></li></ul><h5 id="给表加字段的坑"><a href="#给表加字段的坑" class="headerlink" title="给表加字段的坑"></a>给表加字段的坑</h5><p><strong>有时候给表加一个字段，导致整个库挂了。</strong></p><p><img src="/../../images/%E6%B5%85%E8%B0%88MySQL%E7%9A%84%E9%94%81/1633185917151.png" alt="1633185917151"></p><ul><li>sessionA先启动，拿到MDL读锁</li><li>sessionB启动拿到读锁，并执行</li><li>sessionC需要修改表结构，申请写锁，被阻塞。</li><li>sessionD想要申请读锁，<strong>但是被阻塞住了</strong><ul><li><strong>个人猜测，申请锁应该是通过一个队列，类似对头阻塞的机制</strong></li></ul></li></ul><p>​    因此，sessionC被阻塞其实没什么关系，但是会导致sessionC后面的所有查询事务都被阻塞了。<strong>最主要的原因就是，事务中某个语句申请一把锁。该锁是会等整个事务结束才把锁释放。</strong></p><h3 id="行锁-—-各自引擎具体实现"><a href="#行锁-—-各自引擎具体实现" class="headerlink" title="行锁 — 各自引擎具体实现"></a>行锁 — 各自引擎具体实现</h3><div class="code-wrapper"><pre><code class="hljs"> MySQL 的行锁是在引擎层由各个引擎自己实现的。但并不是所有的引擎都支持行锁，比如 MyISAM 引擎就不支持行锁。</code></pre></div><p>​    不支持行锁意味着并发控制只能使用表锁，对于这种引擎的表，同一张表上任何时刻只能有一个更新在执行，这就会影响到业务并发度。</p><h4 id="两段锁协议-2PC"><a href="#两段锁协议-2PC" class="headerlink" title="两段锁协议 2PC"></a>两段锁协议 2PC</h4><p><img src="/../../images/%E6%B5%85%E8%B0%88MySQL%E7%9A%84%E9%94%81/1633185936238.png" alt="1633185936238"></p><p>​    在这个流程中，实际上事务B仍旧会阻塞。<strong>实际上事务 B 的 update 语句会被阻塞，直到事务 A 执行 commit 之后，事务 B 才能继续执行。</strong> 为什么？</p><ul><li><p>当一个事务中，具体到某个语句执行，该语句需要行锁，才会去申请</p></li><li><p>当该语句执行完毕，行锁不会马上释放，而是等到整个事务结束才会释放。</p></li><li><p>因此，我们在一个事务中，尽量把需要行锁的语句进行后置。</p></li></ul><h4 id="意向锁"><a href="#意向锁" class="headerlink" title="意向锁"></a>意向锁</h4><p>​    行的读写锁，功能我就不详细讲了。跟普通读写锁很类似，下面我来讲一下意向锁。为什么要有意向锁？我们可以想象一些以下这个场景：</p><p>​    当一个事务A想对表加一个表锁。因为表锁和行锁存在一定的互斥关系，那么它就必须对全表的数据进行扫描，确定是否有行锁，如果没有行锁则进行加锁。</p><p>​    这个效率实在太低了，难以让人接受！</p><p><strong>解决办法</strong></p><ul><li>如果我们在对表某个数据加行锁的时候，能不能在表上面打一个tag。</li><li>当别的事务想要加表锁，看到tag就知道，目前该表中存在行锁，那么加表锁的操作就会阻塞</li></ul><p>这种解决思路就称为意向锁。</p><h4 id="deal-lock-和-检测"><a href="#deal-lock-和-检测" class="headerlink" title="deal lock 和 检测"></a>deal lock 和 检测</h4><p><strong>解决死锁的策略</strong></p><ul><li>阻塞超时等待，等待到一定时间放弃。</li><li>死锁检测，当发生死锁后主动回滚死锁中某一个事务，让破坏死锁的条件</li></ul>]]></content>
    
    
    <categories>
      
      <category>数据库</category>
      
    </categories>
    
    
    <tags>
      
      <tag>MySQL</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>浅谈数据复制</title>
    <link href="/2021/10/02/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%9B%B8%E5%85%B3/data-replicate/"/>
    <url>/2021/10/02/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%9B%B8%E5%85%B3/data-replicate/</url>
    
    <content type="html"><![CDATA[<h2 id="数据复制"><a href="#数据复制" class="headerlink" title="数据复制"></a>数据复制</h2><h3 id="数据复制的目的"><a href="#数据复制的目的" class="headerlink" title="数据复制的目的"></a>数据复制的目的</h3><ul><li>使数据中心更加接近客户端的物理位置，降低访问延迟 <strong>(提高效率)</strong></li><li>当部分组件发生故障时，会自动切换到别的组件**(高可用性)**</li><li>拓展至多台机器以同时提供吞吐率</li></ul><p>​    <strong>数据复制的所有技术挑战都是复制那些热点数据，如何把热点数据复制到别的节点上面</strong>。</p><!--more--><h3 id="主从复制"><a href="#主从复制" class="headerlink" title="主从复制"></a>主从复制</h3><h4 id="工作原理"><a href="#工作原理" class="headerlink" title="工作原理"></a>工作原理</h4><p>​    对于每一个记录的写入，所有副本都需要更新；否则，某些节点会出现数据不一致的情况。</p><p>​    主从复制的工作原理如下:</p><ul><li>指定其中一个节点成为master，其他节点为slave</li><li>所有写请求，转发给到master。slave则处理读请求。</li><li>当master做好本地存储之后，把这些操作通过binlog，发送给slave。然后让slave执行。</li></ul><hr><h4 id="同步复制-与-异步复制"><a href="#同步复制-与-异步复制" class="headerlink" title="同步复制 与 异步复制"></a>同步复制 与 异步复制</h4><p><img src="/../../images/%E6%B5%85%E8%B0%88%E6%95%B0%E6%8D%AE%E5%A4%8D%E5%88%B6/1633183736639.png" alt="1633183736639"></p><p>​    如图，master和从节点1之间的复制是同步的，即主节点需要等待从节点1的复制完成写入。</p><p>​    master和从节点2之间的复制时异步的，master发起一个复制后，不用阻塞等待，便直接提交了。等从节点2完成后，才真的向主节点发起一个确认。</p><p><strong>同步复制的特点</strong></p><ul><li>主从节点之间数据的距离一定是很低的，因此如果发生切换的时候，可以在从节点查询到最新的数据</li><li>如果从节点无法回复确认(或者确认丢失)，那么master会一直阻塞等待。并且会影响后面的操作。</li></ul><p><strong>异步复制的特点</strong></p><ul><li>最大的特点就是效率非常高，这里的效率不是指复制很快。是指不用阻塞，发起复制之后不用等待确认回复，直接可以用了。</li><li>没有保证多久能复制完成，这会造成主从之间的距离比较大</li></ul><p><strong>实际上主从的取舍</strong></p><p>​    在实际dba环境中，如果一个复制让所有节点完成后才能接受请求，这不太现实(因为距离可能很远，数据量很大，节点很多，网络原因等…)</p><p>​    因此，一般来说通过同步异步混合的<strong>半同步办法</strong>。这种办法可以保证至少有两个节点拥有最新的数据(恢复的时候比较好)。并且不会阻塞很长时间</p><ul><li>把其中一到两个节点设置为同步复制</li><li>其他节点设置为异步复制</li></ul><hr><h4 id="配置新的从节点"><a href="#配置新的从节点" class="headerlink" title="配置新的从节点"></a>配置新的从节点</h4><p>​    当一个空白的节点要作为slave加入集群中时，一般按照如下操作步骤</p><ul><li>把该节点注册到集群，master和slave之间建立连接</li><li>master执行mysqldump(good to have)，把最近一次的全量备份发送到slave</li><li>并且从备份的时间点开始发送binlog</li></ul><hr><h4 id="处理失效的节点"><a href="#处理失效的节点" class="headerlink" title="处理失效的节点"></a>处理失效的节点</h4><p><strong>从节点失效处理策略 — 追赶试恢复</strong></p><ul><li>slave查询最后一笔事务的事务id，然后连接到主节点</li><li>主节根据事务id，找到对应的binlog，然后发送断开连接时发生的数据变更</li></ul><p><strong>master节点失效 —选举新的主节点</strong></p><ul><li>发送heart-beat，确认主节点是否存活</li><li>在集群中选举新的主节点</li><li>重新配置<ul><li>建立新主节点和从节点之间的连接</li><li>防止脑裂的情况</li></ul></li></ul><p><strong>可能存在的问题</strong></p><ul><li>如果新的主节点 并未收到所有主节点的数据。(还在接受旧主节点的binlog状态中)。</li><li>宕机的主节点很快又上线，但他（还认为自己是主节点，没意识到改朝换代了）继续发送binlog，让其他slave进行同步</li><li>这时候新的主节点就会很困惑，不知道是否要接受旧主节点的binlog写数据。<ul><li>不写，违背了数据持久化的承诺</li><li>写，这非常冲突</li></ul></li></ul><hr><ul><li>主节点宕机，选举出新的主节点。(新的主节点和旧的主节点之间，数据存在一定距离)</li><li>新主节点的自增id落后于旧的节点。但是某些中间件已经同步了旧主节点的 <strong>那部分自增id的记录</strong></li><li>这会导致一种数据泄露的问题</li></ul><hr><ul><li>脑裂</li></ul><hr><h4 id="复制滞后的问题"><a href="#复制滞后的问题" class="headerlink" title="复制滞后的问题"></a>复制滞后的问题</h4><p><strong>马上读 — 好像数据丢失了</strong></p><p>​    根据CAP理论，高可用性和一致性，只能选择一个。大多数分布式系统都是选择高可用性，因此会出现数据丢失的问题。</p><p><img src="/../../images/%E6%B5%85%E8%B0%88%E6%95%B0%E6%8D%AE%E5%A4%8D%E5%88%B6/1633183754202.png" alt="1633183754202"></p><p>​    解决马上读问题，一般常用的办法。</p><ul><li>如果用户访问会被修改的内容则从master节点读取；否则，从slave节点读取。 </li><li>举个例子，在一个博客系统中，你编辑自己的文章并且发布，当然希望马上能读取，这时候我们从master节点拉自己的文章。但是读别的文章，就可以从slave上面进行读取</li></ul><hr><ul><li>客户端保存更新操作的timeStamp，发送请求时把这个东西附送上</li><li>一个副本根据timeStamp读取数据，判断一下他的数据是否够新，如果不够新，就转发给下一个副本节点，从它那里取数据</li></ul><p><strong>单调读 — 两次读到的内容不一样</strong></p><ul><li>简单来说，第一次读，转发到某个节点上，该节点是最新的数据</li><li>紧接着第二次请求，但是该请求转发到另外的节点上。该节点还没完成数据同步，因此读到旧版本的数据</li></ul><p><img src="/../../images/%E6%B5%85%E8%B0%88%E6%95%B0%E6%8D%AE%E5%A4%8D%E5%88%B6/1633183769266.png" alt="1633183769266"></p><p><strong>顺序写入问题</strong></p><ul><li>某些记录之间存在顺序关系</li><li>比如insert a，update a。这两个存在明显的顺序关系，但是可能因为网络等原因，到达从节点之间不一致什么的</li></ul><p>​    目前解决这类问题的办法，好像是通过一些拓扑算法，显式跟踪事件之间的因果关系。</p><p><strong>实际开发中</strong></p><p>​    如果在开发中，不是对数据滞后带来的后果无法容忍。一般都会忽略到他们，比如说，在更新头像这服务上面，很多时候更新头像是有延迟的，一段时间后才会真的让你更新成功。</p><p>​    不然，如果不能忽略，上面的处理方案，都是要在应用层进行编写。这会给应用层的代码逻辑带来很大的挑战。</p><h3 id="多主节点复制-—-数据中心"><a href="#多主节点复制-—-数据中心" class="headerlink" title="多主节点复制 — 数据中心"></a>多主节点复制 — 数据中心</h3><p>​    为了实现异地容灾，或者说缩短客户端和数据库的距离。通常把整个数据库集群做一个备份，每个备份作为一个数据中心。</p><p>​    每个数据中间内部，都是采用主从复制。数据中心之间，采用多主节点复制。</p><p><img src="/../../images/%E6%B5%85%E8%B0%88%E6%95%B0%E6%8D%AE%E5%A4%8D%E5%88%B6/1633183815399.png" alt="1633183815399"></p><h4 id="如何处理写冲突"><a href="#如何处理写冲突" class="headerlink" title="如何处理写冲突"></a>如何处理写冲突</h4><p>​    多主从最大的问题就是容易产生写冲突。</p><p>​    例如，两个用户同时编辑wiki页面。他们的操作都分别路由到两个不同数据中心，这是完全合法的操作。</p><p>​    但是，两个数据中心进行merge的时候，则会出现冲突问题</p><p><img src="/../../images/%E6%B5%85%E8%B0%88%E6%95%B0%E6%8D%AE%E5%A4%8D%E5%88%B6/1633183827053.png" alt="1633183827053"></p><p><strong>同步 和 异步 检测写冲突</strong></p><p>​    如果是单主从模式下，只能有一个写，另外一个写操作会被阻塞。然而，在多主从这种架构之下，在数据中心的角度来看，每个写请求都是成功的。</p><p>​    因此，每次写入操作都能完成，并且冲突只能异步地，在以后才进行一次检测。</p><p>​    理论上，也不是不能进行同步检测。只需要像2PC一样，让一个节点出来充当monitor。但是会十分影响性能。</p><p><strong>避免冲突</strong></p><p>​    目前来说，处理写冲突的最好的方案就是避免冲突。<strong>把不同记录的修改，根据hash进行路由，这样不同数据中心之间”被修改的记录”就会交错，不会有重合部分，自然就不会有冲突</strong></p><p><strong>Last Write Win — LWW</strong></p><p>​    每个更新操作，附带一个时间戳。数据中心之间进行收敛的时候，根据时间戳进行复制。<strong>原则是，最新的记录要覆盖之前的记录</strong>。</p><p>​    这样，数据中心最后会收敛到一致。</p><h4 id="多主从的拓扑结构"><a href="#多主从的拓扑结构" class="headerlink" title="多主从的拓扑结构"></a>多主从的拓扑结构</h4><p>​    常见的拓扑结构有三种(1)环形 (2)星形 (3)全连接。<strong>一般来说，越复杂的拓扑结构。稳定性越高(指的是，不会因为关键节点宕机而整个网络瘫痪)</strong></p><p><img src="/../../images/%E6%B5%85%E8%B0%88%E6%95%B0%E6%8D%AE%E5%A4%8D%E5%88%B6/1633183836515.png" alt="1633183836515"></p><p><strong>问题</strong></p><ul><li>对于环形和星形的问题，其实很简单。跟计算机网络一样，如果某个<strong>crux节点宕机了，整个服务会受到相当大的影响</strong>。</li><li>全连接网络其实也有很一些问题，主要是受到网络延迟的影响**(就是说，节点收到同一份binlog的时间可能是不一样的)**</li></ul><p><img src="/../../images/%E6%B5%85%E8%B0%88%E6%95%B0%E6%8D%AE%E5%A4%8D%E5%88%B6/1633183848245.png" alt="1633183848245"></p><figure class="highlight n1ql"><table><tr><td class="gutter"><div class="code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></div></td><td class="code"><pre><code class="hljs n1ql">1.节点123 是不同的数据中心<br>2.客户端A <span class="hljs-keyword">insert</span>一条记录到节点<span class="hljs-number">1</span>。然后节点<span class="hljs-number">1</span> 把该记录同步到其他节点<br><span class="hljs-number">3.</span>节点<span class="hljs-number">3</span>，收到同步的记录。并且客户端B，对该记录进行<span class="hljs-keyword">update</span>。并且同步到别的节点。<br>(显然 <span class="hljs-keyword">insert</span> 和 updata是具有顺序关系的...)<br><span class="hljs-number">4.</span>万一，节点<span class="hljs-number">2</span>收到的信息是(<span class="hljs-keyword">update</span>，<span class="hljs-keyword">insert</span>)，那么就会发生错误。<br><br>问题解决办法：<br><span class="hljs-number">1.</span>为了使得日志消息正确有序，可以使用一种称为版本向量的技术。<br></code></pre></td></tr></table></figure><h3 id="无主节点复制"><a href="#无主节点复制" class="headerlink" title="无主节点复制"></a>无主节点复制</h3><p>​    一些存储系统采用不同的设计思路：选择放弃主节点，所有副本能够直接接受写请求。<strong>换句话来说，所有节点都是主节点</strong>。 </p><p>​    有一些无主节点系统的实现，每个节点都可以直接接收客户端的写请求。但有一些实现，会有一个协调者，他来统一进行管理。</p><h4 id="节点失效时写入数据库"><a href="#节点失效时写入数据库" class="headerlink" title="节点失效时写入数据库"></a>节点失效时写入数据库</h4><p><strong>写数据的过程</strong></p><ul><li>假设某个数据库系统中，有三个节点。其中一个节点宕机下线了</li><li>客户端直接发送写请求给到所有节点</li><li>假设三个节点中，只有两个恢复ack。我们就认为他就是写入成功</li></ul><p><strong>读数据的过程</strong></p><ul><li>当一个客户端从数据库读取数据时，它不是向一个副本发送请求。而是并行发送多个副本。</li><li>当客户端拿到结果后，根据投票或者版本号，来确认采用哪个副本的。</li></ul><h4 id="数据修复"><a href="#数据修复" class="headerlink" title="数据修复"></a>数据修复</h4><p>​    如果某个节点中途下线了，如何让他修复数据追赶上进度？</p><p><strong>读修复</strong></p><ul><li>当客户端从三个副本那里拿到数据之后，假设拿到数据时(版本1，版本3，版本3)。</li><li>monitor就会觉得版本1数据落后了，因此把版本3数据往该节点写入。</li></ul><p><img src="/../../images/%E6%B5%85%E8%B0%88%E6%95%B0%E6%8D%AE%E5%A4%8D%E5%88%B6/1633183867613.png" alt="1633183867613"></p><p><strong>反熵</strong></p><ul><li>后台有进程不断查找副本之间数据的差异</li><li>并且会自动进行修复</li></ul>]]></content>
    
    
    <categories>
      
      <category>数据库</category>
      
    </categories>
    
    
    <tags>
      
      <tag>分布式</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>MySQL基础架构 --- 一条语句是怎么执行的?</title>
    <link href="/2021/10/01/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%9B%B8%E5%85%B3/mysql-base/"/>
    <url>/2021/10/01/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%9B%B8%E5%85%B3/mysql-base/</url>
    
    <content type="html"><![CDATA[<p>​    </p><p>​    对于一个很简单的表，里面只有一个字段ID，执行下列语句时</p><figure class="highlight plaintext"><table><tr><td class="gutter"><div class="code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><pre><code class="hljs mysql">select * from T where ID = 10;<br></code></pre></td></tr></table></figure><p>​    我们对该语句的执行过程进行，一个拆解。</p><h3 id="MySQL的基本架构图"><a href="#MySQL的基本架构图" class="headerlink" title="MySQL的基本架构图"></a>MySQL的基本架构图</h3><p><img src="/../../images/MySQL%E5%9F%BA%E7%A1%80%E6%9E%B6%E6%9E%84-%E4%B8%80%E6%9D%A1%E8%AF%AD%E5%8F%A5%E6%98%AF%E6%80%8E%E4%B9%88%E6%89%A7%E8%A1%8C%E7%9A%84/1633185245582.png" alt="1633185245582"></p><!--more--><ul><li>连接器：管理数据库连接</li><li>分析器：类似编译原理，进行一个SQL语法的分析，判断是否符合语义</li><li>优化器：进行索引的选择</li><li>执行器：引擎操作器，拿到结果</li><li>缓存：    保存之前的页，如果有就直接返回（一般mysql很少开启缓存）</li><li>引擎层：如何存放，并且组织数据</li></ul><h3 id="日志系统-一条更新语句如何完成-两阶段提交"><a href="#日志系统-一条更新语句如何完成-两阶段提交" class="headerlink" title="日志系统 一条更新语句如何完成(两阶段提交)"></a>日志系统 一条更新语句如何完成(两阶段提交)</h3><p>​    之前学习<code>select</code>流程的时候，一条查询语句的执行顺序是<code>客户端</code>，<code>连接器</code>，<code>分析器，优化器</code>，<code>执行器</code>,<code>引擎</code>。</p><p>​    update语句，跟select语句有点类似，但是又有很多区别（涉及到日志的两阶段提交）</p><h3 id="update语句执行流程"><a href="#update语句执行流程" class="headerlink" title="update语句执行流程"></a>update语句执行流程</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs mysql">update T set c = c + 1 <br>where ID = 10;<br></code></pre></td></tr></table></figure><p>​    对于这条更新语句，select所走的所有流程，update都会走一遍，因为只有拿出该页才能对record进行一个update。</p><p>​    但是与查询流程不同的是，update还涉及到两个很重要的模块**redo log(重做日志)和binlog(归档日志)**。</p><p>​    </p><h3 id="redo-log-引擎层的日志"><a href="#redo-log-引擎层的日志" class="headerlink" title="redo log(引擎层的日志)"></a>redo log(引擎层的日志)</h3><p>​    在Innodb中，redo log可以理解为一个可以循环使用的文件。为了循环使用，必须有两个指针。分别为<strong>write_pos 和 check_pos</strong>。</p><ul><li>write_pos:新的一条日志记录，从哪里开始记录</li><li>check_pos:表示，循环开始的地方。如果write_pos &#x3D;&#x3D; check_pos，代表当前文件已经写满，必须fresh当前的重做日志了</li></ul><p><img src="/../../images/MySQL%E5%9F%BA%E7%A1%80%E6%9E%B6%E6%9E%84-%E4%B8%80%E6%9D%A1%E8%AF%AD%E5%8F%A5%E6%98%AF%E6%80%8E%E4%B9%88%E6%89%A7%E8%A1%8C%E7%9A%84/1633185258741.png" alt="1633185258741"></p><p><strong>作用</strong></p><ul><li>让数据库有了对事务进行重做的能力，能把还没来得及归档的数据，通过日志重新跑一编。</li></ul><h3 id="binlog-server层日志"><a href="#binlog-server层日志" class="headerlink" title="binlog(server层日志)"></a>binlog(server层日志)</h3><p>​    MySQL 整体来看，其实就有两块：</p><ul><li>一块是 Server 层，它主要做的是 MySQL 功能层面的事情；</li><li>还有一块是引擎层，负责存储相关的具体事宜。</li></ul><p>​    binlog就是server层独有的日志，记录的是<strong>对某个记录的逻辑上的操作(比如，给ID&#x3D;2这条记录的C字段+1)</strong></p><p><strong>为什么server层也要有一个日志？</strong></p><ul><li>因为，innodb不是mysql原生的存储引擎，而是作为一个插件来进行补充的。</li><li>因此server原生的MYISAM引擎，理所应当也要有一个日志binlog</li></ul><p><strong>两者区别</strong></p><ul><li><p>redo log只属于innoDB引擎；binlog是所有MySQL中server层的日志</p></li><li><p>redo log物理日志，每条记录表示在某个数据页进行了什么操作</p></li><li><p>binlog是逻辑日志，每条记录的逻辑变化(给某个字段 + n)</p></li><li><p>redo log循环写，binlog顺序写</p></li></ul><h3 id="update的两阶段提交"><a href="#update的两阶段提交" class="headerlink" title="update的两阶段提交"></a>update的两阶段提交</h3><p>​    有了两个日志的概念，下面讲讲update语句的执行流程</p><ul><li>通过执行器，取出对应的数据页</li><li>并且给对应的记录进行操作，再给到innoDB引擎</li><li>引擎拿到改写的页后，刷盘，并且把<strong>该操作写入redo log中</strong></li><li>并把对应的事务ID标记为，<strong>prepare可以提交状态</strong></li></ul><hr><ul><li>prepare之后，告知执行器，刷盘完成了。</li><li>server层中，生成该操作的binlog，并且写入磁盘，再告知引擎</li><li>引擎把prepare状态改为commit</li></ul><p>​    以上就是两阶段提交的全部过程。</p><p><strong>如何让数据库恢复到半个月内的任意一秒？</strong></p><p>场景:</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs">当需要恢复到指定的某一秒时，比如某天下午两点发现中午十二点有一次误删表，需要找回数据<br></code></pre></td></tr></table></figure><p>操作:</p><ul><li>找到最近一次的全量备份（read-view）</li><li>然后重跑全量备份 到 昨天中午十二点的删表操作的binlog</li></ul><p><strong>为什么要有两阶段提交？</strong></p><ul><li><p>因为有了两阶段提交，数据库通过这两个日志进行crash-safe之后，一定能保证恢复的数据是自洽的。</p></li><li><p>因为恢复数据库的时候，需要重跑binlog。我们需要拿出binlog的每条记录跟redo log进行比对，看看是否commit，如果commit就执行，不然就放弃</p></li></ul><p><strong>如果没有两阶段提交</strong></p><p>(1)先提交redo log，再提交binlog</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs routeros">1.redo log中记录了一条，<span class="hljs-builtin-name">set</span> <span class="hljs-attribute">C</span>=C+1 WHERE ID = 10的记录,(<span class="hljs-attribute">C</span>=0)<br>2.写入binlog中途宕机了，当值binlog没有该记录<br>3.crash的时候，我们是希望<span class="hljs-attribute">C</span>=1,因为redo log已经记录了<br>4.但是重跑binlog的时候，缺失了该条记录，因此最后<span class="hljs-attribute">C</span>=0,显然跟想要的结果不一致<br></code></pre></td></tr></table></figure><p>(2)先提交binlog，再提交redo log</p><figure class="highlight mel"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs mel"><span class="hljs-number">1.</span>binlog写完，<span class="hljs-keyword">redo</span> <span class="hljs-keyword">log</span>没写完就宕机了<br><span class="hljs-number">2.</span>意味着，其实db是不承认这条记录的<br><span class="hljs-number">3.</span>因此跑binlog的时候，该条在<span class="hljs-keyword">redo</span> <span class="hljs-keyword">log</span>缺失的记录仍旧会被执行。<br><span class="hljs-number">4.</span>最后造成了，恢复的数据库 &gt; 想要的数据库。<br></code></pre></td></tr></table></figure><h3 id="QA"><a href="#QA" class="headerlink" title="QA"></a>QA</h3><p><strong>1.为什么binlog没有crash-safe功能</strong></p><figure class="highlight mel"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs mel"><span class="hljs-number">1.</span>根本原因是 <span class="hljs-keyword">redo</span>-<span class="hljs-keyword">log</span> 是循环写。因为是循环写，带来了刷盘机制<br><span class="hljs-number">2.</span>binlog 记录的是给<span class="hljs-string">&quot;id = 2,这行某个极端+1&quot;</span><br><span class="hljs-number">3.</span>因为binlog没有刷盘机制，因此没有一个标记，让binlog判断哪些数据已经刷盘了<br><br>举个栗子<br>binlog中有两条数据,init c = <span class="hljs-number">0</span><br>(<span class="hljs-number">1</span>)给ID=<span class="hljs-number">2</span>,这行c字段加<span class="hljs-number">1</span><br>(<span class="hljs-number">2</span>)给ID=<span class="hljs-number">2</span>,这行c字段加<span class="hljs-number">1</span><br><br>假设，写入(<span class="hljs-number">1</span>)的时候，刷盘了。那么<span class="hljs-keyword">redo</span> <span class="hljs-keyword">log</span>只要重做(<span class="hljs-number">2</span>)即可了。<br>如果没有<span class="hljs-keyword">redo</span> <span class="hljs-keyword">log</span>，那么binlog无法判断哪条数据已经刷盘了，如果全量重跑一遍数据的话，很可能会出错。<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>数据库</category>
      
    </categories>
    
    
    <tags>
      
      <tag>MySQL</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>如何做数据分区</title>
    <link href="/2021/09/11/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%9B%B8%E5%85%B3/how-to-do-the-data-partition/"/>
    <url>/2021/09/11/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%9B%B8%E5%85%B3/how-to-do-the-data-partition/</url>
    
    <content type="html"><![CDATA[<h2 id="数据分区"><a href="#数据分区" class="headerlink" title="数据分区"></a>数据分区</h2><h3 id="数据分区-和-数据复制"><a href="#数据分区-和-数据复制" class="headerlink" title="数据分区 和 数据复制"></a>数据分区 和 数据复制</h3><p>​    分区通常与数据复制一起使用。也就是说，买个分区，保存在多个节点上面，同样的内容保存在多个节点上面。有利于提高系统的容错性。</p><p><img src="/../../images/%E5%A6%82%E4%BD%95%E5%81%9A%E6%95%B0%E6%8D%AE%E5%88%86%E5%8C%BA/1633163479614.png" alt="1633163479614"></p><h3 id="key-value-数据分区方法"><a href="#key-value-数据分区方法" class="headerlink" title="key-value 数据分区方法"></a>key-value 数据分区方法</h3><p>​    面对海量数据，单库不能负载。因此我们需要分区，主要目标是把数据和查询负载均匀分布在所有节点上。</p><p>​    如果节点平均分布，那么理论上会扩大n倍的吞吐量。</p><p>​    但是如果分区策略选的不好，会出现热点倾斜的问题。</p><figure class="highlight"><table><tr><td class="gutter"><div class="code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><pre><code class="hljs">比如说，QQ账号。采用百库百表的策略，但是有些用户会偏好一些靓号，因此会导致那些库的压力会非常大。因此产生了一个倾斜的问题。<br></code></pre></td></tr></table></figure><!--more--><h4 id="基于关键字分区"><a href="#基于关键字分区" class="headerlink" title="基于关键字分区"></a>基于关键字分区</h4><p><img src="/../../images/%E5%A6%82%E4%BD%95%E5%81%9A%E6%95%B0%E6%8D%AE%E5%88%86%E5%8C%BA/1633163555652.png" alt="1633163555652"></p><p><strong>缺点</strong></p><ul><li>比较容易出现热点倾斜，比如说靓号。<strong>这样会导致其他分区处于空闲状态，没有很好体现分区的好处</strong></li></ul><h4 id="基于关键字哈希值分区"><a href="#基于关键字哈希值分区" class="headerlink" title="基于关键字哈希值分区"></a>基于关键字哈希值分区</h4><p>​    针对上述热点倾斜的问题，许多分布式系统采用了关键字哈希来进行分区。</p><p>​    一个好的哈希函数，可以让数据分布得比较均匀。一旦找到合适的关键字哈希，就可以为他分配一个哈希范围，然后确定分区。</p><p><img src="/../../images/%E5%A6%82%E4%BD%95%E5%81%9A%E6%95%B0%E6%8D%AE%E5%88%86%E5%8C%BA/1633163577968.png" alt="1633163577968"></p><p><strong>特点</strong></p><ul><li>一致性哈希拓展性比较好，很容易添加节点，或者减少节点</li><li>但是哈希之后，记录分散在不同的分区。<strong>原本逻辑上相邻的记录，会被映射的不同的地方，因此比较难进行范围查询</strong></li></ul><p><strong>范围查询难 — 折中解决方案</strong></p><ul><li>以TDSQL为例，设计的时候，指定一个<code>shard_key</code>分片键。然后，定义的所有索引都要带有这个分片键。</li><li>假设分片键是user_id，那么就可以对该user_id一些相关的字段作范围查询</li></ul><p><strong>负载倾斜的解决方案</strong></p><ul><li>如果出现热点事件，那么会导致某一个键会被大量访问，即使通过hash处理，某个键的负载也会很高</li><li>一般是给热点数据，加一个随机数，使他分散到不同的分区上面。</li></ul><h4 id="分区之后-非聚集索引如何处理"><a href="#分区之后-非聚集索引如何处理" class="headerlink" title="分区之后 非聚集索引如何处理"></a>分区之后 非聚集索引如何处理</h4><ul><li>每个分区，维护自己分区的二级索引</li></ul><p><img src="/../../images/%E5%A6%82%E4%BD%95%E5%81%9A%E6%95%B0%E6%8D%AE%E5%88%86%E5%8C%BA/1633163597162.png" alt="1633163597162"></p><ul><li>每个分区维护一种耳机索引(该索引是全量数据)</li></ul><p><img src="/../../images/%E5%A6%82%E4%BD%95%E5%81%9A%E6%95%B0%E6%8D%AE%E5%88%86%E5%8C%BA/1633163612864.png" alt="1633163612864"></p><h3 id="分区再平衡"><a href="#分区再平衡" class="headerlink" title="分区再平衡"></a>分区再平衡</h3><p>随着时间的推移，数据库系统可能会出现某些变化:</p><ul><li>查询压力增加，需要更多的CPU进行处理</li><li>数据规模越来越大，需要更多的磁盘进行存储</li><li>节点出现故障</li></ul><p>这些变化都要求数据和请求可以<strong>从一个节点转移到另一个节点</strong>。这种方案叫做动态平衡。需要满足这些要求</p><ul><li>平衡后，负载应该是要均匀的</li><li>平衡过程中，数据库可以正常提供服务</li><li>尽量使平衡过程中的数据迁移，迁移量尽可能少</li></ul><h4 id="动态再平衡策略"><a href="#动态再平衡策略" class="headerlink" title="动态再平衡策略"></a>动态再平衡策略</h4><p><strong>庞大分区法</strong></p><p>​    这个方案非常简单。创建远大于节点数量的分区。然后进行动态平衡的时候，比如说添加节点，我们可以从每个节点中，匀走一些分区，组成新的节点。</p><p><img src="/../../images/%E5%A6%82%E4%BD%95%E5%81%9A%E6%95%B0%E6%8D%AE%E5%88%86%E5%8C%BA/1633163657118.png" alt="1633163657118"></p><p><strong>动态分区法</strong></p><p>​    可以把它想象成B-Tree。如果某个节点太庞大就分裂成两个分区，如果太小就合并</p><h3 id="请求路由问题"><a href="#请求路由问题" class="headerlink" title="请求路由问题"></a>请求路由问题</h3><p>​    现在我们已经将数据分布到很多节点上，但是还没解决<strong>收到一个请求时，把请求转发到哪个节点。甚至，分区再平衡的时候，这个映射关系是动态变化的</strong></p><p>​    类似服务发现的问题</p><p><img src="/../../images/%E5%A6%82%E4%BD%95%E5%81%9A%E6%95%B0%E6%8D%AE%E5%88%86%E5%8C%BA/1633163669886.png" alt="1633163669886"></p><ul><li>方案一：客户端随机转发到一个节点，如果命中则处理该请求。否则，节点转发到下一个节点</li><li>方案二：往上架一层，该层感知所有节点信息，负责路由。</li><li>方案三：客户端感知节点信息，直接转发。</li></ul><p>​    不管用什么办法，核心是：<strong>做出路由决策的组件，如何感知分区之间的变化？</strong></p><p>​    这是一个很有挑战的问题，让所有参与者都达成共识，否则请求会被发送到错误的节点，没有得到正确的处理。分布式系统中有专门的共识协议<strong>（理论上存在）</strong></p><p><strong>解决方案</strong></p><p>​    一般来说，让决策组件感知变化，会借鉴Zookeeper。</p><ul><li>每个节点都向zookeeper注册自己</li><li>决策组件可以向zookeeper订阅信息</li><li>并且，如果节点发生变化，zookeeper会向所有订阅者更新信息。</li></ul><p><img src="/../../images/%E5%A6%82%E4%BD%95%E5%81%9A%E6%95%B0%E6%8D%AE%E5%88%86%E5%8C%BA/1633163684965.png" alt="1633163684965"></p>]]></content>
    
    
    <categories>
      
      <category>数据库</category>
      
    </categories>
    
    
    <tags>
      
      <tag>分布式</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
